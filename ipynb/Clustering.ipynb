{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921c6565-71f8-4414-92cb-e750753cbf1a",
   "metadata": {},
   "source": [
    "1. specify `sys.path.append` as your project directory path\n",
    "\n",
    "2. change `Config.dataset` as different dataset names\n",
    "\n",
    "3. set `Config.arch='ViT-L/14'` and `f_classifier='./cache/vocabulary_classifier_L.pth'` for ViT-L architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187d77c-026e-4cf7-9000-103a8718cd8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/sheng-eatamath/S3A')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import model as clip\n",
    "from data.build_dataset import build_transform\n",
    "from data.imagenet_datasets import get_datasets_rzsc, Vocab\n",
    "from data.vocab import get_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184f5eb3-cd49-42e6-87b1-cb7e50d0d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = 'cuda:1'\n",
    "    arch = 'ViT-B/16'\n",
    "    ### dataset name\n",
    "    dataset = 'imagenet'\n",
    "    n_sampled_classes = 100 ### set num of sampled classes for ImageNet-100\n",
    "    seed = 0\n",
    "    \n",
    "    input_size = 224\n",
    "    batch_size = 512\n",
    "    use_def = False\n",
    "    clip_checkpoint = None\n",
    "    f_classifier = './cache/vocabulary_classifier.pth' ### precomputed 21k CLIP vocabulary classifier\n",
    "    \n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6c3e7-a7cf-4d0b-b4f6-2c8f2ae6daef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_clip(args):\n",
    "    \"\"\" load clip model from checkpoint \"\"\"\n",
    "    model = clip.load(args.arch, device=args.device)\n",
    "    if args.clip_checkpoint:\n",
    "        model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "    model.to(args.device).eval()\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    print(\"Input resolution:\", input_resolution)\n",
    "    print(\"Context length:\", context_length)\n",
    "    print(\"Vocab size:\", vocab_size)\n",
    "    return model\n",
    "\n",
    "vocab = get_vocab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818f39d-9340-4999-857d-2b086c9b0ac4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "std = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(args.input_size, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(args.input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=torch.tensor(mean),\n",
    "        std=torch.tensor(std))\n",
    "])\n",
    "dataset = get_datasets_rzsc(args, vocab, is_train=True, transform=transform_f, seed=0)\n",
    "loader_val = torch.utils.data.DataLoader(dataset, num_workers=4, batch_size=256, shuffle=False)\n",
    "print('dataset size', len(dataset))\n",
    "\n",
    "model = load_clip(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499fb6d7-7d39-4a90-8c65-0af9c5c9374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "all_vfeatures = []\n",
    "all_clu_label = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual.extract_features(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                all_vfeatures.append(deepcopy(logits.cpu().numpy()))\n",
    "                all_clu_label.append(deepcopy(label_clu.numpy()))\n",
    "        pbar.update(1)\n",
    "\n",
    "all_vfeatures = np.concatenate(all_vfeatures)\n",
    "all_clu_label = np.concatenate(all_clu_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a064680-71f5-46fe-a46d-4c846a6ef891",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./cache/features/vfeatures-{args.dataset}.npy', all_vfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e629eb-8f0c-4d31-8861-0adb53ffd580",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from my_util_package.evaluate import cluster_acc\n",
    "K = dataset.dataset.num_classes if hasattr(dataset, 'dataset') else dataset.num_classes\n",
    "print(f'K={K}')\n",
    "print(np.unique(all_clu_label).shape)\n",
    "\n",
    "kmeans = KMeans(n_clusters=K, random_state=0, n_init=17, max_iter=1000, verbose=0).fit(all_vfeatures)\n",
    "preds = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f06bba4-26f2-4c4a-8645-79b2f977deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clu = cluster_acc(all_clu_label, preds)\n",
    "print(f'cluster acc={acc_clu}')\n",
    "\n",
    "np.save(f'./cache/cluster/kmeans-{args.dataset}.pth', preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sssa",
   "language": "python",
   "name": "sssa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
