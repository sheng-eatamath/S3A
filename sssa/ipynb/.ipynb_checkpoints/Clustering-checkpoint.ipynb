{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c187d77c-026e-4cf7-9000-103a8718cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheng/anaconda3/envs/gcd/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "# sys.path.append('/home/sheng/sssa/CLIP/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from functools import reduce, partial\n",
    "from itertools import zip_longest\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from wordnet_utils import *\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "from ipynb_utils import get_hier_datasets, get_classifier, MCMF_assign_labels\n",
    "# import clip\n",
    "import model as clip\n",
    "from data.datasets import build_transform, get_hier_datasets, Vocab\n",
    "# from data.imagenet_datasets import get_datasets_oszsl\n",
    "from data.imagenet_datasets import get_datasets_oszsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184f5eb3-cd49-42e6-87b1-cb7e50d0d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = 'cuda:2'\n",
    "    arch = 'ViT-B/16'\n",
    "    dataset = 'sun'\n",
    "    n_sampled_classes = 100\n",
    "    input_size = 224\n",
    "    seed = 0\n",
    "    \n",
    "    batch_size = 512\n",
    "    use_def = False\n",
    "    clip_checkpoint = None\n",
    "    f_classifier = './cache/wordnet_classifier_in21k_word.pth'\n",
    "    templates_name = 'templates_small'\n",
    "    \n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b6c3e7-a7cf-4d0b-b4f6-2c8f2ae6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates(args):\n",
    "    with open(f'../{args.templates_name}.json', 'rb') as f:\n",
    "        templates = json.load(f)['imagenet']\n",
    "    return templates\n",
    "\n",
    "def get_vocab():\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        vocab: {`names`: list, `ids`: synset ids, `parents`: [{synset ids}]}\n",
    "    \"\"\"\n",
    "    with open('/home/sheng/dataset/wordnet_nouns_with_synset_4.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    return vocab\n",
    "\n",
    "def get_subsample_vocab(sample_synset_id: set):\n",
    "    vocab = get_vocab()\n",
    "    index = np.array([ i for i in range(len(vocab['synsets'])) if vocab['synsets'][i] in sample_synset_id ]).astype(np.int32)\n",
    "    for k in vocab.keys():\n",
    "        vocab[k] = np.array(vocab[k])[index].tolist()\n",
    "    return vocab\n",
    "\n",
    "def read_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "    return data\n",
    "\n",
    "def read_lvis_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/lvis_imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "        # data = list(map(lambda x: x.split('.')[0], data))\n",
    "    return data\n",
    "\n",
    "def load_clip2(args):\n",
    "    model = clip.load(args.arch, device=args.device)\n",
    "    if args.clip_checkpoint:\n",
    "        model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "    model.to(args.device).eval()\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "\n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    print(\"Input resolution:\", input_resolution)\n",
    "    print(\"Context length:\", context_length)\n",
    "    print(\"Vocab size:\", vocab_size)\n",
    "    return model\n",
    "\n",
    "templates = load_templates(args)\n",
    "vocab = get_vocab()\n",
    "nouns = [ wn.synset(s) for s in vocab['synsets'] ]\n",
    "classnames = vocab['names']\n",
    "parents = vocab['parents']\n",
    "defs = vocab['def']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2818f39d-9340-4999-857d-2b086c9b0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 108754\n",
      "missing keys:\n",
      "['visual.projection_head.0.weight', 'visual.projection_head.0.bias', 'visual.projection_head.2.weight', 'visual.projection_head.2.bias']\n",
      "Model parameters: 150,408,193\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "\"\"\" prepare dataset and load CLIP \"\"\"\n",
    "classes = read_imagenet21k_classes() + os.listdir('/home/sheng/dataset/imagenet-img/')\n",
    "classes = [wn.synset_from_pos_and_offset('n', int(x[1:])).name() for x in classes]\n",
    "classes = set(classes)\n",
    "if args.dataset == 'lvis':\n",
    "    classes = read_lvis_imagenet21k_classes()\n",
    "    classes = set(classes)\n",
    "vocab = get_subsample_vocab(classes)\n",
    "vocab = Vocab(vocab=vocab)\n",
    "\n",
    "transform_val = build_transform(is_train=False, args=args, train_config=None)\n",
    "mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "std = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(args.input_size, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(args.input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=torch.tensor(mean),\n",
    "        std=torch.tensor(std))\n",
    "])\n",
    "dataset = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=0)\n",
    "loader_val = torch.utils.data.DataLoader(dataset, num_workers=4, batch_size=256, shuffle=False)\n",
    "print('dataset size', len(dataset))\n",
    "\n",
    "# model, preprocess = load_clip(args)\n",
    "model = load_clip2(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499fb6d7-7d39-4a90-8c65-0af9c5c9374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [18:43<00:00,  2.64s/it] \n"
     ]
    }
   ],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "all_vfeatures = []\n",
    "all_clu_label = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual.extract_features(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                all_vfeatures.append(deepcopy(logits.cpu().numpy()))\n",
    "                all_clu_label.append(deepcopy(label_clu.numpy()))\n",
    "        pbar.update(1)\n",
    "\n",
    "all_vfeatures = np.concatenate(all_vfeatures)\n",
    "all_clu_label = np.concatenate(all_clu_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81986868-0008-4917-a1e4-0d6890a35ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_vfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a064680-71f5-46fe-a46d-4c846a6ef891",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./cache/features/vfeatures-{args.dataset}.npy', all_vfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c3d403-474b-41c0-a098-9487fa8d524d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=397\n",
      "(397,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from my_util_package_oszsl.evaluation import cluster_acc\n",
    "K = dataset.num_classes\n",
    "print(f'K={K}')\n",
    "print(np.unique(all_clu_label).shape)\n",
    "# kmeans = MiniBatchKMeans(n_clusters=10*K, batch_size=2048, random_state=0, n_init=10, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "# preds = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d7c3a4-71f7-4229-af50-4159c0c001ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 41855.5078125.\n",
      "Iteration 1, inertia 27962.5078125.\n",
      "Iteration 2, inertia 27324.05859375.\n",
      "Iteration 3, inertia 27072.75.\n",
      "Iteration 4, inertia 26943.43359375.\n",
      "Iteration 5, inertia 26870.37109375.\n",
      "Iteration 6, inertia 26825.224609375.\n",
      "Iteration 7, inertia 26792.74609375.\n",
      "Iteration 8, inertia 26766.40234375.\n",
      "Iteration 9, inertia 26741.42578125.\n",
      "Iteration 10, inertia 26719.029296875.\n",
      "Iteration 11, inertia 26700.123046875.\n",
      "Iteration 12, inertia 26682.962890625.\n",
      "Iteration 13, inertia 26666.962890625.\n",
      "Iteration 14, inertia 26651.48046875.\n",
      "Iteration 15, inertia 26638.08203125.\n",
      "Iteration 16, inertia 26626.853515625.\n",
      "Iteration 17, inertia 26617.966796875.\n",
      "Iteration 18, inertia 26610.29296875.\n",
      "Iteration 19, inertia 26603.060546875.\n",
      "Iteration 20, inertia 26596.212890625.\n",
      "Iteration 21, inertia 26589.7734375.\n",
      "Iteration 22, inertia 26582.4375.\n",
      "Iteration 23, inertia 26576.453125.\n",
      "Iteration 24, inertia 26572.01171875.\n",
      "Iteration 25, inertia 26568.5234375.\n",
      "Iteration 26, inertia 26565.34375.\n",
      "Iteration 27, inertia 26562.578125.\n",
      "Iteration 28, inertia 26559.837890625.\n",
      "Iteration 29, inertia 26557.353515625.\n",
      "Iteration 30, inertia 26555.224609375.\n",
      "Iteration 31, inertia 26553.671875.\n",
      "Iteration 32, inertia 26552.451171875.\n",
      "Iteration 33, inertia 26551.51953125.\n",
      "Iteration 34, inertia 26550.55859375.\n",
      "Iteration 35, inertia 26549.580078125.\n",
      "Iteration 36, inertia 26548.69140625.\n",
      "Iteration 37, inertia 26547.833984375.\n",
      "Iteration 38, inertia 26546.919921875.\n",
      "Iteration 39, inertia 26546.126953125.\n",
      "Iteration 40, inertia 26545.501953125.\n",
      "Iteration 41, inertia 26545.1015625.\n",
      "Iteration 42, inertia 26544.802734375.\n",
      "Iteration 43, inertia 26544.455078125.\n",
      "Iteration 44, inertia 26544.02734375.\n",
      "Iteration 45, inertia 26543.466796875.\n",
      "Iteration 46, inertia 26542.90234375.\n",
      "Iteration 47, inertia 26542.451171875.\n",
      "Iteration 48, inertia 26542.1484375.\n",
      "Iteration 49, inertia 26541.94921875.\n",
      "Iteration 50, inertia 26541.732421875.\n",
      "Iteration 51, inertia 26541.552734375.\n",
      "Iteration 52, inertia 26541.375.\n",
      "Iteration 53, inertia 26541.193359375.\n",
      "Iteration 54, inertia 26541.04296875.\n",
      "Iteration 55, inertia 26540.95703125.\n",
      "Iteration 56, inertia 26540.890625.\n",
      "Iteration 57, inertia 26540.87890625.\n",
      "Iteration 58, inertia 26540.859375.\n",
      "Iteration 59, inertia 26540.857421875.\n",
      "Converged at iteration 59: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41964.91796875.\n",
      "Iteration 1, inertia 27992.38671875.\n",
      "Iteration 2, inertia 27410.1484375.\n",
      "Iteration 3, inertia 27169.1171875.\n",
      "Iteration 4, inertia 27035.732421875.\n",
      "Iteration 5, inertia 26954.173828125.\n",
      "Iteration 6, inertia 26897.1640625.\n",
      "Iteration 7, inertia 26857.125.\n",
      "Iteration 8, inertia 26825.521484375.\n",
      "Iteration 9, inertia 26800.083984375.\n",
      "Iteration 10, inertia 26779.142578125.\n",
      "Iteration 11, inertia 26763.1640625.\n",
      "Iteration 12, inertia 26748.521484375.\n",
      "Iteration 13, inertia 26730.90234375.\n",
      "Iteration 14, inertia 26711.427734375.\n",
      "Iteration 15, inertia 26696.310546875.\n",
      "Iteration 16, inertia 26686.251953125.\n",
      "Iteration 17, inertia 26678.84765625.\n",
      "Iteration 18, inertia 26673.404296875.\n",
      "Iteration 19, inertia 26668.87109375.\n",
      "Iteration 20, inertia 26664.626953125.\n",
      "Iteration 21, inertia 26660.4765625.\n",
      "Iteration 22, inertia 26655.560546875.\n",
      "Iteration 23, inertia 26649.904296875.\n",
      "Iteration 24, inertia 26645.263671875.\n",
      "Iteration 25, inertia 26641.224609375.\n",
      "Iteration 26, inertia 26637.486328125.\n",
      "Iteration 27, inertia 26634.25.\n",
      "Iteration 28, inertia 26631.587890625.\n",
      "Iteration 29, inertia 26629.4453125.\n",
      "Iteration 30, inertia 26627.736328125.\n",
      "Iteration 31, inertia 26626.30859375.\n",
      "Iteration 32, inertia 26625.083984375.\n",
      "Iteration 33, inertia 26624.029296875.\n",
      "Iteration 34, inertia 26623.109375.\n",
      "Iteration 35, inertia 26622.12890625.\n",
      "Iteration 36, inertia 26621.111328125.\n",
      "Iteration 37, inertia 26619.9609375.\n",
      "Iteration 38, inertia 26618.52734375.\n",
      "Iteration 39, inertia 26616.892578125.\n",
      "Iteration 40, inertia 26615.046875.\n",
      "Iteration 41, inertia 26613.994140625.\n",
      "Iteration 42, inertia 26613.134765625.\n",
      "Iteration 43, inertia 26612.49609375.\n",
      "Iteration 44, inertia 26611.880859375.\n",
      "Iteration 45, inertia 26610.990234375.\n",
      "Iteration 46, inertia 26610.15625.\n",
      "Iteration 47, inertia 26609.6015625.\n",
      "Iteration 48, inertia 26609.2421875.\n",
      "Iteration 49, inertia 26608.97265625.\n",
      "Iteration 50, inertia 26608.771484375.\n",
      "Iteration 51, inertia 26608.634765625.\n",
      "Iteration 52, inertia 26608.494140625.\n",
      "Iteration 53, inertia 26608.365234375.\n",
      "Iteration 54, inertia 26608.2578125.\n",
      "Iteration 55, inertia 26608.162109375.\n",
      "Iteration 56, inertia 26608.01953125.\n",
      "Iteration 57, inertia 26607.896484375.\n",
      "Iteration 58, inertia 26607.8125.\n",
      "Iteration 59, inertia 26607.744140625.\n",
      "Iteration 60, inertia 26607.697265625.\n",
      "Iteration 61, inertia 26607.654296875.\n",
      "Iteration 62, inertia 26607.625.\n",
      "Iteration 63, inertia 26607.580078125.\n",
      "Iteration 64, inertia 26607.54296875.\n",
      "Iteration 65, inertia 26607.5078125.\n",
      "Iteration 66, inertia 26607.462890625.\n",
      "Iteration 67, inertia 26607.439453125.\n",
      "Iteration 68, inertia 26607.43359375.\n",
      "Iteration 69, inertia 26607.42578125.\n",
      "Iteration 70, inertia 26607.419921875.\n",
      "Iteration 71, inertia 26607.41015625.\n",
      "Iteration 72, inertia 26607.40234375.\n",
      "Converged at iteration 72: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42039.19140625.\n",
      "Iteration 1, inertia 27983.255859375.\n",
      "Iteration 2, inertia 27366.8515625.\n",
      "Iteration 3, inertia 27128.55859375.\n",
      "Iteration 4, inertia 26985.279296875.\n",
      "Iteration 5, inertia 26884.986328125.\n",
      "Iteration 6, inertia 26817.005859375.\n",
      "Iteration 7, inertia 26771.880859375.\n",
      "Iteration 8, inertia 26736.111328125.\n",
      "Iteration 9, inertia 26706.556640625.\n",
      "Iteration 10, inertia 26683.484375.\n",
      "Iteration 11, inertia 26665.69921875.\n",
      "Iteration 12, inertia 26652.037109375.\n",
      "Iteration 13, inertia 26641.8359375.\n",
      "Iteration 14, inertia 26633.16796875.\n",
      "Iteration 15, inertia 26626.447265625.\n",
      "Iteration 16, inertia 26620.806640625.\n",
      "Iteration 17, inertia 26616.412109375.\n",
      "Iteration 18, inertia 26613.271484375.\n",
      "Iteration 19, inertia 26610.4921875.\n",
      "Iteration 20, inertia 26607.828125.\n",
      "Iteration 21, inertia 26605.052734375.\n",
      "Iteration 22, inertia 26602.60546875.\n",
      "Iteration 23, inertia 26600.521484375.\n",
      "Iteration 24, inertia 26598.470703125.\n",
      "Iteration 25, inertia 26596.3984375.\n",
      "Iteration 26, inertia 26594.5078125.\n",
      "Iteration 27, inertia 26592.859375.\n",
      "Iteration 28, inertia 26591.06640625.\n",
      "Iteration 29, inertia 26589.263671875.\n",
      "Iteration 30, inertia 26587.568359375.\n",
      "Iteration 31, inertia 26586.1953125.\n",
      "Iteration 32, inertia 26584.470703125.\n",
      "Iteration 33, inertia 26582.560546875.\n",
      "Iteration 34, inertia 26580.673828125.\n",
      "Iteration 35, inertia 26578.8125.\n",
      "Iteration 36, inertia 26577.28125.\n",
      "Iteration 37, inertia 26575.90625.\n",
      "Iteration 38, inertia 26574.486328125.\n",
      "Iteration 39, inertia 26573.16796875.\n",
      "Iteration 40, inertia 26571.84765625.\n",
      "Iteration 41, inertia 26570.77734375.\n",
      "Iteration 42, inertia 26569.939453125.\n",
      "Iteration 43, inertia 26569.283203125.\n",
      "Iteration 44, inertia 26568.716796875.\n",
      "Iteration 45, inertia 26568.142578125.\n",
      "Iteration 46, inertia 26567.58203125.\n",
      "Iteration 47, inertia 26567.134765625.\n",
      "Iteration 48, inertia 26566.8203125.\n",
      "Iteration 49, inertia 26566.55078125.\n",
      "Iteration 50, inertia 26566.328125.\n",
      "Iteration 51, inertia 26566.138671875.\n",
      "Iteration 52, inertia 26565.974609375.\n",
      "Iteration 53, inertia 26565.84765625.\n",
      "Iteration 54, inertia 26565.712890625.\n",
      "Iteration 55, inertia 26565.58203125.\n",
      "Iteration 56, inertia 26565.47265625.\n",
      "Iteration 57, inertia 26565.365234375.\n",
      "Iteration 58, inertia 26565.234375.\n",
      "Iteration 59, inertia 26565.109375.\n",
      "Iteration 60, inertia 26565.017578125.\n",
      "Iteration 61, inertia 26564.962890625.\n",
      "Iteration 62, inertia 26564.888671875.\n",
      "Iteration 63, inertia 26564.7890625.\n",
      "Iteration 64, inertia 26564.734375.\n",
      "Iteration 65, inertia 26564.724609375.\n",
      "Iteration 66, inertia 26564.712890625.\n",
      "Converged at iteration 66: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41934.40234375.\n",
      "Iteration 1, inertia 27870.033203125.\n",
      "Iteration 2, inertia 27293.5234375.\n",
      "Iteration 3, inertia 27083.484375.\n",
      "Iteration 4, inertia 26960.66015625.\n",
      "Iteration 5, inertia 26876.22265625.\n",
      "Iteration 6, inertia 26819.259765625.\n",
      "Iteration 7, inertia 26777.2734375.\n",
      "Iteration 8, inertia 26745.71484375.\n",
      "Iteration 9, inertia 26723.345703125.\n",
      "Iteration 10, inertia 26706.53515625.\n",
      "Iteration 11, inertia 26692.681640625.\n",
      "Iteration 12, inertia 26681.228515625.\n",
      "Iteration 13, inertia 26671.8515625.\n",
      "Iteration 14, inertia 26663.18359375.\n",
      "Iteration 15, inertia 26655.62109375.\n",
      "Iteration 16, inertia 26649.158203125.\n",
      "Iteration 17, inertia 26643.560546875.\n",
      "Iteration 18, inertia 26638.3828125.\n",
      "Iteration 19, inertia 26633.96875.\n",
      "Iteration 20, inertia 26630.33984375.\n",
      "Iteration 21, inertia 26626.98828125.\n",
      "Iteration 22, inertia 26623.8125.\n",
      "Iteration 23, inertia 26621.314453125.\n",
      "Iteration 24, inertia 26619.408203125.\n",
      "Iteration 25, inertia 26617.525390625.\n",
      "Iteration 26, inertia 26615.361328125.\n",
      "Iteration 27, inertia 26613.259765625.\n",
      "Iteration 28, inertia 26611.322265625.\n",
      "Iteration 29, inertia 26609.615234375.\n",
      "Iteration 30, inertia 26607.875.\n",
      "Iteration 31, inertia 26606.099609375.\n",
      "Iteration 32, inertia 26604.478515625.\n",
      "Iteration 33, inertia 26603.126953125.\n",
      "Iteration 34, inertia 26601.796875.\n",
      "Iteration 35, inertia 26600.595703125.\n",
      "Iteration 36, inertia 26599.384765625.\n",
      "Iteration 37, inertia 26598.4609375.\n",
      "Iteration 38, inertia 26597.556640625.\n",
      "Iteration 39, inertia 26596.759765625.\n",
      "Iteration 40, inertia 26596.1796875.\n",
      "Iteration 41, inertia 26595.68359375.\n",
      "Iteration 42, inertia 26595.185546875.\n",
      "Iteration 43, inertia 26594.740234375.\n",
      "Iteration 44, inertia 26594.201171875.\n",
      "Iteration 45, inertia 26593.572265625.\n",
      "Iteration 46, inertia 26592.501953125.\n",
      "Iteration 47, inertia 26590.974609375.\n",
      "Iteration 48, inertia 26589.44140625.\n",
      "Iteration 49, inertia 26588.267578125.\n",
      "Iteration 50, inertia 26587.1796875.\n",
      "Iteration 51, inertia 26586.326171875.\n",
      "Iteration 52, inertia 26585.71875.\n",
      "Iteration 53, inertia 26585.294921875.\n",
      "Iteration 54, inertia 26585.01171875.\n",
      "Iteration 55, inertia 26584.802734375.\n",
      "Iteration 56, inertia 26584.611328125.\n",
      "Iteration 57, inertia 26584.478515625.\n",
      "Iteration 58, inertia 26584.3125.\n",
      "Iteration 59, inertia 26584.1953125.\n",
      "Iteration 60, inertia 26584.123046875.\n",
      "Iteration 61, inertia 26584.0546875.\n",
      "Iteration 62, inertia 26584.001953125.\n",
      "Iteration 63, inertia 26583.984375.\n",
      "Iteration 64, inertia 26583.947265625.\n",
      "Iteration 65, inertia 26583.916015625.\n",
      "Iteration 66, inertia 26583.888671875.\n",
      "Iteration 67, inertia 26583.84375.\n",
      "Iteration 68, inertia 26583.81640625.\n",
      "Iteration 69, inertia 26583.779296875.\n",
      "Iteration 70, inertia 26583.74609375.\n",
      "Iteration 71, inertia 26583.701171875.\n",
      "Iteration 72, inertia 26583.646484375.\n",
      "Iteration 73, inertia 26583.587890625.\n",
      "Iteration 74, inertia 26583.517578125.\n",
      "Iteration 75, inertia 26583.443359375.\n",
      "Iteration 76, inertia 26583.369140625.\n",
      "Iteration 77, inertia 26583.3203125.\n",
      "Iteration 78, inertia 26583.294921875.\n",
      "Iteration 79, inertia 26583.2578125.\n",
      "Iteration 80, inertia 26583.212890625.\n",
      "Iteration 81, inertia 26583.18359375.\n",
      "Iteration 82, inertia 26583.1640625.\n",
      "Iteration 83, inertia 26583.158203125.\n",
      "Iteration 84, inertia 26583.13671875.\n",
      "Iteration 85, inertia 26583.12890625.\n",
      "Iteration 86, inertia 26583.111328125.\n",
      "Iteration 87, inertia 26583.078125.\n",
      "Iteration 88, inertia 26583.03515625.\n",
      "Iteration 89, inertia 26583.001953125.\n",
      "Iteration 90, inertia 26582.986328125.\n",
      "Iteration 91, inertia 26582.9609375.\n",
      "Iteration 92, inertia 26582.955078125.\n",
      "Iteration 93, inertia 26582.93359375.\n",
      "Iteration 94, inertia 26582.935546875.\n",
      "Iteration 95, inertia 26582.9375.\n",
      "Iteration 96, inertia 26582.935546875.\n",
      "Iteration 97, inertia 26582.935546875.\n",
      "Iteration 98, inertia 26582.92578125.\n",
      "Iteration 99, inertia 26582.927734375.\n",
      "Iteration 100, inertia 26582.923828125.\n",
      "Iteration 101, inertia 26582.921875.\n",
      "Iteration 102, inertia 26582.921875.\n",
      "Iteration 103, inertia 26582.90625.\n",
      "Iteration 104, inertia 26582.904296875.\n",
      "Iteration 105, inertia 26582.900390625.\n",
      "Iteration 106, inertia 26582.89453125.\n",
      "Iteration 107, inertia 26582.896484375.\n",
      "Iteration 108, inertia 26582.890625.\n",
      "Iteration 109, inertia 26582.892578125.\n",
      "Iteration 110, inertia 26582.88671875.\n",
      "Converged at iteration 110: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41868.47265625.\n",
      "Iteration 1, inertia 27954.310546875.\n",
      "Iteration 2, inertia 27328.828125.\n",
      "Iteration 3, inertia 27089.4375.\n",
      "Iteration 4, inertia 26955.111328125.\n",
      "Iteration 5, inertia 26861.83984375.\n",
      "Iteration 6, inertia 26804.27734375.\n",
      "Iteration 7, inertia 26765.1484375.\n",
      "Iteration 8, inertia 26735.986328125.\n",
      "Iteration 9, inertia 26712.880859375.\n",
      "Iteration 10, inertia 26695.23046875.\n",
      "Iteration 11, inertia 26680.80078125.\n",
      "Iteration 12, inertia 26668.755859375.\n",
      "Iteration 13, inertia 26658.1640625.\n",
      "Iteration 14, inertia 26648.037109375.\n",
      "Iteration 15, inertia 26638.939453125.\n",
      "Iteration 16, inertia 26631.140625.\n",
      "Iteration 17, inertia 26624.376953125.\n",
      "Iteration 18, inertia 26618.916015625.\n",
      "Iteration 19, inertia 26614.720703125.\n",
      "Iteration 20, inertia 26611.044921875.\n",
      "Iteration 21, inertia 26608.38671875.\n",
      "Iteration 22, inertia 26606.1953125.\n",
      "Iteration 23, inertia 26604.212890625.\n",
      "Iteration 24, inertia 26602.21875.\n",
      "Iteration 25, inertia 26599.958984375.\n",
      "Iteration 26, inertia 26597.259765625.\n",
      "Iteration 27, inertia 26594.2421875.\n",
      "Iteration 28, inertia 26591.052734375.\n",
      "Iteration 29, inertia 26588.392578125.\n",
      "Iteration 30, inertia 26586.86328125.\n",
      "Iteration 31, inertia 26585.271484375.\n",
      "Iteration 32, inertia 26583.85546875.\n",
      "Iteration 33, inertia 26582.404296875.\n",
      "Iteration 34, inertia 26581.01953125.\n",
      "Iteration 35, inertia 26579.759765625.\n",
      "Iteration 36, inertia 26578.66796875.\n",
      "Iteration 37, inertia 26577.59765625.\n",
      "Iteration 38, inertia 26576.75390625.\n",
      "Iteration 39, inertia 26575.9453125.\n",
      "Iteration 40, inertia 26575.091796875.\n",
      "Iteration 41, inertia 26574.224609375.\n",
      "Iteration 42, inertia 26573.5078125.\n",
      "Iteration 43, inertia 26572.865234375.\n",
      "Iteration 44, inertia 26572.29296875.\n",
      "Iteration 45, inertia 26571.783203125.\n",
      "Iteration 46, inertia 26571.296875.\n",
      "Iteration 47, inertia 26570.869140625.\n",
      "Iteration 48, inertia 26570.39453125.\n",
      "Iteration 49, inertia 26569.962890625.\n",
      "Iteration 50, inertia 26569.6796875.\n",
      "Iteration 51, inertia 26569.45703125.\n",
      "Iteration 52, inertia 26569.322265625.\n",
      "Iteration 53, inertia 26569.15234375.\n",
      "Iteration 54, inertia 26568.986328125.\n",
      "Iteration 55, inertia 26568.83203125.\n",
      "Iteration 56, inertia 26568.72265625.\n",
      "Iteration 57, inertia 26568.63671875.\n",
      "Iteration 58, inertia 26568.55078125.\n",
      "Iteration 59, inertia 26568.498046875.\n",
      "Iteration 60, inertia 26568.44140625.\n",
      "Iteration 61, inertia 26568.392578125.\n",
      "Iteration 62, inertia 26568.349609375.\n",
      "Iteration 63, inertia 26568.294921875.\n",
      "Iteration 64, inertia 26568.22265625.\n",
      "Iteration 65, inertia 26568.173828125.\n",
      "Iteration 66, inertia 26568.14453125.\n",
      "Iteration 67, inertia 26568.123046875.\n",
      "Iteration 68, inertia 26568.095703125.\n",
      "Iteration 69, inertia 26568.06640625.\n",
      "Iteration 70, inertia 26568.046875.\n",
      "Iteration 71, inertia 26568.03515625.\n",
      "Iteration 72, inertia 26568.033203125.\n",
      "Iteration 73, inertia 26568.01953125.\n",
      "Iteration 74, inertia 26568.01171875.\n",
      "Iteration 75, inertia 26568.01171875.\n",
      "Iteration 76, inertia 26568.005859375.\n",
      "Iteration 77, inertia 26568.0.\n",
      "Converged at iteration 77: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42027.67578125.\n",
      "Iteration 1, inertia 27978.275390625.\n",
      "Iteration 2, inertia 27348.2265625.\n",
      "Iteration 3, inertia 27098.521484375.\n",
      "Iteration 4, inertia 26962.150390625.\n",
      "Iteration 5, inertia 26875.271484375.\n",
      "Iteration 6, inertia 26811.900390625.\n",
      "Iteration 7, inertia 26759.8046875.\n",
      "Iteration 8, inertia 26716.36328125.\n",
      "Iteration 9, inertia 26680.357421875.\n",
      "Iteration 10, inertia 26655.673828125.\n",
      "Iteration 11, inertia 26639.626953125.\n",
      "Iteration 12, inertia 26628.22265625.\n",
      "Iteration 13, inertia 26619.40625.\n",
      "Iteration 14, inertia 26611.705078125.\n",
      "Iteration 15, inertia 26605.06640625.\n",
      "Iteration 16, inertia 26599.115234375.\n",
      "Iteration 17, inertia 26592.849609375.\n",
      "Iteration 18, inertia 26586.892578125.\n",
      "Iteration 19, inertia 26581.6875.\n",
      "Iteration 20, inertia 26577.923828125.\n",
      "Iteration 21, inertia 26574.947265625.\n",
      "Iteration 22, inertia 26572.453125.\n",
      "Iteration 23, inertia 26570.09375.\n",
      "Iteration 24, inertia 26567.650390625.\n",
      "Iteration 25, inertia 26565.4609375.\n",
      "Iteration 26, inertia 26563.38671875.\n",
      "Iteration 27, inertia 26561.775390625.\n",
      "Iteration 28, inertia 26560.40234375.\n",
      "Iteration 29, inertia 26558.984375.\n",
      "Iteration 30, inertia 26557.603515625.\n",
      "Iteration 31, inertia 26556.111328125.\n",
      "Iteration 32, inertia 26554.771484375.\n",
      "Iteration 33, inertia 26553.1328125.\n",
      "Iteration 34, inertia 26551.783203125.\n",
      "Iteration 35, inertia 26551.01953125.\n",
      "Iteration 36, inertia 26550.322265625.\n",
      "Iteration 37, inertia 26549.697265625.\n",
      "Iteration 38, inertia 26549.080078125.\n",
      "Iteration 39, inertia 26548.6796875.\n",
      "Iteration 40, inertia 26548.248046875.\n",
      "Iteration 41, inertia 26547.671875.\n",
      "Iteration 42, inertia 26547.123046875.\n",
      "Iteration 43, inertia 26546.287109375.\n",
      "Iteration 44, inertia 26545.494140625.\n",
      "Iteration 45, inertia 26544.994140625.\n",
      "Iteration 46, inertia 26544.50390625.\n",
      "Iteration 47, inertia 26544.083984375.\n",
      "Iteration 48, inertia 26543.720703125.\n",
      "Iteration 49, inertia 26543.375.\n",
      "Iteration 50, inertia 26542.8828125.\n",
      "Iteration 51, inertia 26542.36328125.\n",
      "Iteration 52, inertia 26542.0546875.\n",
      "Iteration 53, inertia 26541.724609375.\n",
      "Iteration 54, inertia 26541.44140625.\n",
      "Iteration 55, inertia 26541.267578125.\n",
      "Iteration 56, inertia 26541.134765625.\n",
      "Iteration 57, inertia 26541.02734375.\n",
      "Iteration 58, inertia 26540.958984375.\n",
      "Iteration 59, inertia 26540.90234375.\n",
      "Iteration 60, inertia 26540.857421875.\n",
      "Iteration 61, inertia 26540.828125.\n",
      "Iteration 62, inertia 26540.794921875.\n",
      "Iteration 63, inertia 26540.7734375.\n",
      "Iteration 64, inertia 26540.755859375.\n",
      "Iteration 65, inertia 26540.73828125.\n",
      "Iteration 66, inertia 26540.703125.\n",
      "Iteration 67, inertia 26540.666015625.\n",
      "Iteration 68, inertia 26540.6484375.\n",
      "Iteration 69, inertia 26540.640625.\n",
      "Iteration 70, inertia 26540.619140625.\n",
      "Iteration 71, inertia 26540.58203125.\n",
      "Iteration 72, inertia 26540.564453125.\n",
      "Iteration 73, inertia 26540.548828125.\n",
      "Iteration 74, inertia 26540.5390625.\n",
      "Iteration 75, inertia 26540.53125.\n",
      "Iteration 76, inertia 26540.529296875.\n",
      "Converged at iteration 76: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42188.7265625.\n",
      "Iteration 1, inertia 27984.064453125.\n",
      "Iteration 2, inertia 27339.72265625.\n",
      "Iteration 3, inertia 27090.5.\n",
      "Iteration 4, inertia 26961.375.\n",
      "Iteration 5, inertia 26876.453125.\n",
      "Iteration 6, inertia 26812.27734375.\n",
      "Iteration 7, inertia 26765.841796875.\n",
      "Iteration 8, inertia 26727.970703125.\n",
      "Iteration 9, inertia 26700.947265625.\n",
      "Iteration 10, inertia 26679.390625.\n",
      "Iteration 11, inertia 26662.603515625.\n",
      "Iteration 12, inertia 26648.60546875.\n",
      "Iteration 13, inertia 26637.1796875.\n",
      "Iteration 14, inertia 26626.7109375.\n",
      "Iteration 15, inertia 26615.1328125.\n",
      "Iteration 16, inertia 26603.8828125.\n",
      "Iteration 17, inertia 26593.216796875.\n",
      "Iteration 18, inertia 26584.9296875.\n",
      "Iteration 19, inertia 26578.96875.\n",
      "Iteration 20, inertia 26575.212890625.\n",
      "Iteration 21, inertia 26572.08203125.\n",
      "Iteration 22, inertia 26569.130859375.\n",
      "Iteration 23, inertia 26566.923828125.\n",
      "Iteration 24, inertia 26564.826171875.\n",
      "Iteration 25, inertia 26562.677734375.\n",
      "Iteration 26, inertia 26560.421875.\n",
      "Iteration 27, inertia 26557.97265625.\n",
      "Iteration 28, inertia 26555.78515625.\n",
      "Iteration 29, inertia 26554.009765625.\n",
      "Iteration 30, inertia 26552.248046875.\n",
      "Iteration 31, inertia 26550.66796875.\n",
      "Iteration 32, inertia 26548.90234375.\n",
      "Iteration 33, inertia 26547.384765625.\n",
      "Iteration 34, inertia 26546.12890625.\n",
      "Iteration 35, inertia 26545.029296875.\n",
      "Iteration 36, inertia 26544.1328125.\n",
      "Iteration 37, inertia 26543.41015625.\n",
      "Iteration 38, inertia 26542.671875.\n",
      "Iteration 39, inertia 26542.080078125.\n",
      "Iteration 40, inertia 26541.595703125.\n",
      "Iteration 41, inertia 26541.166015625.\n",
      "Iteration 42, inertia 26540.681640625.\n",
      "Iteration 43, inertia 26540.189453125.\n",
      "Iteration 44, inertia 26539.7890625.\n",
      "Iteration 45, inertia 26539.4140625.\n",
      "Iteration 46, inertia 26539.009765625.\n",
      "Iteration 47, inertia 26538.626953125.\n",
      "Iteration 48, inertia 26538.1875.\n",
      "Iteration 49, inertia 26537.740234375.\n",
      "Iteration 50, inertia 26537.33984375.\n",
      "Iteration 51, inertia 26536.84375.\n",
      "Iteration 52, inertia 26536.390625.\n",
      "Iteration 53, inertia 26535.990234375.\n",
      "Iteration 54, inertia 26535.744140625.\n",
      "Iteration 55, inertia 26535.5625.\n",
      "Iteration 56, inertia 26535.349609375.\n",
      "Iteration 57, inertia 26535.171875.\n",
      "Iteration 58, inertia 26535.05078125.\n",
      "Iteration 59, inertia 26534.90625.\n",
      "Iteration 60, inertia 26534.771484375.\n",
      "Iteration 61, inertia 26534.697265625.\n",
      "Iteration 62, inertia 26534.64453125.\n",
      "Iteration 63, inertia 26534.6171875.\n",
      "Iteration 64, inertia 26534.599609375.\n",
      "Iteration 65, inertia 26534.580078125.\n",
      "Iteration 66, inertia 26534.564453125.\n",
      "Iteration 67, inertia 26534.548828125.\n",
      "Iteration 68, inertia 26534.525390625.\n",
      "Iteration 69, inertia 26534.494140625.\n",
      "Iteration 70, inertia 26534.470703125.\n",
      "Iteration 71, inertia 26534.431640625.\n",
      "Iteration 72, inertia 26534.380859375.\n",
      "Iteration 73, inertia 26534.32421875.\n",
      "Iteration 74, inertia 26534.287109375.\n",
      "Iteration 75, inertia 26534.263671875.\n",
      "Iteration 76, inertia 26534.251953125.\n",
      "Iteration 77, inertia 26534.236328125.\n",
      "Iteration 78, inertia 26534.224609375.\n",
      "Iteration 79, inertia 26534.2109375.\n",
      "Iteration 80, inertia 26534.1875.\n",
      "Iteration 81, inertia 26534.181640625.\n",
      "Iteration 82, inertia 26534.16796875.\n",
      "Iteration 83, inertia 26534.15625.\n",
      "Iteration 84, inertia 26534.146484375.\n",
      "Iteration 85, inertia 26534.1484375.\n",
      "Converged at iteration 85: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41928.90234375.\n",
      "Iteration 1, inertia 27925.740234375.\n",
      "Iteration 2, inertia 27323.49609375.\n",
      "Iteration 3, inertia 27109.126953125.\n",
      "Iteration 4, inertia 26991.896484375.\n",
      "Iteration 5, inertia 26914.66015625.\n",
      "Iteration 6, inertia 26855.662109375.\n",
      "Iteration 7, inertia 26813.4921875.\n",
      "Iteration 8, inertia 26779.953125.\n",
      "Iteration 9, inertia 26755.369140625.\n",
      "Iteration 10, inertia 26736.546875.\n",
      "Iteration 11, inertia 26719.060546875.\n",
      "Iteration 12, inertia 26704.7734375.\n",
      "Iteration 13, inertia 26693.451171875.\n",
      "Iteration 14, inertia 26683.923828125.\n",
      "Iteration 15, inertia 26675.619140625.\n",
      "Iteration 16, inertia 26669.40625.\n",
      "Iteration 17, inertia 26664.28515625.\n",
      "Iteration 18, inertia 26659.26953125.\n",
      "Iteration 19, inertia 26654.435546875.\n",
      "Iteration 20, inertia 26650.6484375.\n",
      "Iteration 21, inertia 26647.1328125.\n",
      "Iteration 22, inertia 26643.841796875.\n",
      "Iteration 23, inertia 26640.802734375.\n",
      "Iteration 24, inertia 26637.916015625.\n",
      "Iteration 25, inertia 26634.6484375.\n",
      "Iteration 26, inertia 26631.095703125.\n",
      "Iteration 27, inertia 26627.720703125.\n",
      "Iteration 28, inertia 26625.509765625.\n",
      "Iteration 29, inertia 26624.087890625.\n",
      "Iteration 30, inertia 26623.001953125.\n",
      "Iteration 31, inertia 26622.119140625.\n",
      "Iteration 32, inertia 26621.283203125.\n",
      "Iteration 33, inertia 26620.6015625.\n",
      "Iteration 34, inertia 26620.021484375.\n",
      "Iteration 35, inertia 26619.416015625.\n",
      "Iteration 36, inertia 26618.998046875.\n",
      "Iteration 37, inertia 26618.5859375.\n",
      "Iteration 38, inertia 26618.138671875.\n",
      "Iteration 39, inertia 26617.728515625.\n",
      "Iteration 40, inertia 26617.349609375.\n",
      "Iteration 41, inertia 26616.998046875.\n",
      "Iteration 42, inertia 26616.65234375.\n",
      "Iteration 43, inertia 26616.224609375.\n",
      "Iteration 44, inertia 26615.693359375.\n",
      "Iteration 45, inertia 26615.173828125.\n",
      "Iteration 46, inertia 26614.767578125.\n",
      "Iteration 47, inertia 26614.361328125.\n",
      "Iteration 48, inertia 26613.83984375.\n",
      "Iteration 49, inertia 26613.083984375.\n",
      "Iteration 50, inertia 26612.361328125.\n",
      "Iteration 51, inertia 26611.783203125.\n",
      "Iteration 52, inertia 26611.38671875.\n",
      "Iteration 53, inertia 26611.1328125.\n",
      "Iteration 54, inertia 26610.876953125.\n",
      "Iteration 55, inertia 26610.642578125.\n",
      "Iteration 56, inertia 26610.466796875.\n",
      "Iteration 57, inertia 26610.2890625.\n",
      "Iteration 58, inertia 26610.126953125.\n",
      "Iteration 59, inertia 26609.931640625.\n",
      "Iteration 60, inertia 26609.767578125.\n",
      "Iteration 61, inertia 26609.6328125.\n",
      "Iteration 62, inertia 26609.513671875.\n",
      "Iteration 63, inertia 26609.400390625.\n",
      "Iteration 64, inertia 26609.279296875.\n",
      "Iteration 65, inertia 26609.1796875.\n",
      "Iteration 66, inertia 26609.111328125.\n",
      "Iteration 67, inertia 26609.044921875.\n",
      "Iteration 68, inertia 26609.005859375.\n",
      "Iteration 69, inertia 26608.95703125.\n",
      "Iteration 70, inertia 26608.900390625.\n",
      "Iteration 71, inertia 26608.849609375.\n",
      "Iteration 72, inertia 26608.810546875.\n",
      "Iteration 73, inertia 26608.763671875.\n",
      "Iteration 74, inertia 26608.734375.\n",
      "Iteration 75, inertia 26608.716796875.\n",
      "Iteration 76, inertia 26608.693359375.\n",
      "Iteration 77, inertia 26608.642578125.\n",
      "Iteration 78, inertia 26608.595703125.\n",
      "Iteration 79, inertia 26608.54296875.\n",
      "Iteration 80, inertia 26608.501953125.\n",
      "Iteration 81, inertia 26608.392578125.\n",
      "Iteration 82, inertia 26608.2578125.\n",
      "Iteration 83, inertia 26608.126953125.\n",
      "Iteration 84, inertia 26607.884765625.\n",
      "Iteration 85, inertia 26607.58203125.\n",
      "Iteration 86, inertia 26607.29296875.\n",
      "Iteration 87, inertia 26606.9140625.\n",
      "Iteration 88, inertia 26606.54296875.\n",
      "Iteration 89, inertia 26606.193359375.\n",
      "Iteration 90, inertia 26605.857421875.\n",
      "Iteration 91, inertia 26605.5390625.\n",
      "Iteration 92, inertia 26605.28515625.\n",
      "Iteration 93, inertia 26605.162109375.\n",
      "Iteration 94, inertia 26605.048828125.\n",
      "Iteration 95, inertia 26605.009765625.\n",
      "Iteration 96, inertia 26604.978515625.\n",
      "Iteration 97, inertia 26604.947265625.\n",
      "Iteration 98, inertia 26604.896484375.\n",
      "Iteration 99, inertia 26604.865234375.\n",
      "Iteration 100, inertia 26604.841796875.\n",
      "Iteration 101, inertia 26604.822265625.\n",
      "Iteration 102, inertia 26604.80859375.\n",
      "Iteration 103, inertia 26604.791015625.\n",
      "Iteration 104, inertia 26604.78515625.\n",
      "Iteration 105, inertia 26604.78125.\n",
      "Converged at iteration 105: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42159.84375.\n",
      "Iteration 1, inertia 27963.458984375.\n",
      "Iteration 2, inertia 27339.64453125.\n",
      "Iteration 3, inertia 27112.283203125.\n",
      "Iteration 4, inertia 26974.380859375.\n",
      "Iteration 5, inertia 26884.162109375.\n",
      "Iteration 6, inertia 26824.1640625.\n",
      "Iteration 7, inertia 26778.896484375.\n",
      "Iteration 8, inertia 26745.3359375.\n",
      "Iteration 9, inertia 26721.513671875.\n",
      "Iteration 10, inertia 26703.947265625.\n",
      "Iteration 11, inertia 26688.70703125.\n",
      "Iteration 12, inertia 26675.6328125.\n",
      "Iteration 13, inertia 26662.771484375.\n",
      "Iteration 14, inertia 26649.244140625.\n",
      "Iteration 15, inertia 26637.505859375.\n",
      "Iteration 16, inertia 26629.5625.\n",
      "Iteration 17, inertia 26623.564453125.\n",
      "Iteration 18, inertia 26618.59765625.\n",
      "Iteration 19, inertia 26614.33203125.\n",
      "Iteration 20, inertia 26610.798828125.\n",
      "Iteration 21, inertia 26607.61328125.\n",
      "Iteration 22, inertia 26605.029296875.\n",
      "Iteration 23, inertia 26602.6796875.\n",
      "Iteration 24, inertia 26600.470703125.\n",
      "Iteration 25, inertia 26598.615234375.\n",
      "Iteration 26, inertia 26596.951171875.\n",
      "Iteration 27, inertia 26595.759765625.\n",
      "Iteration 28, inertia 26594.80859375.\n",
      "Iteration 29, inertia 26593.875.\n",
      "Iteration 30, inertia 26592.927734375.\n",
      "Iteration 31, inertia 26592.056640625.\n",
      "Iteration 32, inertia 26591.228515625.\n",
      "Iteration 33, inertia 26590.521484375.\n",
      "Iteration 34, inertia 26589.798828125.\n",
      "Iteration 35, inertia 26589.1640625.\n",
      "Iteration 36, inertia 26588.53125.\n",
      "Iteration 37, inertia 26588.0234375.\n",
      "Iteration 38, inertia 26587.421875.\n",
      "Iteration 39, inertia 26586.728515625.\n",
      "Iteration 40, inertia 26585.9765625.\n",
      "Iteration 41, inertia 26585.4453125.\n",
      "Iteration 42, inertia 26584.9296875.\n",
      "Iteration 43, inertia 26584.39453125.\n",
      "Iteration 44, inertia 26583.76171875.\n",
      "Iteration 45, inertia 26583.146484375.\n",
      "Iteration 46, inertia 26582.7578125.\n",
      "Iteration 47, inertia 26582.3203125.\n",
      "Iteration 48, inertia 26582.02734375.\n",
      "Iteration 49, inertia 26581.904296875.\n",
      "Iteration 50, inertia 26581.833984375.\n",
      "Iteration 51, inertia 26581.77734375.\n",
      "Iteration 52, inertia 26581.75390625.\n",
      "Iteration 53, inertia 26581.71875.\n",
      "Iteration 54, inertia 26581.666015625.\n",
      "Iteration 55, inertia 26581.626953125.\n",
      "Iteration 56, inertia 26581.59765625.\n",
      "Iteration 57, inertia 26581.57421875.\n",
      "Iteration 58, inertia 26581.537109375.\n",
      "Iteration 59, inertia 26581.48828125.\n",
      "Iteration 60, inertia 26581.4609375.\n",
      "Iteration 61, inertia 26581.443359375.\n",
      "Iteration 62, inertia 26581.421875.\n",
      "Iteration 63, inertia 26581.3984375.\n",
      "Iteration 64, inertia 26581.39453125.\n",
      "Iteration 65, inertia 26581.390625.\n",
      "Iteration 66, inertia 26581.388671875.\n",
      "Iteration 67, inertia 26581.375.\n",
      "Iteration 68, inertia 26581.359375.\n",
      "Iteration 69, inertia 26581.345703125.\n",
      "Iteration 70, inertia 26581.328125.\n",
      "Iteration 71, inertia 26581.318359375.\n",
      "Iteration 72, inertia 26581.29296875.\n",
      "Iteration 73, inertia 26581.27734375.\n",
      "Iteration 74, inertia 26581.2578125.\n",
      "Iteration 75, inertia 26581.24609375.\n",
      "Iteration 76, inertia 26581.248046875.\n",
      "Iteration 77, inertia 26581.248046875.\n",
      "Iteration 78, inertia 26581.244140625.\n",
      "Iteration 79, inertia 26581.244140625.\n",
      "Iteration 80, inertia 26581.234375.\n",
      "Converged at iteration 80: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41863.58203125.\n",
      "Iteration 1, inertia 28025.44140625.\n",
      "Iteration 2, inertia 27384.51953125.\n",
      "Iteration 3, inertia 27141.033203125.\n",
      "Iteration 4, inertia 27005.595703125.\n",
      "Iteration 5, inertia 26913.291015625.\n",
      "Iteration 6, inertia 26850.921875.\n",
      "Iteration 7, inertia 26805.095703125.\n",
      "Iteration 8, inertia 26766.90234375.\n",
      "Iteration 9, inertia 26734.759765625.\n",
      "Iteration 10, inertia 26710.298828125.\n",
      "Iteration 11, inertia 26693.189453125.\n",
      "Iteration 12, inertia 26680.69921875.\n",
      "Iteration 13, inertia 26670.361328125.\n",
      "Iteration 14, inertia 26661.0625.\n",
      "Iteration 15, inertia 26652.970703125.\n",
      "Iteration 16, inertia 26645.84765625.\n",
      "Iteration 17, inertia 26639.16796875.\n",
      "Iteration 18, inertia 26632.41796875.\n",
      "Iteration 19, inertia 26625.396484375.\n",
      "Iteration 20, inertia 26619.2265625.\n",
      "Iteration 21, inertia 26613.64453125.\n",
      "Iteration 22, inertia 26607.916015625.\n",
      "Iteration 23, inertia 26599.767578125.\n",
      "Iteration 24, inertia 26591.8046875.\n",
      "Iteration 25, inertia 26586.689453125.\n",
      "Iteration 26, inertia 26582.919921875.\n",
      "Iteration 27, inertia 26580.20703125.\n",
      "Iteration 28, inertia 26577.62109375.\n",
      "Iteration 29, inertia 26575.353515625.\n",
      "Iteration 30, inertia 26573.41796875.\n",
      "Iteration 31, inertia 26571.703125.\n",
      "Iteration 32, inertia 26569.904296875.\n",
      "Iteration 33, inertia 26568.619140625.\n",
      "Iteration 34, inertia 26567.650390625.\n",
      "Iteration 35, inertia 26566.775390625.\n",
      "Iteration 36, inertia 26566.05078125.\n",
      "Iteration 37, inertia 26565.349609375.\n",
      "Iteration 38, inertia 26564.5625.\n",
      "Iteration 39, inertia 26563.916015625.\n",
      "Iteration 40, inertia 26563.24609375.\n",
      "Iteration 41, inertia 26562.474609375.\n",
      "Iteration 42, inertia 26561.79296875.\n",
      "Iteration 43, inertia 26560.998046875.\n",
      "Iteration 44, inertia 26560.18359375.\n",
      "Iteration 45, inertia 26559.43359375.\n",
      "Iteration 46, inertia 26558.9375.\n",
      "Iteration 47, inertia 26558.6328125.\n",
      "Iteration 48, inertia 26558.427734375.\n",
      "Iteration 49, inertia 26558.29296875.\n",
      "Iteration 50, inertia 26558.140625.\n",
      "Iteration 51, inertia 26558.01171875.\n",
      "Iteration 52, inertia 26557.904296875.\n",
      "Iteration 53, inertia 26557.80859375.\n",
      "Iteration 54, inertia 26557.73828125.\n",
      "Iteration 55, inertia 26557.685546875.\n",
      "Iteration 56, inertia 26557.658203125.\n",
      "Iteration 57, inertia 26557.638671875.\n",
      "Iteration 58, inertia 26557.619140625.\n",
      "Iteration 59, inertia 26557.6015625.\n",
      "Iteration 60, inertia 26557.58984375.\n",
      "Iteration 61, inertia 26557.56640625.\n",
      "Iteration 62, inertia 26557.564453125.\n",
      "Iteration 63, inertia 26557.55859375.\n",
      "Iteration 64, inertia 26557.560546875.\n",
      "Iteration 65, inertia 26557.55078125.\n",
      "Converged at iteration 65: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42000.515625.\n",
      "Iteration 1, inertia 27927.890625.\n",
      "Iteration 2, inertia 27303.77734375.\n",
      "Iteration 3, inertia 27063.01171875.\n",
      "Iteration 4, inertia 26919.150390625.\n",
      "Iteration 5, inertia 26833.01171875.\n",
      "Iteration 6, inertia 26782.876953125.\n",
      "Iteration 7, inertia 26751.26171875.\n",
      "Iteration 8, inertia 26728.13671875.\n",
      "Iteration 9, inertia 26710.04296875.\n",
      "Iteration 10, inertia 26694.650390625.\n",
      "Iteration 11, inertia 26681.423828125.\n",
      "Iteration 12, inertia 26669.0.\n",
      "Iteration 13, inertia 26656.537109375.\n",
      "Iteration 14, inertia 26642.9375.\n",
      "Iteration 15, inertia 26629.5703125.\n",
      "Iteration 16, inertia 26618.517578125.\n",
      "Iteration 17, inertia 26609.658203125.\n",
      "Iteration 18, inertia 26603.3046875.\n",
      "Iteration 19, inertia 26597.861328125.\n",
      "Iteration 20, inertia 26593.080078125.\n",
      "Iteration 21, inertia 26588.82421875.\n",
      "Iteration 22, inertia 26585.611328125.\n",
      "Iteration 23, inertia 26582.751953125.\n",
      "Iteration 24, inertia 26579.990234375.\n",
      "Iteration 25, inertia 26576.94921875.\n",
      "Iteration 26, inertia 26573.646484375.\n",
      "Iteration 27, inertia 26569.609375.\n",
      "Iteration 28, inertia 26566.56640625.\n",
      "Iteration 29, inertia 26563.8671875.\n",
      "Iteration 30, inertia 26561.041015625.\n",
      "Iteration 31, inertia 26558.447265625.\n",
      "Iteration 32, inertia 26556.390625.\n",
      "Iteration 33, inertia 26554.8515625.\n",
      "Iteration 34, inertia 26553.625.\n",
      "Iteration 35, inertia 26552.2734375.\n",
      "Iteration 36, inertia 26550.990234375.\n",
      "Iteration 37, inertia 26550.068359375.\n",
      "Iteration 38, inertia 26549.37890625.\n",
      "Iteration 39, inertia 26548.734375.\n",
      "Iteration 40, inertia 26548.15234375.\n",
      "Iteration 41, inertia 26547.52734375.\n",
      "Iteration 42, inertia 26546.8828125.\n",
      "Iteration 43, inertia 26545.869140625.\n",
      "Iteration 44, inertia 26544.6484375.\n",
      "Iteration 45, inertia 26543.724609375.\n",
      "Iteration 46, inertia 26543.140625.\n",
      "Iteration 47, inertia 26542.798828125.\n",
      "Iteration 48, inertia 26542.509765625.\n",
      "Iteration 49, inertia 26542.154296875.\n",
      "Iteration 50, inertia 26541.63671875.\n",
      "Iteration 51, inertia 26540.83984375.\n",
      "Iteration 52, inertia 26540.080078125.\n",
      "Iteration 53, inertia 26539.560546875.\n",
      "Iteration 54, inertia 26539.064453125.\n",
      "Iteration 55, inertia 26538.287109375.\n",
      "Iteration 56, inertia 26537.240234375.\n",
      "Iteration 57, inertia 26535.958984375.\n",
      "Iteration 58, inertia 26534.962890625.\n",
      "Iteration 59, inertia 26534.265625.\n",
      "Iteration 60, inertia 26533.703125.\n",
      "Iteration 61, inertia 26533.283203125.\n",
      "Iteration 62, inertia 26532.873046875.\n",
      "Iteration 63, inertia 26532.453125.\n",
      "Iteration 64, inertia 26532.087890625.\n",
      "Iteration 65, inertia 26531.716796875.\n",
      "Iteration 66, inertia 26531.44140625.\n",
      "Iteration 67, inertia 26531.197265625.\n",
      "Iteration 68, inertia 26530.87109375.\n",
      "Iteration 69, inertia 26530.46484375.\n",
      "Iteration 70, inertia 26529.91015625.\n",
      "Iteration 71, inertia 26529.228515625.\n",
      "Iteration 72, inertia 26527.8203125.\n",
      "Iteration 73, inertia 26526.01171875.\n",
      "Iteration 74, inertia 26525.330078125.\n",
      "Iteration 75, inertia 26524.8046875.\n",
      "Iteration 76, inertia 26524.5234375.\n",
      "Iteration 77, inertia 26524.146484375.\n",
      "Iteration 78, inertia 26523.474609375.\n",
      "Iteration 79, inertia 26522.748046875.\n",
      "Iteration 80, inertia 26522.169921875.\n",
      "Iteration 81, inertia 26521.734375.\n",
      "Iteration 82, inertia 26521.392578125.\n",
      "Iteration 83, inertia 26521.197265625.\n",
      "Iteration 84, inertia 26521.095703125.\n",
      "Iteration 85, inertia 26521.05078125.\n",
      "Iteration 86, inertia 26521.025390625.\n",
      "Iteration 87, inertia 26521.021484375.\n",
      "Iteration 88, inertia 26521.015625.\n",
      "Converged at iteration 88: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42221.828125.\n",
      "Iteration 1, inertia 28058.876953125.\n",
      "Iteration 2, inertia 27422.625.\n",
      "Iteration 3, inertia 27183.130859375.\n",
      "Iteration 4, inertia 27048.5859375.\n",
      "Iteration 5, inertia 26957.6875.\n",
      "Iteration 6, inertia 26889.40234375.\n",
      "Iteration 7, inertia 26836.482421875.\n",
      "Iteration 8, inertia 26790.9296875.\n",
      "Iteration 9, inertia 26750.9453125.\n",
      "Iteration 10, inertia 26717.95703125.\n",
      "Iteration 11, inertia 26692.63671875.\n",
      "Iteration 12, inertia 26674.248046875.\n",
      "Iteration 13, inertia 26660.126953125.\n",
      "Iteration 14, inertia 26649.33984375.\n",
      "Iteration 15, inertia 26640.19921875.\n",
      "Iteration 16, inertia 26632.181640625.\n",
      "Iteration 17, inertia 26626.099609375.\n",
      "Iteration 18, inertia 26621.212890625.\n",
      "Iteration 19, inertia 26616.708984375.\n",
      "Iteration 20, inertia 26612.06640625.\n",
      "Iteration 21, inertia 26607.005859375.\n",
      "Iteration 22, inertia 26602.849609375.\n",
      "Iteration 23, inertia 26598.23828125.\n",
      "Iteration 24, inertia 26594.205078125.\n",
      "Iteration 25, inertia 26591.1015625.\n",
      "Iteration 26, inertia 26589.13671875.\n",
      "Iteration 27, inertia 26587.34765625.\n",
      "Iteration 28, inertia 26585.646484375.\n",
      "Iteration 29, inertia 26584.033203125.\n",
      "Iteration 30, inertia 26582.572265625.\n",
      "Iteration 31, inertia 26581.29296875.\n",
      "Iteration 32, inertia 26580.208984375.\n",
      "Iteration 33, inertia 26579.296875.\n",
      "Iteration 34, inertia 26578.498046875.\n",
      "Iteration 35, inertia 26577.775390625.\n",
      "Iteration 36, inertia 26577.08203125.\n",
      "Iteration 37, inertia 26576.392578125.\n",
      "Iteration 38, inertia 26575.640625.\n",
      "Iteration 39, inertia 26574.82421875.\n",
      "Iteration 40, inertia 26573.880859375.\n",
      "Iteration 41, inertia 26572.8984375.\n",
      "Iteration 42, inertia 26572.029296875.\n",
      "Iteration 43, inertia 26571.470703125.\n",
      "Iteration 44, inertia 26571.052734375.\n",
      "Iteration 45, inertia 26570.70703125.\n",
      "Iteration 46, inertia 26570.314453125.\n",
      "Iteration 47, inertia 26569.923828125.\n",
      "Iteration 48, inertia 26569.58203125.\n",
      "Iteration 49, inertia 26569.181640625.\n",
      "Iteration 50, inertia 26568.66015625.\n",
      "Iteration 51, inertia 26568.08984375.\n",
      "Iteration 52, inertia 26567.470703125.\n",
      "Iteration 53, inertia 26566.6640625.\n",
      "Iteration 54, inertia 26565.986328125.\n",
      "Iteration 55, inertia 26565.44140625.\n",
      "Iteration 56, inertia 26565.158203125.\n",
      "Iteration 57, inertia 26564.93359375.\n",
      "Iteration 58, inertia 26564.65234375.\n",
      "Iteration 59, inertia 26564.400390625.\n",
      "Iteration 60, inertia 26564.23828125.\n",
      "Iteration 61, inertia 26564.072265625.\n",
      "Iteration 62, inertia 26563.94140625.\n",
      "Iteration 63, inertia 26563.798828125.\n",
      "Iteration 64, inertia 26563.658203125.\n",
      "Iteration 65, inertia 26563.5546875.\n",
      "Iteration 66, inertia 26563.455078125.\n",
      "Iteration 67, inertia 26563.3515625.\n",
      "Iteration 68, inertia 26563.244140625.\n",
      "Iteration 69, inertia 26563.166015625.\n",
      "Iteration 70, inertia 26563.111328125.\n",
      "Iteration 71, inertia 26563.0390625.\n",
      "Iteration 72, inertia 26562.94921875.\n",
      "Iteration 73, inertia 26562.791015625.\n",
      "Iteration 74, inertia 26562.5546875.\n",
      "Iteration 75, inertia 26562.333984375.\n",
      "Iteration 76, inertia 26562.015625.\n",
      "Iteration 77, inertia 26561.638671875.\n",
      "Iteration 78, inertia 26561.32421875.\n",
      "Iteration 79, inertia 26561.03125.\n",
      "Iteration 80, inertia 26560.78515625.\n",
      "Iteration 81, inertia 26560.4609375.\n",
      "Iteration 82, inertia 26560.287109375.\n",
      "Iteration 83, inertia 26560.166015625.\n",
      "Iteration 84, inertia 26560.095703125.\n",
      "Iteration 85, inertia 26560.021484375.\n",
      "Iteration 86, inertia 26559.947265625.\n",
      "Iteration 87, inertia 26559.89453125.\n",
      "Iteration 88, inertia 26559.84765625.\n",
      "Iteration 89, inertia 26559.7890625.\n",
      "Iteration 90, inertia 26559.767578125.\n",
      "Iteration 91, inertia 26559.74609375.\n",
      "Iteration 92, inertia 26559.736328125.\n",
      "Iteration 93, inertia 26559.716796875.\n",
      "Iteration 94, inertia 26559.6953125.\n",
      "Iteration 95, inertia 26559.681640625.\n",
      "Iteration 96, inertia 26559.650390625.\n",
      "Iteration 97, inertia 26559.59375.\n",
      "Iteration 98, inertia 26559.52734375.\n",
      "Iteration 99, inertia 26559.421875.\n",
      "Iteration 100, inertia 26559.34375.\n",
      "Iteration 101, inertia 26559.25390625.\n",
      "Iteration 102, inertia 26559.18359375.\n",
      "Iteration 103, inertia 26559.134765625.\n",
      "Iteration 104, inertia 26559.076171875.\n",
      "Iteration 105, inertia 26559.041015625.\n",
      "Iteration 106, inertia 26559.01953125.\n",
      "Iteration 107, inertia 26559.00390625.\n",
      "Iteration 108, inertia 26558.96484375.\n",
      "Iteration 109, inertia 26558.9375.\n",
      "Iteration 110, inertia 26558.90625.\n",
      "Iteration 111, inertia 26558.89453125.\n",
      "Iteration 112, inertia 26558.890625.\n",
      "Iteration 113, inertia 26558.890625.\n",
      "Converged at iteration 113: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41655.3359375.\n",
      "Iteration 1, inertia 27985.46484375.\n",
      "Iteration 2, inertia 27359.810546875.\n",
      "Iteration 3, inertia 27110.685546875.\n",
      "Iteration 4, inertia 26973.66015625.\n",
      "Iteration 5, inertia 26884.529296875.\n",
      "Iteration 6, inertia 26823.158203125.\n",
      "Iteration 7, inertia 26779.400390625.\n",
      "Iteration 8, inertia 26747.505859375.\n",
      "Iteration 9, inertia 26720.48046875.\n",
      "Iteration 10, inertia 26697.943359375.\n",
      "Iteration 11, inertia 26681.04296875.\n",
      "Iteration 12, inertia 26667.73828125.\n",
      "Iteration 13, inertia 26658.03515625.\n",
      "Iteration 14, inertia 26650.04296875.\n",
      "Iteration 15, inertia 26643.05859375.\n",
      "Iteration 16, inertia 26636.828125.\n",
      "Iteration 17, inertia 26628.15234375.\n",
      "Iteration 18, inertia 26620.044921875.\n",
      "Iteration 19, inertia 26614.583984375.\n",
      "Iteration 20, inertia 26609.033203125.\n",
      "Iteration 21, inertia 26604.533203125.\n",
      "Iteration 22, inertia 26601.65234375.\n",
      "Iteration 23, inertia 26599.384765625.\n",
      "Iteration 24, inertia 26596.990234375.\n",
      "Iteration 25, inertia 26594.353515625.\n",
      "Iteration 26, inertia 26591.369140625.\n",
      "Iteration 27, inertia 26587.38671875.\n",
      "Iteration 28, inertia 26584.837890625.\n",
      "Iteration 29, inertia 26583.484375.\n",
      "Iteration 30, inertia 26582.376953125.\n",
      "Iteration 31, inertia 26581.3515625.\n",
      "Iteration 32, inertia 26580.37109375.\n",
      "Iteration 33, inertia 26579.248046875.\n",
      "Iteration 34, inertia 26578.162109375.\n",
      "Iteration 35, inertia 26577.1484375.\n",
      "Iteration 36, inertia 26576.359375.\n",
      "Iteration 37, inertia 26575.78125.\n",
      "Iteration 38, inertia 26575.390625.\n",
      "Iteration 39, inertia 26575.048828125.\n",
      "Iteration 40, inertia 26574.71484375.\n",
      "Iteration 41, inertia 26574.416015625.\n",
      "Iteration 42, inertia 26574.00390625.\n",
      "Iteration 43, inertia 26572.66796875.\n",
      "Iteration 44, inertia 26570.361328125.\n",
      "Iteration 45, inertia 26569.41796875.\n",
      "Iteration 46, inertia 26569.111328125.\n",
      "Iteration 47, inertia 26568.853515625.\n",
      "Iteration 48, inertia 26568.615234375.\n",
      "Iteration 49, inertia 26568.439453125.\n",
      "Iteration 50, inertia 26568.291015625.\n",
      "Iteration 51, inertia 26568.140625.\n",
      "Iteration 52, inertia 26567.986328125.\n",
      "Iteration 53, inertia 26567.736328125.\n",
      "Iteration 54, inertia 26567.3984375.\n",
      "Iteration 55, inertia 26566.7734375.\n",
      "Iteration 56, inertia 26565.96875.\n",
      "Iteration 57, inertia 26565.19921875.\n",
      "Iteration 58, inertia 26564.775390625.\n",
      "Iteration 59, inertia 26564.400390625.\n",
      "Iteration 60, inertia 26564.107421875.\n",
      "Iteration 61, inertia 26563.88671875.\n",
      "Iteration 62, inertia 26563.771484375.\n",
      "Iteration 63, inertia 26563.671875.\n",
      "Iteration 64, inertia 26563.55859375.\n",
      "Iteration 65, inertia 26563.474609375.\n",
      "Iteration 66, inertia 26563.376953125.\n",
      "Iteration 67, inertia 26563.29296875.\n",
      "Iteration 68, inertia 26563.197265625.\n",
      "Iteration 69, inertia 26563.09375.\n",
      "Iteration 70, inertia 26562.87890625.\n",
      "Iteration 71, inertia 26562.5.\n",
      "Iteration 72, inertia 26562.060546875.\n",
      "Iteration 73, inertia 26561.31640625.\n",
      "Iteration 74, inertia 26560.41015625.\n",
      "Iteration 75, inertia 26559.55859375.\n",
      "Iteration 76, inertia 26558.8125.\n",
      "Iteration 77, inertia 26558.19140625.\n",
      "Iteration 78, inertia 26557.66015625.\n",
      "Iteration 79, inertia 26557.259765625.\n",
      "Iteration 80, inertia 26556.833984375.\n",
      "Iteration 81, inertia 26556.529296875.\n",
      "Iteration 82, inertia 26556.24609375.\n",
      "Iteration 83, inertia 26555.8515625.\n",
      "Iteration 84, inertia 26555.2578125.\n",
      "Iteration 85, inertia 26554.568359375.\n",
      "Iteration 86, inertia 26553.939453125.\n",
      "Iteration 87, inertia 26553.271484375.\n",
      "Iteration 88, inertia 26552.767578125.\n",
      "Iteration 89, inertia 26552.404296875.\n",
      "Iteration 90, inertia 26552.138671875.\n",
      "Iteration 91, inertia 26551.869140625.\n",
      "Iteration 92, inertia 26551.685546875.\n",
      "Iteration 93, inertia 26551.55078125.\n",
      "Iteration 94, inertia 26551.46484375.\n",
      "Iteration 95, inertia 26551.40625.\n",
      "Iteration 96, inertia 26551.37109375.\n",
      "Iteration 97, inertia 26551.341796875.\n",
      "Iteration 98, inertia 26551.333984375.\n",
      "Iteration 99, inertia 26551.322265625.\n",
      "Iteration 100, inertia 26551.314453125.\n",
      "Iteration 101, inertia 26551.291015625.\n",
      "Iteration 102, inertia 26551.287109375.\n",
      "Iteration 103, inertia 26551.259765625.\n",
      "Iteration 104, inertia 26551.240234375.\n",
      "Iteration 105, inertia 26551.23046875.\n",
      "Iteration 106, inertia 26551.224609375.\n",
      "Iteration 107, inertia 26551.21875.\n",
      "Iteration 108, inertia 26551.216796875.\n",
      "Converged at iteration 108: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41820.62109375.\n",
      "Iteration 1, inertia 27997.888671875.\n",
      "Iteration 2, inertia 27422.986328125.\n",
      "Iteration 3, inertia 27194.212890625.\n",
      "Iteration 4, inertia 27053.58984375.\n",
      "Iteration 5, inertia 26953.48046875.\n",
      "Iteration 6, inertia 26884.1015625.\n",
      "Iteration 7, inertia 26834.0078125.\n",
      "Iteration 8, inertia 26793.693359375.\n",
      "Iteration 9, inertia 26763.62890625.\n",
      "Iteration 10, inertia 26740.7578125.\n",
      "Iteration 11, inertia 26719.869140625.\n",
      "Iteration 12, inertia 26699.185546875.\n",
      "Iteration 13, inertia 26680.4765625.\n",
      "Iteration 14, inertia 26664.57421875.\n",
      "Iteration 15, inertia 26653.349609375.\n",
      "Iteration 16, inertia 26644.4609375.\n",
      "Iteration 17, inertia 26637.09375.\n",
      "Iteration 18, inertia 26630.607421875.\n",
      "Iteration 19, inertia 26624.51171875.\n",
      "Iteration 20, inertia 26618.939453125.\n",
      "Iteration 21, inertia 26613.603515625.\n",
      "Iteration 22, inertia 26609.13671875.\n",
      "Iteration 23, inertia 26605.419921875.\n",
      "Iteration 24, inertia 26601.728515625.\n",
      "Iteration 25, inertia 26598.033203125.\n",
      "Iteration 26, inertia 26595.15625.\n",
      "Iteration 27, inertia 26592.861328125.\n",
      "Iteration 28, inertia 26591.08984375.\n",
      "Iteration 29, inertia 26589.7578125.\n",
      "Iteration 30, inertia 26588.60546875.\n",
      "Iteration 31, inertia 26587.35546875.\n",
      "Iteration 32, inertia 26585.3046875.\n",
      "Iteration 33, inertia 26583.185546875.\n",
      "Iteration 34, inertia 26582.203125.\n",
      "Iteration 35, inertia 26581.412109375.\n",
      "Iteration 36, inertia 26580.705078125.\n",
      "Iteration 37, inertia 26579.90234375.\n",
      "Iteration 38, inertia 26579.0546875.\n",
      "Iteration 39, inertia 26577.72265625.\n",
      "Iteration 40, inertia 26575.36328125.\n",
      "Iteration 41, inertia 26572.501953125.\n",
      "Iteration 42, inertia 26570.078125.\n",
      "Iteration 43, inertia 26568.8515625.\n",
      "Iteration 44, inertia 26568.234375.\n",
      "Iteration 45, inertia 26567.6171875.\n",
      "Iteration 46, inertia 26566.892578125.\n",
      "Iteration 47, inertia 26565.669921875.\n",
      "Iteration 48, inertia 26563.515625.\n",
      "Iteration 49, inertia 26561.669921875.\n",
      "Iteration 50, inertia 26561.09765625.\n",
      "Iteration 51, inertia 26560.53515625.\n",
      "Iteration 52, inertia 26559.685546875.\n",
      "Iteration 53, inertia 26558.3125.\n",
      "Iteration 54, inertia 26557.173828125.\n",
      "Iteration 55, inertia 26556.345703125.\n",
      "Iteration 56, inertia 26555.595703125.\n",
      "Iteration 57, inertia 26554.88671875.\n",
      "Iteration 58, inertia 26554.263671875.\n",
      "Iteration 59, inertia 26553.94140625.\n",
      "Iteration 60, inertia 26553.6796875.\n",
      "Iteration 61, inertia 26553.470703125.\n",
      "Iteration 62, inertia 26553.326171875.\n",
      "Iteration 63, inertia 26553.20703125.\n",
      "Iteration 64, inertia 26553.08203125.\n",
      "Iteration 65, inertia 26552.93359375.\n",
      "Iteration 66, inertia 26552.732421875.\n",
      "Iteration 67, inertia 26552.5234375.\n",
      "Iteration 68, inertia 26552.396484375.\n",
      "Iteration 69, inertia 26552.29296875.\n",
      "Iteration 70, inertia 26552.21484375.\n",
      "Iteration 71, inertia 26552.142578125.\n",
      "Iteration 72, inertia 26552.05078125.\n",
      "Iteration 73, inertia 26551.97265625.\n",
      "Iteration 74, inertia 26551.8828125.\n",
      "Iteration 75, inertia 26551.822265625.\n",
      "Iteration 76, inertia 26551.77734375.\n",
      "Iteration 77, inertia 26551.740234375.\n",
      "Iteration 78, inertia 26551.720703125.\n",
      "Converged at iteration 78: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41835.125.\n",
      "Iteration 1, inertia 28010.759765625.\n",
      "Iteration 2, inertia 27404.029296875.\n",
      "Iteration 3, inertia 27165.892578125.\n",
      "Iteration 4, inertia 27038.84765625.\n",
      "Iteration 5, inertia 26959.189453125.\n",
      "Iteration 6, inertia 26907.74609375.\n",
      "Iteration 7, inertia 26868.650390625.\n",
      "Iteration 8, inertia 26833.884765625.\n",
      "Iteration 9, inertia 26804.8671875.\n",
      "Iteration 10, inertia 26782.666015625.\n",
      "Iteration 11, inertia 26765.671875.\n",
      "Iteration 12, inertia 26751.76171875.\n",
      "Iteration 13, inertia 26738.603515625.\n",
      "Iteration 14, inertia 26727.12109375.\n",
      "Iteration 15, inertia 26715.544921875.\n",
      "Iteration 16, inertia 26705.615234375.\n",
      "Iteration 17, inertia 26696.75.\n",
      "Iteration 18, inertia 26689.39453125.\n",
      "Iteration 19, inertia 26682.205078125.\n",
      "Iteration 20, inertia 26675.330078125.\n",
      "Iteration 21, inertia 26669.576171875.\n",
      "Iteration 22, inertia 26665.064453125.\n",
      "Iteration 23, inertia 26661.498046875.\n",
      "Iteration 24, inertia 26658.583984375.\n",
      "Iteration 25, inertia 26655.9296875.\n",
      "Iteration 26, inertia 26653.220703125.\n",
      "Iteration 27, inertia 26650.09765625.\n",
      "Iteration 28, inertia 26646.9140625.\n",
      "Iteration 29, inertia 26643.869140625.\n",
      "Iteration 30, inertia 26640.779296875.\n",
      "Iteration 31, inertia 26637.251953125.\n",
      "Iteration 32, inertia 26632.5703125.\n",
      "Iteration 33, inertia 26627.259765625.\n",
      "Iteration 34, inertia 26623.314453125.\n",
      "Iteration 35, inertia 26620.095703125.\n",
      "Iteration 36, inertia 26617.080078125.\n",
      "Iteration 37, inertia 26614.365234375.\n",
      "Iteration 38, inertia 26611.640625.\n",
      "Iteration 39, inertia 26609.810546875.\n",
      "Iteration 40, inertia 26608.318359375.\n",
      "Iteration 41, inertia 26607.12890625.\n",
      "Iteration 42, inertia 26606.134765625.\n",
      "Iteration 43, inertia 26605.380859375.\n",
      "Iteration 44, inertia 26604.732421875.\n",
      "Iteration 45, inertia 26604.021484375.\n",
      "Iteration 46, inertia 26603.41796875.\n",
      "Iteration 47, inertia 26602.826171875.\n",
      "Iteration 48, inertia 26602.33984375.\n",
      "Iteration 49, inertia 26601.896484375.\n",
      "Iteration 50, inertia 26601.494140625.\n",
      "Iteration 51, inertia 26600.91796875.\n",
      "Iteration 52, inertia 26600.150390625.\n",
      "Iteration 53, inertia 26599.5390625.\n",
      "Iteration 54, inertia 26598.923828125.\n",
      "Iteration 55, inertia 26598.30078125.\n",
      "Iteration 56, inertia 26597.8671875.\n",
      "Iteration 57, inertia 26597.58984375.\n",
      "Iteration 58, inertia 26597.259765625.\n",
      "Iteration 59, inertia 26596.8828125.\n",
      "Iteration 60, inertia 26596.537109375.\n",
      "Iteration 61, inertia 26596.07421875.\n",
      "Iteration 62, inertia 26595.720703125.\n",
      "Iteration 63, inertia 26595.46875.\n",
      "Iteration 64, inertia 26595.291015625.\n",
      "Iteration 65, inertia 26595.171875.\n",
      "Iteration 66, inertia 26595.072265625.\n",
      "Iteration 67, inertia 26594.98828125.\n",
      "Iteration 68, inertia 26594.8984375.\n",
      "Iteration 69, inertia 26594.826171875.\n",
      "Iteration 70, inertia 26594.765625.\n",
      "Iteration 71, inertia 26594.728515625.\n",
      "Iteration 72, inertia 26594.693359375.\n",
      "Iteration 73, inertia 26594.65234375.\n",
      "Iteration 74, inertia 26594.609375.\n",
      "Iteration 75, inertia 26594.59375.\n",
      "Iteration 76, inertia 26594.560546875.\n",
      "Iteration 77, inertia 26594.525390625.\n",
      "Iteration 78, inertia 26594.48828125.\n",
      "Iteration 79, inertia 26594.462890625.\n",
      "Iteration 80, inertia 26594.44921875.\n",
      "Iteration 81, inertia 26594.43359375.\n",
      "Iteration 82, inertia 26594.4140625.\n",
      "Iteration 83, inertia 26594.400390625.\n",
      "Iteration 84, inertia 26594.388671875.\n",
      "Iteration 85, inertia 26594.375.\n",
      "Iteration 86, inertia 26594.357421875.\n",
      "Iteration 87, inertia 26594.3359375.\n",
      "Iteration 88, inertia 26594.3125.\n",
      "Iteration 89, inertia 26594.3046875.\n",
      "Iteration 90, inertia 26594.30859375.\n",
      "Iteration 91, inertia 26594.30078125.\n",
      "Iteration 92, inertia 26594.291015625.\n",
      "Iteration 93, inertia 26594.2890625.\n",
      "Iteration 94, inertia 26594.279296875.\n",
      "Iteration 95, inertia 26594.283203125.\n",
      "Converged at iteration 95: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41969.984375.\n",
      "Iteration 1, inertia 27888.236328125.\n",
      "Iteration 2, inertia 27301.55078125.\n",
      "Iteration 3, inertia 27076.447265625.\n",
      "Iteration 4, inertia 26943.5078125.\n",
      "Iteration 5, inertia 26861.572265625.\n",
      "Iteration 6, inertia 26809.107421875.\n",
      "Iteration 7, inertia 26770.109375.\n",
      "Iteration 8, inertia 26736.4765625.\n",
      "Iteration 9, inertia 26707.599609375.\n",
      "Iteration 10, inertia 26684.349609375.\n",
      "Iteration 11, inertia 26667.185546875.\n",
      "Iteration 12, inertia 26652.78125.\n",
      "Iteration 13, inertia 26642.046875.\n",
      "Iteration 14, inertia 26633.25.\n",
      "Iteration 15, inertia 26626.3359375.\n",
      "Iteration 16, inertia 26621.072265625.\n",
      "Iteration 17, inertia 26616.51953125.\n",
      "Iteration 18, inertia 26612.75390625.\n",
      "Iteration 19, inertia 26609.513671875.\n",
      "Iteration 20, inertia 26606.298828125.\n",
      "Iteration 21, inertia 26603.478515625.\n",
      "Iteration 22, inertia 26601.12109375.\n",
      "Iteration 23, inertia 26598.955078125.\n",
      "Iteration 24, inertia 26597.10546875.\n",
      "Iteration 25, inertia 26595.2734375.\n",
      "Iteration 26, inertia 26593.671875.\n",
      "Iteration 27, inertia 26592.150390625.\n",
      "Iteration 28, inertia 26590.626953125.\n",
      "Iteration 29, inertia 26589.021484375.\n",
      "Iteration 30, inertia 26587.2421875.\n",
      "Iteration 31, inertia 26585.263671875.\n",
      "Iteration 32, inertia 26582.8046875.\n",
      "Iteration 33, inertia 26577.939453125.\n",
      "Iteration 34, inertia 26573.1640625.\n",
      "Iteration 35, inertia 26569.900390625.\n",
      "Iteration 36, inertia 26567.8984375.\n",
      "Iteration 37, inertia 26566.052734375.\n",
      "Iteration 38, inertia 26564.130859375.\n",
      "Iteration 39, inertia 26562.328125.\n",
      "Iteration 40, inertia 26561.029296875.\n",
      "Iteration 41, inertia 26560.0859375.\n",
      "Iteration 42, inertia 26559.1875.\n",
      "Iteration 43, inertia 26558.4609375.\n",
      "Iteration 44, inertia 26557.6171875.\n",
      "Iteration 45, inertia 26556.6640625.\n",
      "Iteration 46, inertia 26555.669921875.\n",
      "Iteration 47, inertia 26554.671875.\n",
      "Iteration 48, inertia 26553.572265625.\n",
      "Iteration 49, inertia 26552.654296875.\n",
      "Iteration 50, inertia 26551.94140625.\n",
      "Iteration 51, inertia 26551.22265625.\n",
      "Iteration 52, inertia 26550.404296875.\n",
      "Iteration 53, inertia 26549.640625.\n",
      "Iteration 54, inertia 26549.029296875.\n",
      "Iteration 55, inertia 26548.494140625.\n",
      "Iteration 56, inertia 26548.083984375.\n",
      "Iteration 57, inertia 26547.69921875.\n",
      "Iteration 58, inertia 26547.361328125.\n",
      "Iteration 59, inertia 26547.033203125.\n",
      "Iteration 60, inertia 26546.80078125.\n",
      "Iteration 61, inertia 26546.626953125.\n",
      "Iteration 62, inertia 26546.443359375.\n",
      "Iteration 63, inertia 26546.22265625.\n",
      "Iteration 64, inertia 26546.03515625.\n",
      "Iteration 65, inertia 26545.84765625.\n",
      "Iteration 66, inertia 26545.671875.\n",
      "Iteration 67, inertia 26545.513671875.\n",
      "Iteration 68, inertia 26545.337890625.\n",
      "Iteration 69, inertia 26545.12890625.\n",
      "Iteration 70, inertia 26544.837890625.\n",
      "Iteration 71, inertia 26544.44140625.\n",
      "Iteration 72, inertia 26543.7734375.\n",
      "Iteration 73, inertia 26543.212890625.\n",
      "Iteration 74, inertia 26542.833984375.\n",
      "Iteration 75, inertia 26542.5625.\n",
      "Iteration 76, inertia 26542.322265625.\n",
      "Iteration 77, inertia 26542.095703125.\n",
      "Iteration 78, inertia 26541.8828125.\n",
      "Iteration 79, inertia 26541.697265625.\n",
      "Iteration 80, inertia 26541.474609375.\n",
      "Iteration 81, inertia 26541.259765625.\n",
      "Iteration 82, inertia 26541.083984375.\n",
      "Iteration 83, inertia 26540.9375.\n",
      "Iteration 84, inertia 26540.822265625.\n",
      "Iteration 85, inertia 26540.71875.\n",
      "Iteration 86, inertia 26540.63671875.\n",
      "Iteration 87, inertia 26540.5859375.\n",
      "Iteration 88, inertia 26540.505859375.\n",
      "Iteration 89, inertia 26540.447265625.\n",
      "Iteration 90, inertia 26540.376953125.\n",
      "Iteration 91, inertia 26540.322265625.\n",
      "Iteration 92, inertia 26540.24609375.\n",
      "Iteration 93, inertia 26540.189453125.\n",
      "Iteration 94, inertia 26540.103515625.\n",
      "Iteration 95, inertia 26540.025390625.\n",
      "Iteration 96, inertia 26539.962890625.\n",
      "Iteration 97, inertia 26539.908203125.\n",
      "Iteration 98, inertia 26539.8515625.\n",
      "Iteration 99, inertia 26539.810546875.\n",
      "Iteration 100, inertia 26539.7578125.\n",
      "Iteration 101, inertia 26539.671875.\n",
      "Iteration 102, inertia 26539.568359375.\n",
      "Iteration 103, inertia 26539.4296875.\n",
      "Iteration 104, inertia 26539.2890625.\n",
      "Iteration 105, inertia 26539.130859375.\n",
      "Iteration 106, inertia 26539.0390625.\n",
      "Iteration 107, inertia 26538.986328125.\n",
      "Iteration 108, inertia 26538.939453125.\n",
      "Iteration 109, inertia 26538.904296875.\n",
      "Iteration 110, inertia 26538.88671875.\n",
      "Iteration 111, inertia 26538.859375.\n",
      "Iteration 112, inertia 26538.830078125.\n",
      "Iteration 113, inertia 26538.818359375.\n",
      "Iteration 114, inertia 26538.791015625.\n",
      "Iteration 115, inertia 26538.76171875.\n",
      "Iteration 116, inertia 26538.70703125.\n",
      "Iteration 117, inertia 26538.619140625.\n",
      "Iteration 118, inertia 26538.5078125.\n",
      "Iteration 119, inertia 26538.404296875.\n",
      "Iteration 120, inertia 26538.29296875.\n",
      "Iteration 121, inertia 26538.123046875.\n",
      "Iteration 122, inertia 26537.953125.\n",
      "Iteration 123, inertia 26537.775390625.\n",
      "Iteration 124, inertia 26537.587890625.\n",
      "Iteration 125, inertia 26537.3984375.\n",
      "Iteration 126, inertia 26537.19921875.\n",
      "Iteration 127, inertia 26537.029296875.\n",
      "Iteration 128, inertia 26536.919921875.\n",
      "Iteration 129, inertia 26536.845703125.\n",
      "Iteration 130, inertia 26536.712890625.\n",
      "Iteration 131, inertia 26536.609375.\n",
      "Iteration 132, inertia 26536.5234375.\n",
      "Iteration 133, inertia 26536.419921875.\n",
      "Iteration 134, inertia 26536.2734375.\n",
      "Iteration 135, inertia 26536.1796875.\n",
      "Iteration 136, inertia 26536.126953125.\n",
      "Iteration 137, inertia 26536.044921875.\n",
      "Iteration 138, inertia 26535.9609375.\n",
      "Iteration 139, inertia 26535.904296875.\n",
      "Iteration 140, inertia 26535.8515625.\n",
      "Iteration 141, inertia 26535.802734375.\n",
      "Iteration 142, inertia 26535.79296875.\n",
      "Iteration 143, inertia 26535.783203125.\n",
      "Iteration 144, inertia 26535.783203125.\n",
      "Iteration 145, inertia 26535.77734375.\n",
      "Iteration 146, inertia 26535.77734375.\n",
      "Converged at iteration 146: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41965.44140625.\n",
      "Iteration 1, inertia 27860.02734375.\n",
      "Iteration 2, inertia 27289.134765625.\n",
      "Iteration 3, inertia 27068.115234375.\n",
      "Iteration 4, inertia 26944.638671875.\n",
      "Iteration 5, inertia 26864.994140625.\n",
      "Iteration 6, inertia 26803.984375.\n",
      "Iteration 7, inertia 26758.345703125.\n",
      "Iteration 8, inertia 26726.21875.\n",
      "Iteration 9, inertia 26704.76171875.\n",
      "Iteration 10, inertia 26688.87890625.\n",
      "Iteration 11, inertia 26675.998046875.\n",
      "Iteration 12, inertia 26665.66015625.\n",
      "Iteration 13, inertia 26656.7109375.\n",
      "Iteration 14, inertia 26648.015625.\n",
      "Iteration 15, inertia 26638.84765625.\n",
      "Iteration 16, inertia 26631.689453125.\n",
      "Iteration 17, inertia 26626.1171875.\n",
      "Iteration 18, inertia 26621.197265625.\n",
      "Iteration 19, inertia 26617.193359375.\n",
      "Iteration 20, inertia 26613.73828125.\n",
      "Iteration 21, inertia 26610.36328125.\n",
      "Iteration 22, inertia 26607.07421875.\n",
      "Iteration 23, inertia 26604.056640625.\n",
      "Iteration 24, inertia 26601.36328125.\n",
      "Iteration 25, inertia 26599.248046875.\n",
      "Iteration 26, inertia 26597.3671875.\n",
      "Iteration 27, inertia 26595.439453125.\n",
      "Iteration 28, inertia 26593.666015625.\n",
      "Iteration 29, inertia 26592.1171875.\n",
      "Iteration 30, inertia 26590.927734375.\n",
      "Iteration 31, inertia 26589.77734375.\n",
      "Iteration 32, inertia 26588.751953125.\n",
      "Iteration 33, inertia 26587.599609375.\n",
      "Iteration 34, inertia 26586.279296875.\n",
      "Iteration 35, inertia 26584.927734375.\n",
      "Iteration 36, inertia 26583.404296875.\n",
      "Iteration 37, inertia 26582.01171875.\n",
      "Iteration 38, inertia 26580.72265625.\n",
      "Iteration 39, inertia 26579.884765625.\n",
      "Iteration 40, inertia 26579.220703125.\n",
      "Iteration 41, inertia 26578.537109375.\n",
      "Iteration 42, inertia 26577.916015625.\n",
      "Iteration 43, inertia 26577.490234375.\n",
      "Iteration 44, inertia 26577.06640625.\n",
      "Iteration 45, inertia 26576.58203125.\n",
      "Iteration 46, inertia 26576.17578125.\n",
      "Iteration 47, inertia 26575.7734375.\n",
      "Iteration 48, inertia 26575.337890625.\n",
      "Iteration 49, inertia 26575.0390625.\n",
      "Iteration 50, inertia 26574.775390625.\n",
      "Iteration 51, inertia 26574.5390625.\n",
      "Iteration 52, inertia 26574.34765625.\n",
      "Iteration 53, inertia 26574.201171875.\n",
      "Iteration 54, inertia 26574.103515625.\n",
      "Iteration 55, inertia 26574.033203125.\n",
      "Iteration 56, inertia 26573.978515625.\n",
      "Iteration 57, inertia 26573.904296875.\n",
      "Iteration 58, inertia 26573.849609375.\n",
      "Iteration 59, inertia 26573.826171875.\n",
      "Iteration 60, inertia 26573.796875.\n",
      "Iteration 61, inertia 26573.7578125.\n",
      "Iteration 62, inertia 26573.728515625.\n",
      "Iteration 63, inertia 26573.6875.\n",
      "Iteration 64, inertia 26573.638671875.\n",
      "Iteration 65, inertia 26573.62890625.\n",
      "Iteration 66, inertia 26573.607421875.\n",
      "Iteration 67, inertia 26573.572265625.\n",
      "Iteration 68, inertia 26573.548828125.\n",
      "Iteration 69, inertia 26573.52734375.\n",
      "Iteration 70, inertia 26573.498046875.\n",
      "Iteration 71, inertia 26573.466796875.\n",
      "Iteration 72, inertia 26573.421875.\n",
      "Iteration 73, inertia 26573.38671875.\n",
      "Iteration 74, inertia 26573.322265625.\n",
      "Iteration 75, inertia 26573.283203125.\n",
      "Iteration 76, inertia 26573.2265625.\n",
      "Iteration 77, inertia 26573.1640625.\n",
      "Iteration 78, inertia 26573.05859375.\n",
      "Iteration 79, inertia 26572.96484375.\n",
      "Iteration 80, inertia 26572.873046875.\n",
      "Iteration 81, inertia 26572.81640625.\n",
      "Iteration 82, inertia 26572.75390625.\n",
      "Iteration 83, inertia 26572.705078125.\n",
      "Iteration 84, inertia 26572.66015625.\n",
      "Iteration 85, inertia 26572.599609375.\n",
      "Iteration 86, inertia 26572.55859375.\n",
      "Iteration 87, inertia 26572.513671875.\n",
      "Iteration 88, inertia 26572.4296875.\n",
      "Iteration 89, inertia 26572.296875.\n",
      "Iteration 90, inertia 26572.193359375.\n",
      "Iteration 91, inertia 26572.119140625.\n",
      "Iteration 92, inertia 26572.009765625.\n",
      "Iteration 93, inertia 26571.912109375.\n",
      "Iteration 94, inertia 26571.853515625.\n",
      "Iteration 95, inertia 26571.80078125.\n",
      "Iteration 96, inertia 26571.759765625.\n",
      "Iteration 97, inertia 26571.7265625.\n",
      "Iteration 98, inertia 26571.701171875.\n",
      "Iteration 99, inertia 26571.69921875.\n",
      "Iteration 100, inertia 26571.69921875.\n",
      "Iteration 101, inertia 26571.693359375.\n",
      "Iteration 102, inertia 26571.69921875.\n",
      "Converged at iteration 102: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41955.54296875.\n",
      "Iteration 1, inertia 27982.263671875.\n",
      "Iteration 2, inertia 27368.888671875.\n",
      "Iteration 3, inertia 27120.6015625.\n",
      "Iteration 4, inertia 26968.818359375.\n",
      "Iteration 5, inertia 26874.078125.\n",
      "Iteration 6, inertia 26813.32421875.\n",
      "Iteration 7, inertia 26773.037109375.\n",
      "Iteration 8, inertia 26742.9609375.\n",
      "Iteration 9, inertia 26718.83984375.\n",
      "Iteration 10, inertia 26700.087890625.\n",
      "Iteration 11, inertia 26683.076171875.\n",
      "Iteration 12, inertia 26661.986328125.\n",
      "Iteration 13, inertia 26639.1875.\n",
      "Iteration 14, inertia 26626.244140625.\n",
      "Iteration 15, inertia 26617.091796875.\n",
      "Iteration 16, inertia 26610.724609375.\n",
      "Iteration 17, inertia 26606.16796875.\n",
      "Iteration 18, inertia 26602.353515625.\n",
      "Iteration 19, inertia 26598.892578125.\n",
      "Iteration 20, inertia 26596.09765625.\n",
      "Iteration 21, inertia 26592.93359375.\n",
      "Iteration 22, inertia 26589.08984375.\n",
      "Iteration 23, inertia 26585.150390625.\n",
      "Iteration 24, inertia 26582.107421875.\n",
      "Iteration 25, inertia 26579.7421875.\n",
      "Iteration 26, inertia 26577.5703125.\n",
      "Iteration 27, inertia 26575.728515625.\n",
      "Iteration 28, inertia 26574.083984375.\n",
      "Iteration 29, inertia 26572.908203125.\n",
      "Iteration 30, inertia 26571.876953125.\n",
      "Iteration 31, inertia 26570.88671875.\n",
      "Iteration 32, inertia 26569.923828125.\n",
      "Iteration 33, inertia 26569.064453125.\n",
      "Iteration 34, inertia 26568.201171875.\n",
      "Iteration 35, inertia 26567.462890625.\n",
      "Iteration 36, inertia 26566.78125.\n",
      "Iteration 37, inertia 26566.244140625.\n",
      "Iteration 38, inertia 26565.83203125.\n",
      "Iteration 39, inertia 26565.560546875.\n",
      "Iteration 40, inertia 26565.330078125.\n",
      "Iteration 41, inertia 26565.033203125.\n",
      "Iteration 42, inertia 26564.703125.\n",
      "Iteration 43, inertia 26564.427734375.\n",
      "Iteration 44, inertia 26564.197265625.\n",
      "Iteration 45, inertia 26564.029296875.\n",
      "Iteration 46, inertia 26563.876953125.\n",
      "Iteration 47, inertia 26563.78125.\n",
      "Iteration 48, inertia 26563.662109375.\n",
      "Iteration 49, inertia 26563.53125.\n",
      "Iteration 50, inertia 26563.353515625.\n",
      "Iteration 51, inertia 26563.13671875.\n",
      "Iteration 52, inertia 26562.8828125.\n",
      "Iteration 53, inertia 26562.587890625.\n",
      "Iteration 54, inertia 26562.353515625.\n",
      "Iteration 55, inertia 26562.1796875.\n",
      "Iteration 56, inertia 26561.98046875.\n",
      "Iteration 57, inertia 26561.828125.\n",
      "Iteration 58, inertia 26561.69921875.\n",
      "Iteration 59, inertia 26561.544921875.\n",
      "Iteration 60, inertia 26561.416015625.\n",
      "Iteration 61, inertia 26561.310546875.\n",
      "Iteration 62, inertia 26561.22265625.\n",
      "Iteration 63, inertia 26561.166015625.\n",
      "Iteration 64, inertia 26561.1171875.\n",
      "Iteration 65, inertia 26561.072265625.\n",
      "Iteration 66, inertia 26561.033203125.\n",
      "Iteration 67, inertia 26560.986328125.\n",
      "Iteration 68, inertia 26560.91015625.\n",
      "Iteration 69, inertia 26560.755859375.\n",
      "Iteration 70, inertia 26560.626953125.\n",
      "Iteration 71, inertia 26560.51953125.\n",
      "Iteration 72, inertia 26560.4609375.\n",
      "Iteration 73, inertia 26560.421875.\n",
      "Iteration 74, inertia 26560.39453125.\n",
      "Iteration 75, inertia 26560.375.\n",
      "Iteration 76, inertia 26560.376953125.\n",
      "Iteration 77, inertia 26560.365234375.\n",
      "Iteration 78, inertia 26560.365234375.\n",
      "Iteration 79, inertia 26560.3671875.\n",
      "Iteration 80, inertia 26560.361328125.\n",
      "Converged at iteration 80: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41825.5625.\n",
      "Iteration 1, inertia 28022.412109375.\n",
      "Iteration 2, inertia 27389.009765625.\n",
      "Iteration 3, inertia 27126.54296875.\n",
      "Iteration 4, inertia 26979.541015625.\n",
      "Iteration 5, inertia 26893.880859375.\n",
      "Iteration 6, inertia 26835.5078125.\n",
      "Iteration 7, inertia 26792.53515625.\n",
      "Iteration 8, inertia 26755.65625.\n",
      "Iteration 9, inertia 26721.865234375.\n",
      "Iteration 10, inertia 26696.775390625.\n",
      "Iteration 11, inertia 26678.259765625.\n",
      "Iteration 12, inertia 26663.23046875.\n",
      "Iteration 13, inertia 26652.57421875.\n",
      "Iteration 14, inertia 26644.21875.\n",
      "Iteration 15, inertia 26636.599609375.\n",
      "Iteration 16, inertia 26628.8359375.\n",
      "Iteration 17, inertia 26620.28515625.\n",
      "Iteration 18, inertia 26611.916015625.\n",
      "Iteration 19, inertia 26603.921875.\n",
      "Iteration 20, inertia 26596.375.\n",
      "Iteration 21, inertia 26590.572265625.\n",
      "Iteration 22, inertia 26586.318359375.\n",
      "Iteration 23, inertia 26583.04296875.\n",
      "Iteration 24, inertia 26580.52734375.\n",
      "Iteration 25, inertia 26578.2578125.\n",
      "Iteration 26, inertia 26575.76171875.\n",
      "Iteration 27, inertia 26573.30859375.\n",
      "Iteration 28, inertia 26570.8828125.\n",
      "Iteration 29, inertia 26568.2109375.\n",
      "Iteration 30, inertia 26565.5078125.\n",
      "Iteration 31, inertia 26562.779296875.\n",
      "Iteration 32, inertia 26560.138671875.\n",
      "Iteration 33, inertia 26557.63671875.\n",
      "Iteration 34, inertia 26555.798828125.\n",
      "Iteration 35, inertia 26554.525390625.\n",
      "Iteration 36, inertia 26553.333984375.\n",
      "Iteration 37, inertia 26552.234375.\n",
      "Iteration 38, inertia 26551.29296875.\n",
      "Iteration 39, inertia 26550.109375.\n",
      "Iteration 40, inertia 26548.984375.\n",
      "Iteration 41, inertia 26547.9921875.\n",
      "Iteration 42, inertia 26547.248046875.\n",
      "Iteration 43, inertia 26546.69921875.\n",
      "Iteration 44, inertia 26546.396484375.\n",
      "Iteration 45, inertia 26546.1015625.\n",
      "Iteration 46, inertia 26545.83984375.\n",
      "Iteration 47, inertia 26545.685546875.\n",
      "Iteration 48, inertia 26545.54296875.\n",
      "Iteration 49, inertia 26545.40625.\n",
      "Iteration 50, inertia 26545.283203125.\n",
      "Iteration 51, inertia 26545.142578125.\n",
      "Iteration 52, inertia 26544.974609375.\n",
      "Iteration 53, inertia 26544.755859375.\n",
      "Iteration 54, inertia 26544.447265625.\n",
      "Iteration 55, inertia 26544.14453125.\n",
      "Iteration 56, inertia 26543.890625.\n",
      "Iteration 57, inertia 26543.583984375.\n",
      "Iteration 58, inertia 26543.287109375.\n",
      "Iteration 59, inertia 26543.048828125.\n",
      "Iteration 60, inertia 26542.84375.\n",
      "Iteration 61, inertia 26542.69921875.\n",
      "Iteration 62, inertia 26542.57421875.\n",
      "Iteration 63, inertia 26542.455078125.\n",
      "Iteration 64, inertia 26542.3515625.\n",
      "Iteration 65, inertia 26542.244140625.\n",
      "Iteration 66, inertia 26542.173828125.\n",
      "Iteration 67, inertia 26542.115234375.\n",
      "Iteration 68, inertia 26542.07421875.\n",
      "Iteration 69, inertia 26541.998046875.\n",
      "Iteration 70, inertia 26541.9375.\n",
      "Iteration 71, inertia 26541.900390625.\n",
      "Iteration 72, inertia 26541.876953125.\n",
      "Iteration 73, inertia 26541.853515625.\n",
      "Iteration 74, inertia 26541.814453125.\n",
      "Iteration 75, inertia 26541.779296875.\n",
      "Iteration 76, inertia 26541.75.\n",
      "Iteration 77, inertia 26541.712890625.\n",
      "Iteration 78, inertia 26541.681640625.\n",
      "Iteration 79, inertia 26541.654296875.\n",
      "Iteration 80, inertia 26541.603515625.\n",
      "Iteration 81, inertia 26541.580078125.\n",
      "Iteration 82, inertia 26541.57421875.\n",
      "Iteration 83, inertia 26541.564453125.\n",
      "Iteration 84, inertia 26541.544921875.\n",
      "Iteration 85, inertia 26541.537109375.\n",
      "Iteration 86, inertia 26541.53125.\n",
      "Converged at iteration 86: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42197.0859375.\n",
      "Iteration 1, inertia 27979.013671875.\n",
      "Iteration 2, inertia 27354.7421875.\n",
      "Iteration 3, inertia 27108.244140625.\n",
      "Iteration 4, inertia 26968.9921875.\n",
      "Iteration 5, inertia 26878.033203125.\n",
      "Iteration 6, inertia 26813.025390625.\n",
      "Iteration 7, inertia 26761.9765625.\n",
      "Iteration 8, inertia 26719.41796875.\n",
      "Iteration 9, inertia 26691.798828125.\n",
      "Iteration 10, inertia 26671.732421875.\n",
      "Iteration 11, inertia 26655.17578125.\n",
      "Iteration 12, inertia 26641.505859375.\n",
      "Iteration 13, inertia 26630.77734375.\n",
      "Iteration 14, inertia 26622.474609375.\n",
      "Iteration 15, inertia 26615.78125.\n",
      "Iteration 16, inertia 26609.849609375.\n",
      "Iteration 17, inertia 26604.580078125.\n",
      "Iteration 18, inertia 26599.91796875.\n",
      "Iteration 19, inertia 26594.59765625.\n",
      "Iteration 20, inertia 26588.7578125.\n",
      "Iteration 21, inertia 26583.3125.\n",
      "Iteration 22, inertia 26579.3046875.\n",
      "Iteration 23, inertia 26576.044921875.\n",
      "Iteration 24, inertia 26573.30078125.\n",
      "Iteration 25, inertia 26570.310546875.\n",
      "Iteration 26, inertia 26567.02734375.\n",
      "Iteration 27, inertia 26564.90234375.\n",
      "Iteration 28, inertia 26563.478515625.\n",
      "Iteration 29, inertia 26562.28515625.\n",
      "Iteration 30, inertia 26561.072265625.\n",
      "Iteration 31, inertia 26560.00390625.\n",
      "Iteration 32, inertia 26558.95703125.\n",
      "Iteration 33, inertia 26557.97265625.\n",
      "Iteration 34, inertia 26557.03125.\n",
      "Iteration 35, inertia 26556.1015625.\n",
      "Iteration 36, inertia 26555.392578125.\n",
      "Iteration 37, inertia 26554.873046875.\n",
      "Iteration 38, inertia 26554.42578125.\n",
      "Iteration 39, inertia 26554.01953125.\n",
      "Iteration 40, inertia 26553.6484375.\n",
      "Iteration 41, inertia 26553.2734375.\n",
      "Iteration 42, inertia 26552.8671875.\n",
      "Iteration 43, inertia 26552.296875.\n",
      "Iteration 44, inertia 26551.826171875.\n",
      "Iteration 45, inertia 26551.3203125.\n",
      "Iteration 46, inertia 26550.921875.\n",
      "Iteration 47, inertia 26550.599609375.\n",
      "Iteration 48, inertia 26550.26953125.\n",
      "Iteration 49, inertia 26549.962890625.\n",
      "Iteration 50, inertia 26549.736328125.\n",
      "Iteration 51, inertia 26549.546875.\n",
      "Iteration 52, inertia 26549.380859375.\n",
      "Iteration 53, inertia 26549.236328125.\n",
      "Iteration 54, inertia 26549.087890625.\n",
      "Iteration 55, inertia 26548.9296875.\n",
      "Iteration 56, inertia 26548.7421875.\n",
      "Iteration 57, inertia 26548.59375.\n",
      "Iteration 58, inertia 26548.4140625.\n",
      "Iteration 59, inertia 26548.232421875.\n",
      "Iteration 60, inertia 26548.0546875.\n",
      "Iteration 61, inertia 26547.89453125.\n",
      "Iteration 62, inertia 26547.71484375.\n",
      "Iteration 63, inertia 26547.54296875.\n",
      "Iteration 64, inertia 26547.419921875.\n",
      "Iteration 65, inertia 26547.294921875.\n",
      "Iteration 66, inertia 26547.21484375.\n",
      "Iteration 67, inertia 26547.142578125.\n",
      "Iteration 68, inertia 26547.03125.\n",
      "Iteration 69, inertia 26546.935546875.\n",
      "Iteration 70, inertia 26546.869140625.\n",
      "Iteration 71, inertia 26546.8515625.\n",
      "Iteration 72, inertia 26546.8203125.\n",
      "Iteration 73, inertia 26546.796875.\n",
      "Iteration 74, inertia 26546.7734375.\n",
      "Iteration 75, inertia 26546.763671875.\n",
      "Iteration 76, inertia 26546.744140625.\n",
      "Converged at iteration 76: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42208.21875.\n",
      "Iteration 1, inertia 27997.423828125.\n",
      "Iteration 2, inertia 27363.892578125.\n",
      "Iteration 3, inertia 27124.08203125.\n",
      "Iteration 4, inertia 27000.4765625.\n",
      "Iteration 5, inertia 26912.373046875.\n",
      "Iteration 6, inertia 26841.541015625.\n",
      "Iteration 7, inertia 26791.044921875.\n",
      "Iteration 8, inertia 26756.126953125.\n",
      "Iteration 9, inertia 26731.30078125.\n",
      "Iteration 10, inertia 26712.45703125.\n",
      "Iteration 11, inertia 26696.53515625.\n",
      "Iteration 12, inertia 26680.404296875.\n",
      "Iteration 13, inertia 26663.96484375.\n",
      "Iteration 14, inertia 26651.6171875.\n",
      "Iteration 15, inertia 26643.138671875.\n",
      "Iteration 16, inertia 26635.79296875.\n",
      "Iteration 17, inertia 26628.76953125.\n",
      "Iteration 18, inertia 26623.02734375.\n",
      "Iteration 19, inertia 26618.056640625.\n",
      "Iteration 20, inertia 26614.056640625.\n",
      "Iteration 21, inertia 26610.814453125.\n",
      "Iteration 22, inertia 26608.408203125.\n",
      "Iteration 23, inertia 26606.546875.\n",
      "Iteration 24, inertia 26604.962890625.\n",
      "Iteration 25, inertia 26603.609375.\n",
      "Iteration 26, inertia 26602.302734375.\n",
      "Iteration 27, inertia 26601.11328125.\n",
      "Iteration 28, inertia 26600.08984375.\n",
      "Iteration 29, inertia 26599.154296875.\n",
      "Iteration 30, inertia 26598.349609375.\n",
      "Iteration 31, inertia 26597.583984375.\n",
      "Iteration 32, inertia 26596.978515625.\n",
      "Iteration 33, inertia 26596.416015625.\n",
      "Iteration 34, inertia 26595.810546875.\n",
      "Iteration 35, inertia 26595.171875.\n",
      "Iteration 36, inertia 26594.505859375.\n",
      "Iteration 37, inertia 26593.60546875.\n",
      "Iteration 38, inertia 26592.63671875.\n",
      "Iteration 39, inertia 26591.45703125.\n",
      "Iteration 40, inertia 26590.59375.\n",
      "Iteration 41, inertia 26589.833984375.\n",
      "Iteration 42, inertia 26589.1328125.\n",
      "Iteration 43, inertia 26588.357421875.\n",
      "Iteration 44, inertia 26587.576171875.\n",
      "Iteration 45, inertia 26586.671875.\n",
      "Iteration 46, inertia 26585.58203125.\n",
      "Iteration 47, inertia 26584.634765625.\n",
      "Iteration 48, inertia 26583.84765625.\n",
      "Iteration 49, inertia 26583.123046875.\n",
      "Iteration 50, inertia 26582.5859375.\n",
      "Iteration 51, inertia 26582.2734375.\n",
      "Iteration 52, inertia 26582.060546875.\n",
      "Iteration 53, inertia 26581.841796875.\n",
      "Iteration 54, inertia 26581.662109375.\n",
      "Iteration 55, inertia 26581.509765625.\n",
      "Iteration 56, inertia 26581.404296875.\n",
      "Iteration 57, inertia 26581.3046875.\n",
      "Iteration 58, inertia 26581.169921875.\n",
      "Iteration 59, inertia 26581.08984375.\n",
      "Iteration 60, inertia 26580.974609375.\n",
      "Iteration 61, inertia 26580.78515625.\n",
      "Iteration 62, inertia 26580.619140625.\n",
      "Iteration 63, inertia 26580.384765625.\n",
      "Iteration 64, inertia 26580.09765625.\n",
      "Iteration 65, inertia 26579.900390625.\n",
      "Iteration 66, inertia 26579.7578125.\n",
      "Iteration 67, inertia 26579.630859375.\n",
      "Iteration 68, inertia 26579.486328125.\n",
      "Iteration 69, inertia 26579.34375.\n",
      "Iteration 70, inertia 26579.15234375.\n",
      "Iteration 71, inertia 26578.998046875.\n",
      "Iteration 72, inertia 26578.876953125.\n",
      "Iteration 73, inertia 26578.779296875.\n",
      "Iteration 74, inertia 26578.69140625.\n",
      "Iteration 75, inertia 26578.611328125.\n",
      "Iteration 76, inertia 26578.51953125.\n",
      "Iteration 77, inertia 26578.4765625.\n",
      "Iteration 78, inertia 26578.404296875.\n",
      "Iteration 79, inertia 26578.314453125.\n",
      "Iteration 80, inertia 26578.1484375.\n",
      "Iteration 81, inertia 26577.984375.\n",
      "Iteration 82, inertia 26577.859375.\n",
      "Iteration 83, inertia 26577.755859375.\n",
      "Iteration 84, inertia 26577.677734375.\n",
      "Iteration 85, inertia 26577.552734375.\n",
      "Iteration 86, inertia 26577.4609375.\n",
      "Iteration 87, inertia 26577.388671875.\n",
      "Iteration 88, inertia 26577.3359375.\n",
      "Iteration 89, inertia 26577.29296875.\n",
      "Iteration 90, inertia 26577.255859375.\n",
      "Iteration 91, inertia 26577.240234375.\n",
      "Iteration 92, inertia 26577.232421875.\n",
      "Iteration 93, inertia 26577.21484375.\n",
      "Iteration 94, inertia 26577.19921875.\n",
      "Iteration 95, inertia 26577.18359375.\n",
      "Iteration 96, inertia 26577.169921875.\n",
      "Iteration 97, inertia 26577.16796875.\n",
      "Converged at iteration 97: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41917.63671875.\n",
      "Iteration 1, inertia 27871.4140625.\n",
      "Iteration 2, inertia 27299.943359375.\n",
      "Iteration 3, inertia 27079.72265625.\n",
      "Iteration 4, inertia 26945.806640625.\n",
      "Iteration 5, inertia 26861.697265625.\n",
      "Iteration 6, inertia 26808.462890625.\n",
      "Iteration 7, inertia 26771.806640625.\n",
      "Iteration 8, inertia 26743.494140625.\n",
      "Iteration 9, inertia 26719.837890625.\n",
      "Iteration 10, inertia 26700.357421875.\n",
      "Iteration 11, inertia 26685.2421875.\n",
      "Iteration 12, inertia 26675.349609375.\n",
      "Iteration 13, inertia 26667.115234375.\n",
      "Iteration 14, inertia 26659.078125.\n",
      "Iteration 15, inertia 26652.4609375.\n",
      "Iteration 16, inertia 26646.669921875.\n",
      "Iteration 17, inertia 26640.779296875.\n",
      "Iteration 18, inertia 26634.67578125.\n",
      "Iteration 19, inertia 26629.2734375.\n",
      "Iteration 20, inertia 26624.662109375.\n",
      "Iteration 21, inertia 26618.255859375.\n",
      "Iteration 22, inertia 26610.85546875.\n",
      "Iteration 23, inertia 26604.87890625.\n",
      "Iteration 24, inertia 26600.0546875.\n",
      "Iteration 25, inertia 26596.802734375.\n",
      "Iteration 26, inertia 26593.560546875.\n",
      "Iteration 27, inertia 26590.94921875.\n",
      "Iteration 28, inertia 26588.5.\n",
      "Iteration 29, inertia 26586.15625.\n",
      "Iteration 30, inertia 26584.19921875.\n",
      "Iteration 31, inertia 26582.51171875.\n",
      "Iteration 32, inertia 26580.9296875.\n",
      "Iteration 33, inertia 26579.333984375.\n",
      "Iteration 34, inertia 26578.248046875.\n",
      "Iteration 35, inertia 26577.140625.\n",
      "Iteration 36, inertia 26576.01171875.\n",
      "Iteration 37, inertia 26575.0390625.\n",
      "Iteration 38, inertia 26574.03515625.\n",
      "Iteration 39, inertia 26573.056640625.\n",
      "Iteration 40, inertia 26572.080078125.\n",
      "Iteration 41, inertia 26570.9453125.\n",
      "Iteration 42, inertia 26569.94921875.\n",
      "Iteration 43, inertia 26569.06640625.\n",
      "Iteration 44, inertia 26568.173828125.\n",
      "Iteration 45, inertia 26567.556640625.\n",
      "Iteration 46, inertia 26566.994140625.\n",
      "Iteration 47, inertia 26566.43359375.\n",
      "Iteration 48, inertia 26565.8125.\n",
      "Iteration 49, inertia 26565.0625.\n",
      "Iteration 50, inertia 26564.4921875.\n",
      "Iteration 51, inertia 26564.02734375.\n",
      "Iteration 52, inertia 26563.599609375.\n",
      "Iteration 53, inertia 26563.326171875.\n",
      "Iteration 54, inertia 26563.109375.\n",
      "Iteration 55, inertia 26562.951171875.\n",
      "Iteration 56, inertia 26562.86328125.\n",
      "Iteration 57, inertia 26562.736328125.\n",
      "Iteration 58, inertia 26562.615234375.\n",
      "Iteration 59, inertia 26562.5.\n",
      "Iteration 60, inertia 26562.42578125.\n",
      "Iteration 61, inertia 26562.326171875.\n",
      "Iteration 62, inertia 26562.224609375.\n",
      "Iteration 63, inertia 26562.130859375.\n",
      "Iteration 64, inertia 26561.998046875.\n",
      "Iteration 65, inertia 26561.796875.\n",
      "Iteration 66, inertia 26561.619140625.\n",
      "Iteration 67, inertia 26561.517578125.\n",
      "Iteration 68, inertia 26561.435546875.\n",
      "Iteration 69, inertia 26561.3984375.\n",
      "Iteration 70, inertia 26561.375.\n",
      "Iteration 71, inertia 26561.345703125.\n",
      "Iteration 72, inertia 26561.314453125.\n",
      "Iteration 73, inertia 26561.3046875.\n",
      "Iteration 74, inertia 26561.294921875.\n",
      "Iteration 75, inertia 26561.302734375.\n",
      "Iteration 76, inertia 26561.302734375.\n",
      "Iteration 77, inertia 26561.296875.\n",
      "Iteration 78, inertia 26561.294921875.\n",
      "Converged at iteration 78: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41940.69921875.\n",
      "Iteration 1, inertia 27875.12890625.\n",
      "Iteration 2, inertia 27292.47265625.\n",
      "Iteration 3, inertia 27070.892578125.\n",
      "Iteration 4, inertia 26942.798828125.\n",
      "Iteration 5, inertia 26849.69140625.\n",
      "Iteration 6, inertia 26783.04296875.\n",
      "Iteration 7, inertia 26738.107421875.\n",
      "Iteration 8, inertia 26710.302734375.\n",
      "Iteration 9, inertia 26689.564453125.\n",
      "Iteration 10, inertia 26673.869140625.\n",
      "Iteration 11, inertia 26661.970703125.\n",
      "Iteration 12, inertia 26652.263671875.\n",
      "Iteration 13, inertia 26644.650390625.\n",
      "Iteration 14, inertia 26638.443359375.\n",
      "Iteration 15, inertia 26632.298828125.\n",
      "Iteration 16, inertia 26627.19921875.\n",
      "Iteration 17, inertia 26622.94921875.\n",
      "Iteration 18, inertia 26618.419921875.\n",
      "Iteration 19, inertia 26614.205078125.\n",
      "Iteration 20, inertia 26610.45703125.\n",
      "Iteration 21, inertia 26607.46484375.\n",
      "Iteration 22, inertia 26604.921875.\n",
      "Iteration 23, inertia 26602.486328125.\n",
      "Iteration 24, inertia 26600.236328125.\n",
      "Iteration 25, inertia 26598.052734375.\n",
      "Iteration 26, inertia 26596.23828125.\n",
      "Iteration 27, inertia 26594.552734375.\n",
      "Iteration 28, inertia 26592.939453125.\n",
      "Iteration 29, inertia 26591.529296875.\n",
      "Iteration 30, inertia 26590.396484375.\n",
      "Iteration 31, inertia 26589.3203125.\n",
      "Iteration 32, inertia 26588.466796875.\n",
      "Iteration 33, inertia 26587.771484375.\n",
      "Iteration 34, inertia 26587.228515625.\n",
      "Iteration 35, inertia 26586.748046875.\n",
      "Iteration 36, inertia 26586.220703125.\n",
      "Iteration 37, inertia 26585.66796875.\n",
      "Iteration 38, inertia 26585.1953125.\n",
      "Iteration 39, inertia 26584.818359375.\n",
      "Iteration 40, inertia 26584.4453125.\n",
      "Iteration 41, inertia 26584.154296875.\n",
      "Iteration 42, inertia 26583.986328125.\n",
      "Iteration 43, inertia 26583.845703125.\n",
      "Iteration 44, inertia 26583.67578125.\n",
      "Iteration 45, inertia 26583.57421875.\n",
      "Iteration 46, inertia 26583.48046875.\n",
      "Iteration 47, inertia 26583.408203125.\n",
      "Iteration 48, inertia 26583.33203125.\n",
      "Iteration 49, inertia 26583.251953125.\n",
      "Iteration 50, inertia 26583.181640625.\n",
      "Iteration 51, inertia 26583.134765625.\n",
      "Iteration 52, inertia 26583.060546875.\n",
      "Iteration 53, inertia 26583.001953125.\n",
      "Iteration 54, inertia 26582.94140625.\n",
      "Iteration 55, inertia 26582.87109375.\n",
      "Iteration 56, inertia 26582.78125.\n",
      "Iteration 57, inertia 26582.689453125.\n",
      "Iteration 58, inertia 26582.60546875.\n",
      "Iteration 59, inertia 26582.5234375.\n",
      "Iteration 60, inertia 26582.45703125.\n",
      "Iteration 61, inertia 26582.41796875.\n",
      "Iteration 62, inertia 26582.349609375.\n",
      "Iteration 63, inertia 26582.283203125.\n",
      "Iteration 64, inertia 26582.224609375.\n",
      "Iteration 65, inertia 26582.1640625.\n",
      "Iteration 66, inertia 26582.12109375.\n",
      "Iteration 67, inertia 26582.048828125.\n",
      "Iteration 68, inertia 26582.005859375.\n",
      "Iteration 69, inertia 26581.958984375.\n",
      "Iteration 70, inertia 26581.90234375.\n",
      "Iteration 71, inertia 26581.85546875.\n",
      "Iteration 72, inertia 26581.806640625.\n",
      "Iteration 73, inertia 26581.7734375.\n",
      "Iteration 74, inertia 26581.732421875.\n",
      "Iteration 75, inertia 26581.69140625.\n",
      "Iteration 76, inertia 26581.654296875.\n",
      "Iteration 77, inertia 26581.625.\n",
      "Iteration 78, inertia 26581.603515625.\n",
      "Iteration 79, inertia 26581.60546875.\n",
      "Iteration 80, inertia 26581.591796875.\n",
      "Iteration 81, inertia 26581.5859375.\n",
      "Iteration 82, inertia 26581.576171875.\n",
      "Iteration 83, inertia 26581.580078125.\n",
      "Converged at iteration 83: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41974.69921875.\n",
      "Iteration 1, inertia 27974.21875.\n",
      "Iteration 2, inertia 27387.681640625.\n",
      "Iteration 3, inertia 27159.462890625.\n",
      "Iteration 4, inertia 27016.4296875.\n",
      "Iteration 5, inertia 26912.90625.\n",
      "Iteration 6, inertia 26842.1796875.\n",
      "Iteration 7, inertia 26797.533203125.\n",
      "Iteration 8, inertia 26767.150390625.\n",
      "Iteration 9, inertia 26741.853515625.\n",
      "Iteration 10, inertia 26719.275390625.\n",
      "Iteration 11, inertia 26699.55859375.\n",
      "Iteration 12, inertia 26684.2265625.\n",
      "Iteration 13, inertia 26671.361328125.\n",
      "Iteration 14, inertia 26660.66015625.\n",
      "Iteration 15, inertia 26652.154296875.\n",
      "Iteration 16, inertia 26645.0078125.\n",
      "Iteration 17, inertia 26639.025390625.\n",
      "Iteration 18, inertia 26634.5859375.\n",
      "Iteration 19, inertia 26630.373046875.\n",
      "Iteration 20, inertia 26626.263671875.\n",
      "Iteration 21, inertia 26622.388671875.\n",
      "Iteration 22, inertia 26618.716796875.\n",
      "Iteration 23, inertia 26615.361328125.\n",
      "Iteration 24, inertia 26612.4375.\n",
      "Iteration 25, inertia 26609.681640625.\n",
      "Iteration 26, inertia 26607.130859375.\n",
      "Iteration 27, inertia 26605.068359375.\n",
      "Iteration 28, inertia 26603.44140625.\n",
      "Iteration 29, inertia 26601.75.\n",
      "Iteration 30, inertia 26600.2578125.\n",
      "Iteration 31, inertia 26599.005859375.\n",
      "Iteration 32, inertia 26597.80859375.\n",
      "Iteration 33, inertia 26596.6640625.\n",
      "Iteration 34, inertia 26595.44140625.\n",
      "Iteration 35, inertia 26594.3046875.\n",
      "Iteration 36, inertia 26593.203125.\n",
      "Iteration 37, inertia 26592.1171875.\n",
      "Iteration 38, inertia 26591.05859375.\n",
      "Iteration 39, inertia 26589.837890625.\n",
      "Iteration 40, inertia 26588.55078125.\n",
      "Iteration 41, inertia 26586.71484375.\n",
      "Iteration 42, inertia 26584.95703125.\n",
      "Iteration 43, inertia 26582.904296875.\n",
      "Iteration 44, inertia 26580.9765625.\n",
      "Iteration 45, inertia 26579.71484375.\n",
      "Iteration 46, inertia 26578.84375.\n",
      "Iteration 47, inertia 26578.130859375.\n",
      "Iteration 48, inertia 26577.466796875.\n",
      "Iteration 49, inertia 26576.806640625.\n",
      "Iteration 50, inertia 26576.16796875.\n",
      "Iteration 51, inertia 26575.48046875.\n",
      "Iteration 52, inertia 26574.71484375.\n",
      "Iteration 53, inertia 26573.853515625.\n",
      "Iteration 54, inertia 26572.9140625.\n",
      "Iteration 55, inertia 26571.994140625.\n",
      "Iteration 56, inertia 26571.119140625.\n",
      "Iteration 57, inertia 26570.45703125.\n",
      "Iteration 58, inertia 26569.884765625.\n",
      "Iteration 59, inertia 26569.220703125.\n",
      "Iteration 60, inertia 26568.595703125.\n",
      "Iteration 61, inertia 26568.033203125.\n",
      "Iteration 62, inertia 26567.583984375.\n",
      "Iteration 63, inertia 26567.169921875.\n",
      "Iteration 64, inertia 26566.78125.\n",
      "Iteration 65, inertia 26566.4765625.\n",
      "Iteration 66, inertia 26566.212890625.\n",
      "Iteration 67, inertia 26566.03125.\n",
      "Iteration 68, inertia 26565.9140625.\n",
      "Iteration 69, inertia 26565.822265625.\n",
      "Iteration 70, inertia 26565.74609375.\n",
      "Iteration 71, inertia 26565.7109375.\n",
      "Iteration 72, inertia 26565.6796875.\n",
      "Iteration 73, inertia 26565.638671875.\n",
      "Iteration 74, inertia 26565.625.\n",
      "Iteration 75, inertia 26565.59765625.\n",
      "Iteration 76, inertia 26565.595703125.\n",
      "Iteration 77, inertia 26565.57421875.\n",
      "Iteration 78, inertia 26565.5625.\n",
      "Iteration 79, inertia 26565.52734375.\n",
      "Iteration 80, inertia 26565.494140625.\n",
      "Iteration 81, inertia 26565.46484375.\n",
      "Iteration 82, inertia 26565.42578125.\n",
      "Iteration 83, inertia 26565.39453125.\n",
      "Iteration 84, inertia 26565.37890625.\n",
      "Iteration 85, inertia 26565.380859375.\n",
      "Converged at iteration 85: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42041.30078125.\n",
      "Iteration 1, inertia 27896.447265625.\n",
      "Iteration 2, inertia 27310.1015625.\n",
      "Iteration 3, inertia 27103.05078125.\n",
      "Iteration 4, inertia 26996.849609375.\n",
      "Iteration 5, inertia 26933.642578125.\n",
      "Iteration 6, inertia 26884.564453125.\n",
      "Iteration 7, inertia 26841.23046875.\n",
      "Iteration 8, inertia 26801.087890625.\n",
      "Iteration 9, inertia 26769.869140625.\n",
      "Iteration 10, inertia 26748.703125.\n",
      "Iteration 11, inertia 26731.28125.\n",
      "Iteration 12, inertia 26716.8203125.\n",
      "Iteration 13, inertia 26705.150390625.\n",
      "Iteration 14, inertia 26695.06640625.\n",
      "Iteration 15, inertia 26685.978515625.\n",
      "Iteration 16, inertia 26678.140625.\n",
      "Iteration 17, inertia 26671.59375.\n",
      "Iteration 18, inertia 26665.421875.\n",
      "Iteration 19, inertia 26659.751953125.\n",
      "Iteration 20, inertia 26654.1171875.\n",
      "Iteration 21, inertia 26648.12109375.\n",
      "Iteration 22, inertia 26643.095703125.\n",
      "Iteration 23, inertia 26639.423828125.\n",
      "Iteration 24, inertia 26636.59765625.\n",
      "Iteration 25, inertia 26633.60546875.\n",
      "Iteration 26, inertia 26630.087890625.\n",
      "Iteration 27, inertia 26624.8671875.\n",
      "Iteration 28, inertia 26616.78125.\n",
      "Iteration 29, inertia 26611.810546875.\n",
      "Iteration 30, inertia 26609.349609375.\n",
      "Iteration 31, inertia 26607.689453125.\n",
      "Iteration 32, inertia 26606.17578125.\n",
      "Iteration 33, inertia 26604.681640625.\n",
      "Iteration 34, inertia 26603.392578125.\n",
      "Iteration 35, inertia 26602.037109375.\n",
      "Iteration 36, inertia 26600.486328125.\n",
      "Iteration 37, inertia 26599.47265625.\n",
      "Iteration 38, inertia 26598.763671875.\n",
      "Iteration 39, inertia 26598.240234375.\n",
      "Iteration 40, inertia 26597.6875.\n",
      "Iteration 41, inertia 26597.0390625.\n",
      "Iteration 42, inertia 26596.416015625.\n",
      "Iteration 43, inertia 26595.751953125.\n",
      "Iteration 44, inertia 26595.19140625.\n",
      "Iteration 45, inertia 26594.60546875.\n",
      "Iteration 46, inertia 26594.091796875.\n",
      "Iteration 47, inertia 26593.666015625.\n",
      "Iteration 48, inertia 26593.32421875.\n",
      "Iteration 49, inertia 26593.02734375.\n",
      "Iteration 50, inertia 26592.771484375.\n",
      "Iteration 51, inertia 26592.541015625.\n",
      "Iteration 52, inertia 26592.353515625.\n",
      "Iteration 53, inertia 26592.17578125.\n",
      "Iteration 54, inertia 26591.923828125.\n",
      "Iteration 55, inertia 26591.599609375.\n",
      "Iteration 56, inertia 26591.400390625.\n",
      "Iteration 57, inertia 26591.2734375.\n",
      "Iteration 58, inertia 26591.15625.\n",
      "Iteration 59, inertia 26591.07421875.\n",
      "Iteration 60, inertia 26590.982421875.\n",
      "Iteration 61, inertia 26590.884765625.\n",
      "Iteration 62, inertia 26590.828125.\n",
      "Iteration 63, inertia 26590.755859375.\n",
      "Iteration 64, inertia 26590.666015625.\n",
      "Iteration 65, inertia 26590.607421875.\n",
      "Iteration 66, inertia 26590.515625.\n",
      "Iteration 67, inertia 26590.384765625.\n",
      "Iteration 68, inertia 26590.236328125.\n",
      "Iteration 69, inertia 26590.068359375.\n",
      "Iteration 70, inertia 26589.923828125.\n",
      "Iteration 71, inertia 26589.8359375.\n",
      "Iteration 72, inertia 26589.77734375.\n",
      "Iteration 73, inertia 26589.716796875.\n",
      "Iteration 74, inertia 26589.677734375.\n",
      "Iteration 75, inertia 26589.650390625.\n",
      "Iteration 76, inertia 26589.6171875.\n",
      "Iteration 77, inertia 26589.599609375.\n",
      "Iteration 78, inertia 26589.587890625.\n",
      "Iteration 79, inertia 26589.568359375.\n",
      "Converged at iteration 79: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42087.59375.\n",
      "Iteration 1, inertia 28050.12109375.\n",
      "Iteration 2, inertia 27428.263671875.\n",
      "Iteration 3, inertia 27169.92578125.\n",
      "Iteration 4, inertia 27029.111328125.\n",
      "Iteration 5, inertia 26941.482421875.\n",
      "Iteration 6, inertia 26883.224609375.\n",
      "Iteration 7, inertia 26837.974609375.\n",
      "Iteration 8, inertia 26801.41015625.\n",
      "Iteration 9, inertia 26767.99609375.\n",
      "Iteration 10, inertia 26740.48828125.\n",
      "Iteration 11, inertia 26719.23046875.\n",
      "Iteration 12, inertia 26700.8515625.\n",
      "Iteration 13, inertia 26683.33203125.\n",
      "Iteration 14, inertia 26668.93359375.\n",
      "Iteration 15, inertia 26656.685546875.\n",
      "Iteration 16, inertia 26644.76171875.\n",
      "Iteration 17, inertia 26631.734375.\n",
      "Iteration 18, inertia 26620.72265625.\n",
      "Iteration 19, inertia 26610.921875.\n",
      "Iteration 20, inertia 26604.328125.\n",
      "Iteration 21, inertia 26599.87109375.\n",
      "Iteration 22, inertia 26596.568359375.\n",
      "Iteration 23, inertia 26593.669921875.\n",
      "Iteration 24, inertia 26590.99609375.\n",
      "Iteration 25, inertia 26588.57421875.\n",
      "Iteration 26, inertia 26586.294921875.\n",
      "Iteration 27, inertia 26584.048828125.\n",
      "Iteration 28, inertia 26581.345703125.\n",
      "Iteration 29, inertia 26578.5234375.\n",
      "Iteration 30, inertia 26575.701171875.\n",
      "Iteration 31, inertia 26572.6015625.\n",
      "Iteration 32, inertia 26569.1484375.\n",
      "Iteration 33, inertia 26566.11328125.\n",
      "Iteration 34, inertia 26563.279296875.\n",
      "Iteration 35, inertia 26560.6171875.\n",
      "Iteration 36, inertia 26558.4140625.\n",
      "Iteration 37, inertia 26556.97265625.\n",
      "Iteration 38, inertia 26555.9921875.\n",
      "Iteration 39, inertia 26555.1953125.\n",
      "Iteration 40, inertia 26554.55078125.\n",
      "Iteration 41, inertia 26554.025390625.\n",
      "Iteration 42, inertia 26553.39453125.\n",
      "Iteration 43, inertia 26552.8203125.\n",
      "Iteration 44, inertia 26552.39453125.\n",
      "Iteration 45, inertia 26552.08984375.\n",
      "Iteration 46, inertia 26551.81640625.\n",
      "Iteration 47, inertia 26551.48828125.\n",
      "Iteration 48, inertia 26551.11328125.\n",
      "Iteration 49, inertia 26550.68359375.\n",
      "Iteration 50, inertia 26550.396484375.\n",
      "Iteration 51, inertia 26550.19140625.\n",
      "Iteration 52, inertia 26550.001953125.\n",
      "Iteration 53, inertia 26549.72265625.\n",
      "Iteration 54, inertia 26549.423828125.\n",
      "Iteration 55, inertia 26549.271484375.\n",
      "Iteration 56, inertia 26549.140625.\n",
      "Iteration 57, inertia 26549.041015625.\n",
      "Iteration 58, inertia 26548.955078125.\n",
      "Iteration 59, inertia 26548.89453125.\n",
      "Iteration 60, inertia 26548.83203125.\n",
      "Iteration 61, inertia 26548.783203125.\n",
      "Iteration 62, inertia 26548.75390625.\n",
      "Iteration 63, inertia 26548.71875.\n",
      "Iteration 64, inertia 26548.708984375.\n",
      "Iteration 65, inertia 26548.70703125.\n",
      "Iteration 66, inertia 26548.705078125.\n",
      "Converged at iteration 66: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41927.3359375.\n",
      "Iteration 1, inertia 27893.595703125.\n",
      "Iteration 2, inertia 27255.685546875.\n",
      "Iteration 3, inertia 27015.578125.\n",
      "Iteration 4, inertia 26898.453125.\n",
      "Iteration 5, inertia 26831.2421875.\n",
      "Iteration 6, inertia 26790.33203125.\n",
      "Iteration 7, inertia 26760.47265625.\n",
      "Iteration 8, inertia 26733.833984375.\n",
      "Iteration 9, inertia 26709.322265625.\n",
      "Iteration 10, inertia 26691.8671875.\n",
      "Iteration 11, inertia 26678.873046875.\n",
      "Iteration 12, inertia 26668.712890625.\n",
      "Iteration 13, inertia 26659.71875.\n",
      "Iteration 14, inertia 26651.74609375.\n",
      "Iteration 15, inertia 26644.529296875.\n",
      "Iteration 16, inertia 26637.875.\n",
      "Iteration 17, inertia 26631.728515625.\n",
      "Iteration 18, inertia 26626.771484375.\n",
      "Iteration 19, inertia 26622.84375.\n",
      "Iteration 20, inertia 26619.3828125.\n",
      "Iteration 21, inertia 26616.416015625.\n",
      "Iteration 22, inertia 26613.873046875.\n",
      "Iteration 23, inertia 26611.54296875.\n",
      "Iteration 24, inertia 26609.591796875.\n",
      "Iteration 25, inertia 26608.26953125.\n",
      "Iteration 26, inertia 26607.037109375.\n",
      "Iteration 27, inertia 26605.771484375.\n",
      "Iteration 28, inertia 26604.30078125.\n",
      "Iteration 29, inertia 26602.76171875.\n",
      "Iteration 30, inertia 26601.224609375.\n",
      "Iteration 31, inertia 26599.6484375.\n",
      "Iteration 32, inertia 26598.310546875.\n",
      "Iteration 33, inertia 26597.228515625.\n",
      "Iteration 34, inertia 26596.248046875.\n",
      "Iteration 35, inertia 26595.521484375.\n",
      "Iteration 36, inertia 26594.939453125.\n",
      "Iteration 37, inertia 26594.419921875.\n",
      "Iteration 38, inertia 26593.892578125.\n",
      "Iteration 39, inertia 26593.345703125.\n",
      "Iteration 40, inertia 26592.634765625.\n",
      "Iteration 41, inertia 26591.728515625.\n",
      "Iteration 42, inertia 26590.46484375.\n",
      "Iteration 43, inertia 26589.0703125.\n",
      "Iteration 44, inertia 26587.55078125.\n",
      "Iteration 45, inertia 26586.1796875.\n",
      "Iteration 46, inertia 26584.625.\n",
      "Iteration 47, inertia 26583.57421875.\n",
      "Iteration 48, inertia 26583.05078125.\n",
      "Iteration 49, inertia 26582.72265625.\n",
      "Iteration 50, inertia 26582.390625.\n",
      "Iteration 51, inertia 26581.998046875.\n",
      "Iteration 52, inertia 26581.53515625.\n",
      "Iteration 53, inertia 26581.046875.\n",
      "Iteration 54, inertia 26580.62890625.\n",
      "Iteration 55, inertia 26580.341796875.\n",
      "Iteration 56, inertia 26580.119140625.\n",
      "Iteration 57, inertia 26579.923828125.\n",
      "Iteration 58, inertia 26579.787109375.\n",
      "Iteration 59, inertia 26579.64453125.\n",
      "Iteration 60, inertia 26579.505859375.\n",
      "Iteration 61, inertia 26579.37890625.\n",
      "Iteration 62, inertia 26579.244140625.\n",
      "Iteration 63, inertia 26579.1640625.\n",
      "Iteration 64, inertia 26579.095703125.\n",
      "Iteration 65, inertia 26579.033203125.\n",
      "Iteration 66, inertia 26578.95703125.\n",
      "Iteration 67, inertia 26578.884765625.\n",
      "Iteration 68, inertia 26578.826171875.\n",
      "Iteration 69, inertia 26578.791015625.\n",
      "Iteration 70, inertia 26578.748046875.\n",
      "Iteration 71, inertia 26578.705078125.\n",
      "Iteration 72, inertia 26578.677734375.\n",
      "Iteration 73, inertia 26578.66796875.\n",
      "Iteration 74, inertia 26578.65625.\n",
      "Iteration 75, inertia 26578.640625.\n",
      "Iteration 76, inertia 26578.650390625.\n",
      "Iteration 77, inertia 26578.638671875.\n",
      "Iteration 78, inertia 26578.630859375.\n",
      "Converged at iteration 78: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42076.65234375.\n",
      "Iteration 1, inertia 27983.037109375.\n",
      "Iteration 2, inertia 27357.3359375.\n",
      "Iteration 3, inertia 27132.14453125.\n",
      "Iteration 4, inertia 27006.8046875.\n",
      "Iteration 5, inertia 26916.275390625.\n",
      "Iteration 6, inertia 26850.08984375.\n",
      "Iteration 7, inertia 26805.240234375.\n",
      "Iteration 8, inertia 26773.541015625.\n",
      "Iteration 9, inertia 26748.333984375.\n",
      "Iteration 10, inertia 26729.986328125.\n",
      "Iteration 11, inertia 26715.7421875.\n",
      "Iteration 12, inertia 26702.35546875.\n",
      "Iteration 13, inertia 26686.7265625.\n",
      "Iteration 14, inertia 26671.798828125.\n",
      "Iteration 15, inertia 26660.4140625.\n",
      "Iteration 16, inertia 26651.833984375.\n",
      "Iteration 17, inertia 26644.3828125.\n",
      "Iteration 18, inertia 26635.23828125.\n",
      "Iteration 19, inertia 26626.095703125.\n",
      "Iteration 20, inertia 26619.9296875.\n",
      "Iteration 21, inertia 26615.001953125.\n",
      "Iteration 22, inertia 26610.61328125.\n",
      "Iteration 23, inertia 26606.8515625.\n",
      "Iteration 24, inertia 26603.76953125.\n",
      "Iteration 25, inertia 26601.4296875.\n",
      "Iteration 26, inertia 26599.552734375.\n",
      "Iteration 27, inertia 26598.107421875.\n",
      "Iteration 28, inertia 26596.93359375.\n",
      "Iteration 29, inertia 26596.005859375.\n",
      "Iteration 30, inertia 26595.2421875.\n",
      "Iteration 31, inertia 26594.568359375.\n",
      "Iteration 32, inertia 26593.73046875.\n",
      "Iteration 33, inertia 26593.076171875.\n",
      "Iteration 34, inertia 26592.51953125.\n",
      "Iteration 35, inertia 26591.939453125.\n",
      "Iteration 36, inertia 26591.208984375.\n",
      "Iteration 37, inertia 26590.259765625.\n",
      "Iteration 38, inertia 26589.208984375.\n",
      "Iteration 39, inertia 26588.36328125.\n",
      "Iteration 40, inertia 26587.59375.\n",
      "Iteration 41, inertia 26586.82421875.\n",
      "Iteration 42, inertia 26586.12109375.\n",
      "Iteration 43, inertia 26585.291015625.\n",
      "Iteration 44, inertia 26584.701171875.\n",
      "Iteration 45, inertia 26584.09375.\n",
      "Iteration 46, inertia 26583.498046875.\n",
      "Iteration 47, inertia 26582.97265625.\n",
      "Iteration 48, inertia 26582.486328125.\n",
      "Iteration 49, inertia 26582.05078125.\n",
      "Iteration 50, inertia 26581.64453125.\n",
      "Iteration 51, inertia 26581.248046875.\n",
      "Iteration 52, inertia 26580.884765625.\n",
      "Iteration 53, inertia 26580.560546875.\n",
      "Iteration 54, inertia 26580.16015625.\n",
      "Iteration 55, inertia 26579.537109375.\n",
      "Iteration 56, inertia 26578.765625.\n",
      "Iteration 57, inertia 26577.91015625.\n",
      "Iteration 58, inertia 26577.271484375.\n",
      "Iteration 59, inertia 26576.916015625.\n",
      "Iteration 60, inertia 26576.64453125.\n",
      "Iteration 61, inertia 26576.4296875.\n",
      "Iteration 62, inertia 26576.30859375.\n",
      "Iteration 63, inertia 26576.234375.\n",
      "Iteration 64, inertia 26576.185546875.\n",
      "Iteration 65, inertia 26576.1484375.\n",
      "Iteration 66, inertia 26576.123046875.\n",
      "Iteration 67, inertia 26576.087890625.\n",
      "Iteration 68, inertia 26576.056640625.\n",
      "Iteration 69, inertia 26576.03125.\n",
      "Iteration 70, inertia 26576.015625.\n",
      "Iteration 71, inertia 26576.00390625.\n",
      "Iteration 72, inertia 26575.984375.\n",
      "Iteration 73, inertia 26575.974609375.\n",
      "Iteration 74, inertia 26575.958984375.\n",
      "Iteration 75, inertia 26575.962890625.\n",
      "Converged at iteration 75: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 41767.84375.\n",
      "Iteration 1, inertia 27952.00390625.\n",
      "Iteration 2, inertia 27364.296875.\n",
      "Iteration 3, inertia 27145.599609375.\n",
      "Iteration 4, inertia 27012.14453125.\n",
      "Iteration 5, inertia 26923.84375.\n",
      "Iteration 6, inertia 26864.984375.\n",
      "Iteration 7, inertia 26820.6015625.\n",
      "Iteration 8, inertia 26789.6953125.\n",
      "Iteration 9, inertia 26767.212890625.\n",
      "Iteration 10, inertia 26746.18359375.\n",
      "Iteration 11, inertia 26727.609375.\n",
      "Iteration 12, inertia 26714.109375.\n",
      "Iteration 13, inertia 26703.748046875.\n",
      "Iteration 14, inertia 26693.849609375.\n",
      "Iteration 15, inertia 26684.224609375.\n",
      "Iteration 16, inertia 26675.66796875.\n",
      "Iteration 17, inertia 26667.734375.\n",
      "Iteration 18, inertia 26661.171875.\n",
      "Iteration 19, inertia 26656.19921875.\n",
      "Iteration 20, inertia 26652.27734375.\n",
      "Iteration 21, inertia 26648.560546875.\n",
      "Iteration 22, inertia 26644.287109375.\n",
      "Iteration 23, inertia 26639.173828125.\n",
      "Iteration 24, inertia 26633.34375.\n",
      "Iteration 25, inertia 26628.74609375.\n",
      "Iteration 26, inertia 26626.369140625.\n",
      "Iteration 27, inertia 26624.255859375.\n",
      "Iteration 28, inertia 26622.359375.\n",
      "Iteration 29, inertia 26620.232421875.\n",
      "Iteration 30, inertia 26617.73046875.\n",
      "Iteration 31, inertia 26615.4453125.\n",
      "Iteration 32, inertia 26613.296875.\n",
      "Iteration 33, inertia 26611.375.\n",
      "Iteration 34, inertia 26610.15234375.\n",
      "Iteration 35, inertia 26609.2265625.\n",
      "Iteration 36, inertia 26608.634765625.\n",
      "Iteration 37, inertia 26608.107421875.\n",
      "Iteration 38, inertia 26607.609375.\n",
      "Iteration 39, inertia 26607.150390625.\n",
      "Iteration 40, inertia 26606.728515625.\n",
      "Iteration 41, inertia 26606.43359375.\n",
      "Iteration 42, inertia 26606.23828125.\n",
      "Iteration 43, inertia 26606.07421875.\n",
      "Iteration 44, inertia 26605.904296875.\n",
      "Iteration 45, inertia 26605.76953125.\n",
      "Iteration 46, inertia 26605.677734375.\n",
      "Iteration 47, inertia 26605.587890625.\n",
      "Iteration 48, inertia 26605.52734375.\n",
      "Iteration 49, inertia 26605.41796875.\n",
      "Iteration 50, inertia 26605.326171875.\n",
      "Iteration 51, inertia 26605.185546875.\n",
      "Iteration 52, inertia 26605.0625.\n",
      "Iteration 53, inertia 26604.986328125.\n",
      "Iteration 54, inertia 26604.90625.\n",
      "Iteration 55, inertia 26604.814453125.\n",
      "Iteration 56, inertia 26604.732421875.\n",
      "Iteration 57, inertia 26604.634765625.\n",
      "Iteration 58, inertia 26604.587890625.\n",
      "Iteration 59, inertia 26604.53125.\n",
      "Iteration 60, inertia 26604.498046875.\n",
      "Iteration 61, inertia 26604.44140625.\n",
      "Iteration 62, inertia 26604.39453125.\n",
      "Iteration 63, inertia 26604.34375.\n",
      "Iteration 64, inertia 26604.3203125.\n",
      "Iteration 65, inertia 26604.30859375.\n",
      "Iteration 66, inertia 26604.302734375.\n",
      "Iteration 67, inertia 26604.2890625.\n",
      "Iteration 68, inertia 26604.28125.\n",
      "Iteration 69, inertia 26604.287109375.\n",
      "Iteration 70, inertia 26604.279296875.\n",
      "Converged at iteration 70: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 42073.93359375.\n",
      "Iteration 1, inertia 27933.556640625.\n",
      "Iteration 2, inertia 27323.439453125.\n",
      "Iteration 3, inertia 27089.083984375.\n",
      "Iteration 4, inertia 26956.953125.\n",
      "Iteration 5, inertia 26880.169921875.\n",
      "Iteration 6, inertia 26823.43359375.\n",
      "Iteration 7, inertia 26779.443359375.\n",
      "Iteration 8, inertia 26746.486328125.\n",
      "Iteration 9, inertia 26723.419921875.\n",
      "Iteration 10, inertia 26706.3984375.\n",
      "Iteration 11, inertia 26693.359375.\n",
      "Iteration 12, inertia 26684.388671875.\n",
      "Iteration 13, inertia 26676.939453125.\n",
      "Iteration 14, inertia 26670.27734375.\n",
      "Iteration 15, inertia 26663.796875.\n",
      "Iteration 16, inertia 26656.04296875.\n",
      "Iteration 17, inertia 26648.15234375.\n",
      "Iteration 18, inertia 26639.96875.\n",
      "Iteration 19, inertia 26633.193359375.\n",
      "Iteration 20, inertia 26627.955078125.\n",
      "Iteration 21, inertia 26622.36328125.\n",
      "Iteration 22, inertia 26616.263671875.\n",
      "Iteration 23, inertia 26610.412109375.\n",
      "Iteration 24, inertia 26606.181640625.\n",
      "Iteration 25, inertia 26603.146484375.\n",
      "Iteration 26, inertia 26600.9609375.\n",
      "Iteration 27, inertia 26599.10546875.\n",
      "Iteration 28, inertia 26597.5390625.\n",
      "Iteration 29, inertia 26596.08984375.\n",
      "Iteration 30, inertia 26594.791015625.\n",
      "Iteration 31, inertia 26593.572265625.\n",
      "Iteration 32, inertia 26592.501953125.\n",
      "Iteration 33, inertia 26591.599609375.\n",
      "Iteration 34, inertia 26590.7734375.\n",
      "Iteration 35, inertia 26590.0.\n",
      "Iteration 36, inertia 26589.30859375.\n",
      "Iteration 37, inertia 26588.59765625.\n",
      "Iteration 38, inertia 26587.908203125.\n",
      "Iteration 39, inertia 26587.28125.\n",
      "Iteration 40, inertia 26586.564453125.\n",
      "Iteration 41, inertia 26585.673828125.\n",
      "Iteration 42, inertia 26584.841796875.\n",
      "Iteration 43, inertia 26583.88671875.\n",
      "Iteration 44, inertia 26582.994140625.\n",
      "Iteration 45, inertia 26582.17578125.\n",
      "Iteration 46, inertia 26581.462890625.\n",
      "Iteration 47, inertia 26580.7109375.\n",
      "Iteration 48, inertia 26580.00390625.\n",
      "Iteration 49, inertia 26579.3828125.\n",
      "Iteration 50, inertia 26578.91796875.\n",
      "Iteration 51, inertia 26578.47265625.\n",
      "Iteration 52, inertia 26578.109375.\n",
      "Iteration 53, inertia 26577.734375.\n",
      "Iteration 54, inertia 26577.390625.\n",
      "Iteration 55, inertia 26577.09765625.\n",
      "Iteration 56, inertia 26576.798828125.\n",
      "Iteration 57, inertia 26576.533203125.\n",
      "Iteration 58, inertia 26576.326171875.\n",
      "Iteration 59, inertia 26576.162109375.\n",
      "Iteration 60, inertia 26575.9921875.\n",
      "Iteration 61, inertia 26575.787109375.\n",
      "Iteration 62, inertia 26575.568359375.\n",
      "Iteration 63, inertia 26575.375.\n",
      "Iteration 64, inertia 26575.2265625.\n",
      "Iteration 65, inertia 26575.1328125.\n",
      "Iteration 66, inertia 26575.029296875.\n",
      "Iteration 67, inertia 26574.908203125.\n",
      "Iteration 68, inertia 26574.8359375.\n",
      "Iteration 69, inertia 26574.76953125.\n",
      "Iteration 70, inertia 26574.736328125.\n",
      "Iteration 71, inertia 26574.697265625.\n",
      "Iteration 72, inertia 26574.673828125.\n",
      "Iteration 73, inertia 26574.6328125.\n",
      "Iteration 74, inertia 26574.6171875.\n",
      "Iteration 75, inertia 26574.60546875.\n",
      "Iteration 76, inertia 26574.587890625.\n",
      "Iteration 77, inertia 26574.564453125.\n",
      "Iteration 78, inertia 26574.544921875.\n",
      "Iteration 79, inertia 26574.53515625.\n",
      "Iteration 80, inertia 26574.51171875.\n",
      "Iteration 81, inertia 26574.48828125.\n",
      "Iteration 82, inertia 26574.46875.\n",
      "Iteration 83, inertia 26574.41796875.\n",
      "Iteration 84, inertia 26574.376953125.\n",
      "Iteration 85, inertia 26574.353515625.\n",
      "Iteration 86, inertia 26574.337890625.\n",
      "Iteration 87, inertia 26574.3203125.\n",
      "Iteration 88, inertia 26574.302734375.\n",
      "Iteration 89, inertia 26574.279296875.\n",
      "Iteration 90, inertia 26574.2734375.\n",
      "Iteration 91, inertia 26574.267578125.\n",
      "Iteration 92, inertia 26574.267578125.\n",
      "Iteration 93, inertia 26574.26171875.\n",
      "Converged at iteration 93: strict convergence.\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=K, random_state=0, n_init=10, max_iter=1000, verbose=1).fit(all_vfeatures)\n",
    "preds = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fd625a-49ec-4ee2-a3a9-be5aed13bf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4764606359306324"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_acc(all_clu_label, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc7ac05-c81b-4d6d-b9d6-8dded5a49e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./cache/cluster/kmeans-{args.dataset}.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c62d6-a5a2-4de6-94b1-43d8d3cf0c9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dataset_name in ['make_entity13', 'imagenet', 'make_entity30', 'make_living17']:\n",
    "    print(f'cluster {dataset_name}')\n",
    "    args.dataset_name = dataset_name\n",
    "    dataset = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_val, seed=0)\n",
    "    loader_val = torch.utils.data.DataLoader(dataset, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "    print('dataset size', len(dataset))\n",
    "    \n",
    "    ### inference\n",
    "    amp_autocast = torch.cuda.amp.autocast\n",
    "    all_vfeatures = []\n",
    "    all_clu_label = []\n",
    "    with tqdm(total=len(loader_val)) as pbar:\n",
    "        model.eval()\n",
    "        for idx_batch, batch in enumerate(loader_val):\n",
    "            images, label_voc, label_clu, idx_img = batch\n",
    "            images = images.to(args.device)\n",
    "            with amp_autocast():\n",
    "                with torch.no_grad():\n",
    "                    logits = model.visual.extract_features(images)\n",
    "                    logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                    all_vfeatures.append(logits.cpu().numpy())\n",
    "                    all_clu_label.append(label_clu.numpy())\n",
    "            pbar.update(1)\n",
    "\n",
    "    all_vfeatures = np.concatenate(all_vfeatures)\n",
    "    all_clu_label = np.concatenate(all_clu_label)\n",
    "    \n",
    "    \n",
    "    # K = dataset.num_classes\n",
    "    K = 2000\n",
    "    kmeans = MiniBatchKMeans(n_clusters=K, batch_size=2048, \n",
    "                             random_state=0, n_init=10, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "    preds = kmeans.labels_\n",
    "    print(cluster_acc(all_clu_label, preds))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=K, random_state=0, n_init=3, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "    preds = kmeans.labels_\n",
    "    print(cluster_acc(all_clu_label, preds))\n",
    "    np.save(f'./cache/cluster/kmeans-{args.dataset_name}-2k.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7586ee-6282-4a15-8375-bf77fc869308",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(vec_count.topk(k=voc_beta*dataset.num_classes).values.cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381a3c8-f1a3-429f-b4b6-13a312c5edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'acc={(all_pred_voc == all_gt_voc).float().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d205833-451c-4539-b20f-227ed64045d9",
   "metadata": {},
   "source": [
    "upperbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bc5cb-e5af-4528-aabb-a6854c51db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "mask = torch.zeros(classifier.size(0), device=args.device)\n",
    "mapping_classifier = torch.tensor(sorted(set(dataset.labels)), device=args.device)\n",
    "mask = torch.scatter(mask, 0, mapping_classifier, 1)\n",
    "classifier = classifier[mask.bool()]\n",
    "\n",
    "all_pred_voc = []\n",
    "all_gt_voc = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                all_pred_voc.append(prob.argmax(dim=-1).cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "\n",
    "all_pred_voc = torch.gather(mapping_classifier.cpu(), 0, all_pred_voc)\n",
    "\n",
    "print(f'acc={(all_pred_voc == all_gt_voc).float().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52897615-fcd6-4c26-ac22-b75be99ff3a1",
   "metadata": {},
   "source": [
    "hierarchy accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef9118-91fc-47ad-9de9-a44437a83c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "\n",
    "all_pred_voc = []\n",
    "all_gt_voc = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                all_pred_voc.append(prob.argmax(dim=-1).cpu())\n",
    "                # label_voc = torch.tensor(list(map(lambda x: vocab.mapping_names_idx[x], label_voc)))\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9519a02-6a92-4b2d-b350-05d5f4d83c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_i2gi = vocab.mapping_idx_global_idx\n",
    "isin = lambda x, y: np.array([xx in y for xx in x])\n",
    "all_pred_hier = []\n",
    "for i in range(len(all_gt_voc)):\n",
    "    cond1 = isin(mapping_i2gi[all_gt_voc[i].item()], reduce(lambda x,y: x|y, [parents[p] for p in mapping_i2gi[all_pred_voc[i].item()]])).any()\n",
    "    cond2 = isin(mapping_i2gi[all_pred_voc[i].item()], reduce(lambda x,y: x|y, [parents[p] for p in mapping_i2gi[all_gt_voc[i].item()]])).any()\n",
    "    pred_hier = cond1 | cond2\n",
    "    all_pred_hier.append(pred_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b82639-e18e-4da9-a0b7-36f32dfc184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_pred_hier).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a45ccd-0b81-4faa-833d-27d9ee4e4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_pred_voc==all_gt_voc).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d1a80-6c76-41d2-97d3-3863a16490c0",
   "metadata": {},
   "source": [
    "KNN performance investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb43e8-525b-4d08-a46d-96f8c19d655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "# classifier = F.normalize(classifier, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deebbc7-f951-40f6-bbe2-19ea353341c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = classifier@classifier.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ab39c-83e4-4414-9282-85f5db9b1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "topk_ind = similarity.topk(k=K+1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5457c3-7439-43d6-88f0-56949b23ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(map(lambda x: list(map(lambda y: classnames[y], x)), topk_ind.cpu().numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040aa32-b9f8-49d0-b48f-14063c0d670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c532a-61b0-48f6-a987-22a327fa77bc",
   "metadata": {},
   "source": [
    "similarity inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c86cca-e05e-435f-894c-1052d2f0841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "all_sim_topk = []\n",
    "all_sim_topk_val = []\n",
    "all_gt_label_voc = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = logits @ classifier.t()\n",
    "                sim_topk = similarity.topk(k=10)\n",
    "                all_sim_topk.append(sim_topk.indices.cpu())\n",
    "                all_sim_topk_val.append(sim_topk.values.cpu())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_features.append(logits.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_sim_topk = torch.cat(all_sim_topk, dim=0)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_sim_topk_val = torch.cat(all_sim_topk_val, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b28b9-6b27-47d4-a840-1c2dacad56cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea0560-9495-459f-9295-40090979c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./pred_clu-{args.dataset_name}-train-{arch}.npy', pred_clu)\n",
    "# pred_clu = np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090ee39-4248-4c84-95f9-61f6e8baf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = all_features.to(args.device)\n",
    "sim = all_features@all_features.t()\n",
    "np.save(f'./knn_ind-{args.dataset_name}-train-{arch}.npy', sim.topk(k=300).indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e20167-6022-4ee0-8e95-ddd93dde38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "cluster_acc(pred_clu, all_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72e71e-2619-4f46-884d-630ce5ca068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "cluster_acc(pred_clu, all_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d59f21-7e3a-4d8d-9d92-564e0b290224",
   "metadata": {},
   "source": [
    "CLIP clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b1f66-2810-4e10-a66f-1e5e8ef58010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clu = np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bf01e-46bb-4aaa-ae59-260bfc32baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CLIP clustering acc \"\"\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_idx_img = []\n",
    "model.eval()\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    for batch in loader_f:\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images)\n",
    "                features = F.normalize(features, dim=-1).float()\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "        all_features.append(features.detach().cpu())\n",
    "        all_labels.append(label_clu)\n",
    "        all_idx_img.append(idx_img)\n",
    "        \n",
    "        pbar.update(1)\n",
    "        \n",
    "all_features = torch.cat(all_features, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "all_idx_img = torch.cat(all_idx_img, dim=0)\n",
    "\n",
    "# cluster_acc(pred_clu, all_labels.numpy())\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(all_labels.unique()), n_init=100, max_iter=1000, random_state=43)\n",
    "pred_clu = kmeans.fit_predict(all_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d553326-8716-4ad4-b895-c507c99fb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./pred_clu-{args.dataset_name}-train-clip.npy', pred_clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f4feb-e99d-4d4c-aa7c-5c4a801f030c",
   "metadata": {},
   "source": [
    "Cluster navigation (depends on clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de786f98-6bb8-4643-b070-de7187cd46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" topk prediction from CLIP \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_labels = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cdc6a-707c-45cf-8bda-d76f80bed2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "### per predicted-cluster voting\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "\n",
    "pred_kmeans_t = pred_kmeans\n",
    "# for it in range(10):\n",
    "#     print(f'iteration {it}')\n",
    "\n",
    "# cluster agg\n",
    "all_clu_pred = []\n",
    "for i in range(len(all_gt_voc.unique())):\n",
    "    selected = (pred_kmeans==i)\n",
    "    clu_pred = F.normalize(all_topk_voc[selected].sum(dim=0), dim=-1, p=1)\n",
    "    all_clu_pred.append(clu_pred)\n",
    "all_clu_pred = torch.stack(all_clu_pred, dim=0)\n",
    "\n",
    "# linear assignment\n",
    "print('is mutex assignment::', all_clu_pred.argmax(dim=-1).size(0)==all_clu_pred.argmax(dim=-1).unique().size(0))\n",
    "print('assignment collision num::', len(list(filter(lambda x: x>1, Counter(all_clu_pred.argmax(dim=-1).numpy()).values()))))\n",
    "\n",
    "cost_mat = all_clu_pred.cpu().numpy()\n",
    "res_ass = linear_assignment(cost_mat.max() - cost_mat)\n",
    "label_kmeans_voc = torch.tensor([res_ass[1][x.item()] for x in pred_kmeans])\n",
    "\n",
    "print('instance label acc::', (label_kmeans_voc==all_gt_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4979ece-f872-406c-ad93-72b2970f0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_labels = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f56c2b-1baf-434d-a4fe-7a35fc495272",
   "metadata": {},
   "outputs": [],
   "source": [
    "### subset vocab\n",
    "col_subset = all_clu_pred.nonzero()[:, 1]\n",
    "col_subset = col_subset.unique().sort().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bf5fc-fcbb-49df-a2c0-a6155255e9c3",
   "metadata": {},
   "source": [
    "KNN investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52721295-8e5c-4baf-9e70-0434168d1867",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "neighborhood_size = np.arange(5, 500, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    topk_res = similarity.topk(k=K+1)\n",
    "    topk_ind = topk_res.indices[:, 1:]\n",
    "    topk_match = torch.gather(label_match, 1, topk_ind)\n",
    "    topk_acc = topk_match.float().mean(dim=-1).mean()\n",
    "    print(f'K={K} acc={topk_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519d41-07c4-44e5-b649-5b170e3e1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.graph import compute_consensus_on_features\n",
    "neighborhood_size = np.arange(5, 50, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    _, _, pred_affinity = compute_consensus_on_features(all_features, k=K+1, q=0.8)\n",
    "    acc = ((pred_affinity & label_match).float().sum(1)/(pred_affinity.float().sum(1)+1e-10)).mean()\n",
    "    n_nn = pred_affinity.float().sum(1).mean()\n",
    "    print(f'K={K} acc={acc} n_nn={n_nn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970ede6-7bd9-408d-a903-30200acf6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_size = np.arange(5, 50, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    _, _, pred_affinity = compute_consensus_on_features(all_features, k=K+1, q=0.5)\n",
    "    acc = ((pred_affinity & label_match).float().sum(1)/(pred_affinity.float().sum(1)+1e-10)).mean()\n",
    "    n_nn = pred_affinity.float().sum(1).mean()\n",
    "    print(f'K={K} acc={acc} n_nn={n_nn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a399a6e-531d-41bd-b16e-c8b0b40f9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KNN matrix output \"\"\"\n",
    "neighborhood_size = 315\n",
    "similarity = all_features@all_features.T\n",
    "label_match = (all_labels.view(-1, 1)==all_labels.view(1, -1))\n",
    "K = neighborhood_size\n",
    "topk_res = similarity.topk(k=K+1)\n",
    "topk_ind = topk_res.indices\n",
    "\n",
    "torch.save(topk_ind, f'./cache/{args.dataset_name}-clip-knn-{neighborhood_size}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eeb7ed-a204-471f-bdf1-4472658c6669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_normalize = lambda x: x/x[:, 0].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc8f4d-0f9e-4300-a049-7d9da7a6b6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 3\n",
    "weight_normalize(instance_weight)[(instance_pred[:, 0]==all_gt_voc)][:, idx].mean(), \\\n",
    "weight_normalize(instance_weight)[(instance_pred[:, idx]==all_gt_voc)][:, idx].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ed802-7bfe-4264-b0a6-3e2568fdfc09",
   "metadata": {},
   "source": [
    "spatial features reweighting and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6086c-c4f7-40aa-adf7-8456702d768c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" visual reranking computation based on spatial features \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "instance_topk_voclabel_by_scd = all_clu_pred.topk(k=5).indices.index_select(0, record_pred_kmeans_t)\n",
    "all_spatial_label_pred = []\n",
    "all_label_voc = []\n",
    "all_label_match_rerank = []\n",
    "all_label_pred = []\n",
    "all_rerank_pred_voc = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                spatial_similarity = model.logit_scale.exp() * (features @ classifier[instance_topk_voclabel_by_scd[idx_img]].permute(0,2,1))\n",
    "                spatial_label_pred = spatial_similarity[:, 1:, :].topk(k=10, dim=1).values.mean(dim=1).argmax(dim=-1)\n",
    "                all_spatial_label_pred.append(spatial_label_pred.cpu())\n",
    "                all_label_voc.append(label_voc)\n",
    "                \n",
    "                ### global-spatial reranking\n",
    "                # global_label_attn = spatial_similarity[:, 0, :].softmax(dim=-1)\n",
    "                # global_spatial_mixed_sim_after_scaling = (spatial_similarity[:, 0, :].unsqueeze(1)*spatial_similarity[:, 1:, :])/100\n",
    "                # topk_spatial_sim_ind = spatial_similarity[:, 1:, :].topk(k=10, dim=1).indices\n",
    "                # spatial_label_attn = torch.gather(global_spatial_mixed_sim_after_scaling , 1, topk_spatial_sim_ind ).mean(dim=1).softmax(dim=-1)\n",
    "                # ind_increment = torch.arange(idx_img.size(0), device=args.device)\n",
    "                # global_spatial_mixed_sim_argmax = (global_label_attn.pow(0.75)*spatial_label_attn.pow(0.25)).argmax(dim=-1)\n",
    "                # GSRerank_pred_voc = instance_topk_voclabel_by_scd[idx_img][ind_increment, global_spatial_mixed_sim_argmax]\n",
    "                # label_match_rerank = GSRerank_pred_voc==label_voc\n",
    "                ### global-attention based spatial voting\n",
    "                global_spatial_attn = features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1)\n",
    "                topk_spatial_ind = global_spatial_attn.topk(k=10).indices\n",
    "                topk_spatial_features = torch.gather(features[:, 1:, :], 1, topk_spatial_ind)\n",
    "                sim_topk_spatial_features = \\\n",
    "                    model.logit_scale.exp() * (topk_spatial_features @ classifier.unsqueeze(0).permute(0,2,1))\n",
    "                \n",
    "                \n",
    "            all_label_match_rerank.append(label_match_rerank.cpu())\n",
    "            all_label_pred.append(global_label_attn.argmax(dim=-1).cpu())\n",
    "            all_rerank_pred_voc.append(GSRerank_pred_voc.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_spatial_label_pred = torch.cat(all_spatial_label_pred, dim=0)\n",
    "all_label_voc = torch.cat(all_label_voc, dim=0)\n",
    "all_label_match_rerank = torch.cat(all_label_match_rerank, dim=0)\n",
    "all_label_pred = torch.cat(all_label_pred, dim=0)\n",
    "all_rerank_pred_voc = torch.cat(all_rerank_pred_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684b3fc-7acd-4294-9af4-b081250a0fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'GSReranked instance Acc:: all_label_match_rerank={all_label_match_rerank.float().mean()}')\n",
    "print(f'SCD:: instance_topk_voclabel_by_scd={(instance_topk_voclabel_by_scd[:, 0]==all_label_voc).float().mean()}')\n",
    "print(f'GSR missing label:: N={len(set(all_gt_voc.unique().cpu().numpy()) - set(all_rerank_pred_voc.unique().cpu().numpy()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f391e4-e326-41dd-9134-a2699e2eba6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" visual spatial features \n",
    "- KNN difference between CLS and tokens\n",
    "\"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "instance_topk_voclabel_by_scd = all_clu_pred.topk(k=5).indices.index_select(0, record_pred_kmeans_t)\n",
    "\n",
    "method = ['cls-spatial-voting', \n",
    "          'cls-spatial-classifier-similarity-inspect',\n",
    "          'cls'][1]\n",
    "all_global_spatial_features = []\n",
    "all_labels_voc_gt = []\n",
    "all_scdknn_classifier_features = []\n",
    "all_entire_spatial_voting = []\n",
    "all_all_voting_voc_ind = []\n",
    "all_pred_voc_label = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                if method == 'cls-spatial-voting':\n",
    "                    # scdknn_classifier_features = classifier[instance_topk_voclabel_by_scd[idx_img]]\n",
    "                    cls_spatial_sim = (features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1))\n",
    "                    cls_knn_token = cls_spatial_sim.topk(k=10).indices\n",
    "                    token_similarity = model.logit_scale.exp() * (features @ classifier.unsqueeze(0).permute(0,2,1))\n",
    "                    knn_token = token_similarity.topk(k=5).indices\n",
    "                    voting_voc_ind = torch.gather(knn_token, 1, cls_knn_token.permute(0,2,1).repeat(1,1,5)).flatten(1)\n",
    "                    all_voting_voc_ind = []\n",
    "                    for i in range(voting_voc_ind.size(0)):\n",
    "                        val, ind = voting_voc_ind[i].unique(return_counts=True)\n",
    "                        all_voting_voc_ind.append(val[ind.topk(k=5).indices].cpu())\n",
    "                    all_voting_voc_ind = torch.stack(all_voting_voc_ind, dim=0)\n",
    "                    all_all_voting_voc_ind.append(all_voting_voc_ind)\n",
    "                elif method == 'cls-spatial-classifier-similarity-inspect': ### corrected, consider projection head\n",
    "                    n_similar_token = 20\n",
    "                    n_vote = 5\n",
    "                    token_similarity = model.logit_scale.exp() * (features @ classifier.unsqueeze(0).permute(0,2,1)) ### B x L+1 x V\n",
    "                    knn_token = token_similarity.topk(k=n_vote).indices ### B x L+1 x n_vote\n",
    "                    cls_spatial_sim = (features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1))\n",
    "                    cls_knn_token = cls_spatial_sim.topk(k=n_similar_token).indices + 1 ### B x 1 x n_similar_token\n",
    "                    # knn_token.gather(1, cls_knn_token)\n",
    "                    all_voting_voc_ind = []\n",
    "                    for i in range(idx_img.size(0)):\n",
    "                        val, count = knn_token[i, cls_knn_token[i, 0, :], :].flatten().unique(return_counts=True) ### n_similar_token x n_vote\n",
    "                        all_voting_voc_ind.append(val[count.topk(k=n_vote).indices].cpu())\n",
    "                    all_voting_voc_ind = torch.stack(all_voting_voc_ind, dim=0)\n",
    "                    all_all_voting_voc_ind.append(all_voting_voc_ind)\n",
    "                    \n",
    "                    all_pred_voc_label.append((features[:, 0, :]@classifier.t()).argmax(dim=-1).cpu())\n",
    "                    \n",
    "                elif method == 'cls':\n",
    "                    similarity = features[:, 0, :]@classifier.t()\n",
    "                    all_pred_voc_label.append(similarity.argmax(dim=-1).cpu())\n",
    "                # entire_spatial_voting = (features[:, 0:, :] @ classifier.unsqueeze(0).permute(0,2,1)).topk(k=5).indices\n",
    "                # torch.scatter_add(p, 1, entire_spatial_voting.flatten(1), torch.ones_like(entire_spatial_voting.flatten(1)).float()).argmax(dim=-1)\n",
    "#             all_global_spatial_features.append(features.cpu())\n",
    "            all_labels_voc_gt.append(label_voc)\n",
    "#             all_scdknn_classifier_features.append(scdknn_classifier_features.cpu().numpy())\n",
    "#             # all_entire_spatial_voting.append(entire_spatial_voting.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "# all_global_spatial_features = torch.cat(all_global_spatial_features, dim=0)\n",
    "all_labels_voc_gt = torch.cat(all_labels_voc_gt, dim=0)\n",
    "# all_scdknn_classifier_features = np.concatenate(all_scdknn_classifier_features)\n",
    "# # all_entire_spatial_voting = torch.cat(all_entire_spatial_voting, dim=0)\n",
    "all_all_voting_voc_ind = torch.cat(all_all_voting_voc_ind, dim=0)\n",
    "all_pred_voc_label = torch.cat(all_pred_voc_label, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e331be-480d-4c28-b77c-11acc0524cc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" offline clustering for visual spatial features \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cluster_kmeans = {}\n",
    "cluster_spectral = {}\n",
    "n_clusters = 10\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "        batch_size = features.size(0)\n",
    "        for i in range(batch_size):\n",
    "            self_sim = features[i]@features[i].t()\n",
    "            pred_spectral = spectral.fit_predict(self_sim.cpu().numpy())\n",
    "            pred_kmeans = kmeans.fit_predict(features[i].cpu().numpy())\n",
    "        cluster_kmeans[idx_img[i]] = pred_kmeans\n",
    "        cluster_spectral[idx_img[i]] = pred_spectral\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780607e-52bb-43cc-88e4-91f1bccdbb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870300b9-1da8-432a-a39c-a61999920035",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" clustering performance comparison \"\"\"\n",
    "n_clusters = 10\n",
    "idx = np.random.randint(low=0, high=510, size=1)\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', n_init=30)\n",
    "begin = time.time()\n",
    "pred_spectral = spectral.fit_predict(self_sim[idx].cpu().numpy())\n",
    "end = time.time()\n",
    "print(f'time={end-begin}')\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "begin = time.time()\n",
    "pred_kmeans = kmeans.fit_predict(features[idx].cpu().numpy())\n",
    "end = time.time()\n",
    "print(f'time={end-begin}')\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=0)\n",
    "tsne_features_tr = tsne.fit_transform(features[idx].cpu().numpy())\n",
    "\n",
    "plt.figure(dpi=64)\n",
    "plt.scatter(x=tsne_features_tr[:, 0], y=tsne_features_tr[:, 1], c=pred_spectral, s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=tsne_features_tr[pred_spectral==pred_spectral[0], 0], y=tsne_features_tr[pred_spectral==pred_spectral[0], 1], c='r', s=5) ### CLS\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=64)\n",
    "plt.scatter(x=tsne_features_tr[:, 0], y=tsne_features_tr[:, 1], c=pred_kmeans, s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=tsne_features_tr[pred_kmeans==pred_kmeans[0], 0], y=tsne_features_tr[pred_kmeans==pred_kmeans[0], 1], c='r', s=5) ### CLS\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eec163-3209-4dc2-8877-9a046f9f54e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_sim.mean(dim=[1,2]).mean(), self_sim.std(dim=[1,2]).mean(), self_sim_classifier.mean(dim=[0,1]), self_sim_classifier.std(dim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257ce01-470a-4fca-ad9d-575e2933d6af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = torch.zeros([512, classifier.size(0)], device=args.device)\n",
    "torch.scatter_add(p, 1, entire_spatial_voting.flatten(1), torch.ones_like(entire_spatial_voting.flatten(1)).float()).argmax(dim=-1), entire_spatial_voting.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10308782-81f6-4b32-ab51-6866c79676e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### dimensionality reduction with TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(2)\n",
    "idx = np.random.randint(low=0, high=len(all_global_spatial_features), size=[1])[0]\n",
    "image_features = all_global_spatial_features[idx]\n",
    "knn_classifier_features = torch.from_numpy(all_scdknn_classifier_features[idx])\n",
    "Nimg = image_features.size(0)\n",
    "tsne_features_input = torch.cat([image_features, knn_classifier_features], dim=0)\n",
    "tsne = TSNE(n_components=2, verbose=2)\n",
    "tsne_features_tr = tsne.fit_transform(tsne_features_input.numpy())\n",
    "image_features_tr = tsne_features_tr[:Nimg]\n",
    "knn_classifier_features_tr = tsne_features_tr[Nimg:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb99d0-1961-450a-b23d-9d01776d773c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=image_features_tr[1:, 0], y=image_features_tr[1:, 1], c='g', s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=image_features_tr[0, 0], y=image_features_tr[0, 1], c='r', s=5) ### CLS\n",
    "plt.scatter(x=knn_classifier_features_tr[:, 0], y=knn_classifier_features_tr[:, 1], c='b', s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e0118-2026-4af4-865a-797ab80e1dd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx = np.random.randint(low=0, high=len(all_global_spatial_features), size=[1])[0]\n",
    "image_features = all_global_spatial_features[idx]\n",
    "knn_classifier_features = torch.from_numpy(all_scdknn_classifier_features[idx])\n",
    "\n",
    "Nimg = image_features.size(0)\n",
    "N2 = knn_classifier_features.size(0)\n",
    "all_knn_classifier_features = classifier[(image_features.to(args.device) @ classifier.t()).topk(k=5).indices.flatten().unique()].cpu()\n",
    "tsne_features_input = torch.cat([image_features, knn_classifier_features, all_knn_classifier_features], dim=0)\n",
    "tsne = TSNE(n_components=2, verbose=2)\n",
    "tsne_features_tr = tsne.fit_transform(tsne_features_input.numpy())\n",
    "image_features_tr = tsne_features_tr[:Nimg]\n",
    "knn_classifier_features_tr = tsne_features_tr[Nimg:Nimg+N2]\n",
    "all_knn_classifier_features_tr = tsne_features_tr[Nimg+N2:]\n",
    "\n",
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=image_features_tr[1:, 0], y=image_features_tr[1:, 1], c='g', s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=image_features_tr[0, 0], y=image_features_tr[0, 1], c='r', s=5) ### CLS\n",
    "plt.scatter(x=all_knn_classifier_features_tr[:, 0], y=all_knn_classifier_features_tr[:, 1], c='y', s=5) ### spatial KNN\n",
    "plt.scatter(x=knn_classifier_features_tr[:, 0], y=knn_classifier_features_tr[:, 1], c='b', s=5) ### cluster KNN\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5ba19-3fd9-4329-86aa-8b38eaab0c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_knn, spatial_knn_counts = (image_features.to(args.device) @ classifier.t()).topk(k=5).indices[:, 0].unique(return_counts=True)\n",
    "(spatial_knn==all_labels_voc_gt[idx]).nonzero(), spatial_knn_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f2346-76ba-4b23-9ad5-75e81ff32394",
   "metadata": {},
   "source": [
    "SCD with shrinked vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e6634-c549-416e-89ff-34041414068b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" SCD with shrinked vocab \"\"\"\n",
    "classifier_selected = None\n",
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier[classifier_selected].t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                ### mapping @selected to vocab ind\n",
    "                B, C = prob_topk_ind.shape\n",
    "                prob_topk_ind = classifier_selected[prob_topk_ind.view(-1)].view(B, C)\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# pred_kmeans = torch.from_numpy(np.load(f'/home/sheng/OSZSL/ipynb/pred_clu-{args.dataset_name}-train-vit_dino-dino_stage1.npy'))\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "for t in range(3):\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d409fc-0177-4e54-b270-7f7d0f452870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_all_clu_pred = all_clu_pred\n",
    "# len(set_gt - set(final_all_clu_pred.topk(k=2).indices.flatten().unique().numpy().tolist()))\n",
    "\n",
    "# len(set_gt - set(all_clu_pred.topk(k=3).indices.flatten().unique().numpy().tolist()))\n",
    "\n",
    "# select_correct = (cluster_ind_voc.cpu()==all_gt_voc)\n",
    "\n",
    "# all_topk_val = torch.from_numpy(all_topk_val)#[select_correct]\n",
    "# prob_all_topk_val = torch.cat([all_topk_val, 1-all_topk_val.sum(dim=-1, keepdim=True)], dim=-1)\n",
    "\n",
    "# ent = - (prob_all_topk_val * (prob_all_topk_val+1e-30).log()).sum(dim=-1)\n",
    "\n",
    "# # import seaborn as sns\n",
    "# # sns.distplot(prob_all_topk_val[select_correct, 0], bins=100)\n",
    "# # sns.distplot(prob_all_topk_val[~select_correct, 0], bins=100)\n",
    "# # sns.scatterplot(x=prob_all_topk_val[:, 0], y=select_correct.float(), s=3, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9395f6-9497-4a0c-90aa-e85c2f26e81d",
   "metadata": {},
   "source": [
    "collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfb1e2-f2da-4787-b872-d08922d43bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "all_topk_val = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                topk_res = prob.topk(k=prob_k, dim=-1)\n",
    "                prob_topk_ind = topk_res.indices\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_topk_val.append(topk_res.values.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "all_topk_val = np.concatenate(all_topk_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc17b14-894c-4cab-bf09-1cd6e4636a09",
   "metadata": {},
   "source": [
    "confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc944ec3-21e1-4577-a721-d969514552e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classifier = get_classifier(args)\n",
    "# classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "# args.num_voc = classifier.size(0)\n",
    "# amp_autocast = torch.cuda.amp.autocast\n",
    "# ### collect variables\n",
    "# prob_k = 5\n",
    "# all_topk_voc = []\n",
    "# all_gt_voc = []\n",
    "# all_label_clu = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = 100 * logits @ classifier.t()\n",
    "#                 prob = similarity.softmax(-1)\n",
    "#                 prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "#                 all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "#                 all_gt_voc.append(label_voc)\n",
    "#                 all_label_clu.append(label_clu)\n",
    "#         pbar.update(1)\n",
    "\n",
    "# all_topk_voc = np.concatenate(all_topk_voc)\n",
    "# all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "# all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "use_confidence = True\n",
    "th_confidence = 0.5\n",
    "pred_kmeans = torch.from_numpy(np.load(f'/home/sheng/OSZSL/ipynb/pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "\n",
    "if use_confidence:\n",
    "    # ### SSL feature extraction\n",
    "    # ssl_prototypes = torch.zeros([pred_kmeans.unique().size(0), 768], device=args.device, dtype=torch.float64) ### C x D\n",
    "    # ssl_counter = torch.zeros(pred_kmeans.unique().size(0))\n",
    "    # with tqdm(total=len(loader_f)) as pbar:\n",
    "    #     modelf.eval()\n",
    "    #     modelf.to(args.device)\n",
    "    #     for idx_batch, batch in enumerate(loader_f):\n",
    "    #         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "    #         images = images.to(args.device)\n",
    "    #         with torch.no_grad():\n",
    "    #             features = modelf(images.float())\n",
    "    #             features = F.normalize(features, dim=-1)\n",
    "    #             for p in range(idx_img.size(0)):\n",
    "    #                 ssl_prototypes[pred_kmeans[p].long()] += features.to(torch.float64)[p]\n",
    "    #             # ssl_prototypes = torch.scatter_add(ssl_prototypes, 0, pred_kmeans[idx_img.long()].to(args.device).long(), features.to(torch.float64))\n",
    "    #             counter_voc_ind, counter_val = pred_kmeans[idx_img].unique(return_counts=True)\n",
    "    #             ssl_counter[counter_voc_ind.long()] += counter_val\n",
    "    #         pbar.update(1)\n",
    "    # ssl_prototypes = ssl_prototypes/ssl_counter.to(args.device).unsqueeze(-1)\n",
    "    # ssl_prototypes = F.normalize(ssl_prototypes, dim=-1)\n",
    "    # ### select confident instances\n",
    "    # all_prob = []\n",
    "    # all_sim = []\n",
    "    # with tqdm(total=len(loader_f)) as pbar:\n",
    "    #     modelf.eval()\n",
    "    #     modelf.to(args.device)\n",
    "    #     for idx_batch, batch in enumerate(loader_f):\n",
    "    #         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "    #         images = images.to(args.device)\n",
    "    #         with torch.no_grad():\n",
    "    #             features = modelf(images)\n",
    "    #             features = F.normalize(features, dim=-1)\n",
    "    #             sim = features@ssl_prototypes.float().t()\n",
    "    #             prob = (sim/1.0).amax(dim=-1)\n",
    "    #             all_prob.append(prob.cpu())\n",
    "    #             all_sim.append(sim.cpu())\n",
    "    #         pbar.update(1)\n",
    "    # all_prob = torch.cat(all_prob, dim=0)\n",
    "    # all_sim = torch.cat(all_sim, dim=0)\n",
    "    ### confidence thresholding\n",
    "    q = np.quantile(all_prob.numpy(), q=0.5)\n",
    "    selected = (all_prob>q)\n",
    "    ### computing\n",
    "    pred_kmeans_t = pred_kmeans[selected]\n",
    "    for t in range(3):\n",
    "        all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc[selected], voc_size=args.num_voc)\n",
    "        label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc[selected])\n",
    "        pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, \n",
    "                                                                  all_prob=None, instance_selected=selected)\n",
    "        set_pred = set(res_ass[1].tolist())\n",
    "        set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "        print('missing label::', len(set_gt - set_pred))\n",
    "        print('cluster acc', cluster_acc(y_true=all_label_clu[selected].numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "else:\n",
    "    pred_kmeans_t = pred_kmeans\n",
    "    for t in range(3):\n",
    "        all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "        label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "        pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "        set_pred = set(res_ass[1].tolist())\n",
    "        set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "        print('missing label::', len(set_gt - set_pred))\n",
    "        print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9cac48-7b09-47ac-b5f6-d67a19966a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" inspect cluster topk assigned classes \"\"\"\n",
    "# topk_cluster_label = all_clu_pred.topk(k=5).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40ee62-0996-46bf-8e3b-40d9b0fc1997",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pred_kmeans_t = pred_kmeans\n",
    "# # for t in range(5):\n",
    "# #     all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t, all_topk_voc)\n",
    "# #     label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "# #     pred_kmeans_t = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args, all_prob=None)\n",
    "# #     set_pred = set(res_ass[1].tolist())\n",
    "# #     set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "# #     print('missing label::', len(set_gt - set_pred))\n",
    "# #     print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "\n",
    "\n",
    "# \"\"\" get confident prediction \"\"\"\n",
    "# th = 0.5\n",
    "# amp_autocast = torch.cuda.amp.autocast\n",
    "# label_voc_kmeans_t = label_voc_kmeans_t.to(args.device)\n",
    "# cluster_ind = []\n",
    "# selected_ind = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = 100 * logits @ classifier.t()\n",
    "#                 prob = similarity[:, label_voc_kmeans_t].softmax(dim=-1)\n",
    "#                 selected = (prob.amax(dim=-1)>th)\n",
    "#                 selected_ind.append(selected.cpu())\n",
    "#         pbar.update(1)\n",
    "# selected_ind = torch.cat(selected_ind, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "# # precision = cluster_acc(y_true=all_label_clu[selected_ind].numpy(), y_pred=pred_kmeans_t[selected_ind].numpy())\n",
    "# # recall = selected_ind.mean()\n",
    "# print(f'confidence selection precision={precision} recall={recall}')\n",
    "\n",
    "# # np.save(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy', pred_kmeans_t.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688f3cb-d754-4c42-bf39-242029dbd35c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# 1. inverse entropy of prototype\n",
    "\n",
    "# 2. top1 sim of proto-image\n",
    "\n",
    "# 3. top1 sim of image-proto\n",
    "\n",
    "# \"\"\"\n",
    "# # candidate_ind = res_ass[1].unique()\n",
    "# # cls_proto_similarity = torch.zeros([len(dataset_f), candidate_ind.size()])\n",
    "# all_sim_proto_image_pred = []\n",
    "# all_sim_proto_image_gt = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch\n",
    "#         images = images.to(args.device)\n",
    "#         label_voc = label_voc.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "#                 prob = similarity.softmax(dim=-1)\n",
    "#                 all_sim_proto_image_pred.append(similarity[:, prob.argmax(dim=-1)].cpu())\n",
    "#                 all_sim_proto_image_gt.append(similarity[:, label_voc].cpu())\n",
    "#         pbar.update(1)\n",
    "        \n",
    "# all_sim_proto_image_pred = torch.cat(all_sim_proto_image_pred, dim=0)\n",
    "# all_sim_proto_image_gt = torch.cat(all_sim_proto_image_gt, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05625353-4773-4ed7-951c-d8974dfb3b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_sim_proto_image_pred = torch.cat(all_sim_proto_image_pred, dim=0)\n",
    "# all_sim_proto_image_gt = torch.cat(all_sim_proto_image_gt, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "# label_match = all_label_clu.view(-1, 1)@all_label_clu.view(1, -1)\n",
    "# pred_match_init = pred_kmeans.view(-1, 1)@pred_kmeans.view(1, -1)\n",
    "# pred_match = pred_kmeans_t.view(-1, 1)@pred_kmeans_t.view(1, -1)\n",
    "\n",
    "# pred_consensus = (pred_match_init==pred_match) \n",
    "# ((pred_consensus & label_match).float().sum(dim=-1) / (pred_consensus.sum(dim=-1)+1e-20)).mean()\n",
    "\n",
    "# (pred_consensus & label_match).float().sum(dim=-1).bool().float().mean()\n",
    "\n",
    "# all_clu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d94cc9-d78b-4cc7-b347-e73d7fc03602",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# ### MCMF\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "class_topk_assignment = MCMF_assign_labels(all_clu_pred.cpu().numpy(), K=2)\n",
    "\n",
    "# ### collect variables\n",
    "# prob_k = 5\n",
    "# all_mcmf_rerank_pred = []\n",
    "# all_gt_voc = []\n",
    "# all_label_clu = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "#                 valid_classifier_ind = class_topk_assignment[pred_kmeans[idx_img].long()].to(args.device)\n",
    "#                 bb, kk = valid_classifier_ind.size()\n",
    "#                 valid_classifier = classifier[valid_classifier_ind.flatten()].view(bb, kk, -1).permute(0,2,1)\n",
    "                \n",
    "#                 similarity = 100 * logits.unsqueeze(1) @ valid_classifier\n",
    "#                 prob = similarity.softmax(-1)\n",
    "                \n",
    "#                 all_mcmf_rerank_pred.append(valid_classifier_ind[prob.argmax(dim=-1)].cpu().numpy())\n",
    "#                 all_gt_voc.append(label_voc)\n",
    "#                 all_label_clu.append(label_clu)\n",
    "#         pbar.update(1)\n",
    "\n",
    "# all_mcmf_rerank_pred = np.concatenate(all_mcmf_rerank_pred)\n",
    "# all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "# all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "        \n",
    "# instance_assignment_pred = torch.zeros(all_mcmf_rerank_pred.shape[0])\n",
    "# for c in pred_kmeans.unique():\n",
    "#     select = (pred_kmeans==c)\n",
    "#     unique_ind, unique_count = torch.from_numpy(all_mcmf_rerank_pred[select]).unique(return_counts=True)\n",
    "#     instance_assignment_pred[select] = unique_ind[unique_count.argsort()[-1]].item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb5d88-4184-408c-9363-ac2e0d74144f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### class-wise assignment to instance prediction\n",
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0), class_topk_assignment.size(1)).to(class_topk_assignment.device).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = class_topk_assignment[c].view(-1, class_topk_assignment.size(1))\n",
    "\n",
    "all_mcmf_instance_pred = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                valid_classifier_ind = instance_assignment_pred[idx_img].long().to(args.device)\n",
    "                bb, kk = valid_classifier_ind.size()\n",
    "                valid_classifier = classifier[valid_classifier_ind.flatten()].view(bb, kk, -1).permute(0,2,1)\n",
    "                \n",
    "                similarity = 100 * logits.unsqueeze(1) @ valid_classifier\n",
    "                prob = similarity.softmax(-1)\n",
    "                \n",
    "                all_mcmf_instance_pred.append(valid_classifier_ind[torch.arange(valid_classifier_ind.size(0)), \n",
    "                                                                   prob.argmax(dim=-1).squeeze(-1)].cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "    \n",
    "all_mcmf_instance_pred = np.concatenate(all_mcmf_instance_pred)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# pred_kmeans_t = pred_kmeans\n",
    "\n",
    "# history_set_pred = []\n",
    "# for t in range(3):\n",
    "#     record_pred_kmeans_t = pred_kmeans_t\n",
    "#     all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "#     label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "#     pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "#     set_pred = set(res_ass[1].tolist())\n",
    "#     set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "#     print('missing label::', len(set_gt - set_pred))\n",
    "#     print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "#     history_set_pred.append(set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06cace-457b-4845-bfbe-78954de01973",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0)).to(pred_kmeans.device).long()\n",
    "cluster_assignment_argmax = all_clu_pred.argmax(dim=-1)\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = cluster_assignment_argmax[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf2c04-7a24-4da7-9bb5-4a1771cb3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0), class_topk_assignment.size(1)).to(class_topk_assignment.device).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = class_topk_assignment[c].view(-1, class_topk_assignment.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddf3a3-5c40-411a-94b0-0f8fd1033079",
   "metadata": {},
   "outputs": [],
   "source": [
    "((instance_assignment_pred[:, 0]==all_gt_voc) | (instance_assignment_pred[:, 1]==all_gt_voc)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff5b8b-7e5a-4501-813e-a8b8f49b9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.from_numpy(all_mcmf_instance_pred)==all_gt_voc).float().mean(), (instance_assignment_pred==all_gt_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3dfd7-b123-48ed-8b03-f0412b0fba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "(instance_assignment_pred==all_gt_voc).float().mean(), len(set(all_gt_voc.unique().numpy()) - set(class_topk_assignment.unique().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43394174-62af-486b-9343-d8b2a4ff98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_topk_assignment.flatten().unique().long(), all_gt_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9f42b-9961-4a24-b172-265501467003",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_mcmf_rerank_pred.squeeze(1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2b726-9910-44ba-bd22-f9232e038cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isin(all_gt_voc.unique(), instance_assignment_pred.unique().long()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa41c0-83b6-4343-96ec-26b7a5abff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ind, unique_count = torch.from_numpy(all_mcmf_rerank_pred[select]).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc8434-c573-4e2b-8ff8-90f6cb4cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ind[unique_count.argsort()[-1]].item(), unique_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8830f-3235-4f83-a063-a332d6236112",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56630fb-9c21-4b54-a78f-06c271abc438",
   "metadata": {},
   "source": [
    "test for MCMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196a123-fccb-4f9a-bc97-88427099915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "class_topk_assignment = MCMF_assign_labels(all_clu_pred.cpu().numpy(), K=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9e34a-29d8-4855-998d-c1a06d283db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" overlap with SCD linear assignment prediction \n",
    "NOTE: MCMF is not ordered prediction\n",
    "\"\"\"\n",
    "for i in range(K):\n",
    "    overlap = (all_clu_pred.argmax(dim=-1).cpu()==class_topk_assignment[:, i]).sum()\n",
    "    print(overlap.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f584cab-0721-4b67-9223-2097b76a8cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('missing label:', len(set_gt - set(class_topk_assignment.unique().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4082f41-7789-4577-b505-2eb33b6788b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" reranking with voting similarity \"\"\"\n",
    "class_topk_assignment_ordered = torch.gather(class_topk_assignment, 1, torch.gather(all_clu_pred, 1, class_topk_assignment).argsort(descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab171407-10f8-4d1a-b1bd-7068d4ac5556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(class_topk_assignment_ordered[record_pred_kmeans_t][:, 1]==all_gt_voc).float().mean() #, (class_topk_assignment_ordered[record_pred_kmeans_t][:, 0]==cluster_ind_voc.cpu()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde93f02-13a3-498c-ba18-67de692b8e3b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641aa10-d6ea-4434-b4b3-57058a9e1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d793092-23ab-497e-9759-714c91e55e51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac099527-5211-4e10-a50f-1ebc926834c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" topk prediction from CLIP \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "# initial topK prediction from CLIP\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_prob = []\n",
    "all_max_ind = []\n",
    "all_topk_vocinds = []\n",
    "all_label_clu = []\n",
    "all_topk_vals = []\n",
    "all_topk_inds = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "                all_max_ind.append(prob.argmax(dim=-1).cpu())\n",
    "                all_topk_vocinds.append(prob.topk(k=10, dim=-1).indices.cpu())\n",
    "                \n",
    "                batch_topk_res = prob.topk(k=20, dim=-1)\n",
    "                all_topk_vals.append(batch_topk_res.values.cpu())\n",
    "                all_topk_inds.append(batch_topk_res.indices.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "# all_prob = torch.cat(all_prob, dim=0)\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "all_max_ind = torch.cat(all_max_ind, dim=0)\n",
    "all_topk_vocinds = torch.cat(all_topk_vocinds, dim=0)\n",
    "all_topk_vals = torch.cat(all_topk_vals, dim=0)\n",
    "all_topk_inds = torch.cat(all_topk_inds, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b4a31-0d72-45d8-bcdd-97c69944fecb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### text proto inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159430a-4362-40b9-9181-1c08c1de63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN proto analysis\n",
    "text_sim = classifier[all_gt_voc.unique(), :]@classifier.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5c99a-edbd-485e-9082-ab819e27db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_topk = text_sim.topk(k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a41ba7-f29d-4697-ae19-399d222cc970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(np.array([vocab.mapping_idx_names[t.item()] for t in text_topk.indices[:, :].flatten().cpu()]).reshape(text_sim.size(0), -1).tolist(), compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20703-1fc0-4791-9242-591d6a7b10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "sns.distplot(all_topk_vals[:, 0].cpu().numpy(), bins=200)\n",
    "sns.distplot(all_topk_vals[:, 1].cpu().numpy(), bins=200)\n",
    "sns.distplot(all_topk_vals[:, 2].cpu().numpy(), bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075cda2-8944-48de-b2f5-8e9517de5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = (all_topk_vals[:, 0]>0.7)\n",
    "'top1 acc', (all_gt_voc[selected] == all_max_ind[selected]).float().mean(), \\\n",
    "'selected percentile', selected.float().mean(), \\\n",
    "'class diversity', len(set(all_gt_voc.unique().numpy()) - set(all_max_ind[selected].unique().numpy())), \\\n",
    "'topk inclusion', torch.stack([all_topk_vocinds[selected, i]==all_gt_voc[selected] for i in range(all_topk_vocinds.size(1))], dim=1).float().sum(dim=-1).bool().float().mean(), \\\n",
    "'selected sample pred voc size', len(all_max_ind[selected].unique()), \\\n",
    "'average selected instance number per class', selected.sum()/len(all_gt_voc.unique()),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e444ff3-7837-4e21-a5eb-d21c6111fd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" initial clip assignment \"\"\"\n",
    "list(filter(lambda x: x[1]<100, [(i.item(), (all_max_ind==i).sum().item()) for i in all_gt_voc.unique()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15937caa-ab71-4efd-b334-634f64485d73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### text to image entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9165942-c523-4821-9ddf-da7e57c3e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "### get all label and predicted label\n",
    "all_label_voc = []\n",
    "all_pred_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                pred_voc = prob.argmax(dim=-1)\n",
    "        all_label_voc.append(label_voc)\n",
    "        all_pred_voc.append(pred_voc.cpu())\n",
    "        all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "all_label_voc = torch.cat(all_label_voc, dim=0)\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "                \n",
    "### compute entropy\n",
    "set_all_label_voc = all_label_voc.unique()\n",
    "set_all_pred_voc = all_pred_voc.unique()\n",
    "selected_classifier_ind = torch.cat([set_all_label_voc, set_all_pred_voc], dim=0).unique()\n",
    "all_similarity = []\n",
    "all_selected_sim = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        label_voc = label_voc.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                all_selected_sim.append(similarity[:, selected_classifier_ind].cpu())\n",
    "                all_similarity.append(similarity.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "        \n",
    "all_selected_sim = torch.cat(all_selected_sim, dim=0)\n",
    "all_similarity = np.concatenate(all_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ded316-eb1c-43f6-93a0-b65682197242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kmeans_t = torch.from_numpy(np.load(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy'))\n",
    "classwise_all_selected_sim = []\n",
    "for c in pred_kmeans_t.unique():\n",
    "    subset = (pred_kmeans_t==c)\n",
    "    classwise_all_selected_sim.append(all_selected_sim[subset, :].mean(dim=0).cpu())\n",
    "classwise_all_selected_sim = torch.stack(classwise_all_selected_sim, dim=0)\n",
    "p = classwise_all_selected_sim.float().softmax(dim=0)\n",
    "ent = (-p*(p+1e-10).log2()).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446d82a-1e89-4e68-a08f-2924614cc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "softmax(all_similarity, axis=0)\n",
    "pred_kmeans_t = torch.from_numpy(np.load(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy'))\n",
    "classwise_all_sim = []\n",
    "for c in pred_kmeans_t.unique():\n",
    "    subset = (pred_kmeans_t==c)\n",
    "    classwise_all_sim.append(all_selected_sim[subset, :].mean(dim=0).cpu())\n",
    "classwise_all_sim = torch.stack(classwise_all_sim, dim=0)\n",
    "p_all = classwise_all_sim.float().softmax(dim=0)\n",
    "ent_all = (-p_all*(p_all+1e-10).log2()).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f95cb-d240-4f8e-bff3-89d1ee2b0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = torch.nan_to_num(ent)\n",
    "ent_gt = ent[torch.isin(selected_classifier_ind, set_all_label_voc)]\n",
    "ent_pred = ent[torch.isin(selected_classifier_ind, set_all_pred_voc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2bd40-54aa-4cd3-8b70-9818908b212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=128)\n",
    "sns.distplot(ent_gt.numpy(), bins=100)\n",
    "sns.distplot(ent_pred.numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5420f-f0cd-4283-b407-23b711156895",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ent_gt>2).sum(), (ent_gt>3).sum(), \\\n",
    "(ent_pred<2).sum(), (ent_pred<3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423501f-0554-4cfc-8457-5d5b2deb434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ent_gt>2).sum(), (ent_gt>3).sum(), \\\n",
    "(ent_pred<2).sum(), (ent_pred<3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b0a19-6e75-46b1-bc28-c977acbaca11",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### class-wise distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907b0c5-c4ad-47e4-b212-871cf13a6ae9",
   "metadata": {},
   "source": [
    "collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb4816-1225-43a5-a842-f42334f28c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" collect variables \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# initial topK prediction from CLIP\n",
    "prob_k = 5\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_inst_topk_ind_voc = []\n",
    "all_inst_topk_val_voc = []\n",
    "all_inst_max_pred = []\n",
    "all_img_idx = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk = prob.topk(k=prob_k, dim=-1)\n",
    "                \n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_inst_topk_ind_voc.append(prob_topk.indices[:, :prob_k+1].cpu())\n",
    "                all_inst_topk_val_voc.append(prob_topk.values[:, :prob_k+1].cpu())\n",
    "                all_inst_max_pred.append(prob.argmax(dim=-1).cpu())\n",
    "                all_img_idx.append(idx_img)\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_inst_topk_ind_voc = torch.cat(all_inst_topk_ind_voc, dim=0)\n",
    "all_inst_topk_val_voc = torch.cat(all_inst_topk_val_voc, dim=0)\n",
    "all_inst_max_pred = torch.cat(all_inst_max_pred, dim=0)\n",
    "all_img_idx = torch.cat(all_img_idx, dim=0)\n",
    "\n",
    "# res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "# all_clu_pred = res['all_clu_pred']\n",
    "# label_voc_kmeans = res['label_voc_kmeans']\n",
    "# pred_kmeans_t = res['pred_kmeans_t']\n",
    "# cluster_ind_voc = res['cluster_ind_voc']\n",
    "# record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "# all_gt_voc = res['all_gt_voc']\n",
    "# all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0c7c3-a560-4944-be35-4984d7286aac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.num_voc = classifier.size(0)\n",
    "\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "history_mapping_assignment_clu = []\n",
    "for t in range(3):\n",
    "    record_pred_kmeans_t = pred_kmeans_t\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_inst_topk_ind_voc, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_label_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_label_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    history_mapping_assignment_clu.append(pred_kmeans_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f3f70-fa95-4d12-8a68-db76c60f3f72",
   "metadata": {},
   "source": [
    "##### class-wise feaature space with KNN prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bb374-07de-4539-8b90-a1c2f1c419f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "\n",
    "all_class_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                # if select[idx_img].sum().item()==0:\n",
    "                #     pbar.update(1)\n",
    "                #     continue\n",
    "                all_class_features.append(features.cpu().numpy())\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "all_class_features = np.concatenate(all_class_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6367e97-4145-40a5-b4c1-cac6d43e0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### randomly select a class of features \n",
    "np.random.seed(5)\n",
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "selected_all_class_features = torch.from_numpy(all_class_features)[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8553e-8c3f-4b8c-811f-d66ab399638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute scd confusing classifier\n",
    "i = torch.arange(select.size(0))[select]\n",
    "for x in history_mapping_assignment_clu[:-1]:\n",
    "    i = x[i]\n",
    "ind, counts = i.unique(return_counts=True)\n",
    "all_confusing_classifier_ind = all_clu_pred[ind[counts.argmax()]].topk(k=3).indices\n",
    "\n",
    "confusing_classifier = classifier[all_confusing_classifier_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299acae-d0bb-4b15-8169-b2b28c2d2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "### distances among confusing classifiers\n",
    "triu_confusing_classifier = (confusing_classifier@confusing_classifier.t()).triu(1)\n",
    "dist_confusing_classifier = triu_confusing_classifier[triu_confusing_classifier.nonzero(as_tuple=True)]\n",
    "print(dist_confusing_classifier.mean(), dist_confusing_classifier.max(), dist_confusing_classifier.min())\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(dist_confusing_classifier.cpu().numpy(), bins=10)\n",
    "plt.show()\n",
    "\n",
    "### distances among gt classifier and confusing classifiers\n",
    "gt_voc_label = all_gt_label_voc[select].unique()[0].item()\n",
    "classifier[gt_voc_label].view(1, -1)@confusing_classifier.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0c3dd-d4d5-43ed-a22d-2718d9f1ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_voc_label in all_confusing_classifier_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39606dc-cf07-4b8c-996c-70f8f9f85e93",
   "metadata": {},
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c855b4-e5a0-489f-8de1-1b443c5426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "selected_all_class_features = all_class_features[select.numpy()]\n",
    "\n",
    "### compute scd confusing classifier\n",
    "i = torch.arange(select.size(0))[select]\n",
    "for x in history_mapping_assignment_clu[:-1]:\n",
    "    i = x[i]\n",
    "ind, counts = i.unique(return_counts=True)\n",
    "all_confusing_classifier_ind = list(set(all_clu_pred[ind[counts.argmax()]].topk(k=5).indices.flatten().numpy()) )\n",
    "                                    # | set(all_inst_topk_ind_voc[select].unique().numpy()))\n",
    "\n",
    "all_confusing_classifier = classifier[torch.tensor(all_confusing_classifier_ind), :].cpu().numpy()\n",
    "all_features_vis = np.concatenate([selected_all_class_features, all_confusing_classifier, classifier[c].view(1, -1).cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9f2ca-ec79-4687-b78f-4bf020dc5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, \n",
    "            n_iter=1000, \n",
    "            # perplexity=10,\n",
    "            method='exact',\n",
    "           )\n",
    "tr_all_features_vis = tsne.fit_transform(all_features_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f19e5b-a25c-4ba8-b292-f5cd06956856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=tr_all_features_vis[:selected_all_class_features.shape[0], 0], y=tr_all_features_vis[:selected_all_class_features.shape[0], 1], s=5, c='b', alpha=0.6)\n",
    "plt.scatter(x=tr_all_features_vis[selected_all_class_features.shape[0]:-1, 0], y=tr_all_features_vis[selected_all_class_features.shape[0]:-1, 1], s=5, c='g', alpha=0.8)\n",
    "plt.scatter(x=tr_all_features_vis[-1, 0], y=tr_all_features_vis[-1, 1], s=8, c='r', alpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fdeec-8a34-4438-b8d8-e49fbe8a6843",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### spatial region visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220fb90-11d5-42c5-aa86-fc28ab55c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "from PIL import Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea03a00-fc6f-43c0-9aef-35e9153ed7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. collect variables\n",
    "upper bound visualization test\n",
    "\"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_inst_topk_ind_voc, voc_size=args.num_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6ad22-bf9a-42f9-9af6-bb752ac2fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cluster to instance topk\n",
    "cluster_topk_ind = all_clu_pred.topk(k=5).indices\n",
    "inst_topk_ind = cluster_topk_ind[pred_kmeans.long(), ...]\n",
    "### sample one cluster \n",
    "sampled_cluster_idx = torch.randint(low=0, high=all_gt_label_clu.max(), size=[1])\n",
    "inst_select = all_gt_label_clu==sampled_cluster_idx.item()\n",
    "\n",
    "sampled_img_idx = np.random.choice(inst_select.nonzero().flatten().numpy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb46779-a632-4c67-a04e-9d1d378f9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "model.eval()\n",
    "with amp_autocast():\n",
    "    with torch.no_grad():\n",
    "        image, label_voc, label_clu, _ = dataset_f[sampled_img_idx[idx]]\n",
    "        image = image.to(args.device)\n",
    "        \n",
    "        candidate_voc_labels = inst_topk_ind[sampled_img_idx[idx]]\n",
    "        candidate_voc_synsets = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name() for x in candidate_voc_labels ]\n",
    "        gt_class_label = mapping_vocidx_to_synsets(label_voc, vocab)[0].name()\n",
    "        \n",
    "        features = model.visual(image.unsqueeze(0), return_spatial=True)\n",
    "        features = F.normalize(features, dim=-1)\n",
    "        \n",
    "        spatial_sim = 100 * features[0, 1:, :]@classifier[candidate_voc_labels].t()\n",
    "        spatial_softmax = spatial_sim.softmax(dim=-1)\n",
    "        spatial_ind = spatial_softmax.argmax(dim=-1).reshape(14, 14)\n",
    "        spatial_score = spatial_softmax.amax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        spatial_sim_entire = 100 * features[0, 1:, :]@classifier.t()\n",
    "        spatial_softmax_entire = spatial_sim_entire.softmax(dim=-1)\n",
    "        spatial_sim_entire = spatial_sim_entire[:, candidate_voc_labels]\n",
    "        spatial_ind_entire = spatial_softmax_entire.argmax(dim=-1).reshape(14, 14)\n",
    "        spatial_score_entire = spatial_softmax_entire.amax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        sim_self = 10 * features[0, 0, :]@features[0, 1:, :].t()\n",
    "        sim_self = sim_self.softmax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        candidate_voc_topk_labels = (100 * features[0, 0, :]@classifier.t()).topk(k=10).indices\n",
    "        candidate_voc_topk_synsets = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name() for x in candidate_voc_topk_labels ]\n",
    "        \n",
    "        features = model.visual(image.unsqueeze(0), return_spatial=True, with_proj=False)\n",
    "        features = F.normalize(features, dim=-1)\n",
    "        \n",
    "        image, label_voc, label_clu, _ = dataset_r[sampled_img_idx[idx]]\n",
    "        sim_self = 10 * features[0, 0, :]@features[0, 1:, :].t()\n",
    "        sim_self = sim_self.softmax(dim=-1).reshape(14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d16c8-f23a-4ef2-900b-fdb41006bbdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_ind, spatial_score, spatial_ind_entire, spatial_score_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e305481-005d-4d73-914b-011aa97fa716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint([gt_class_label, candidate_voc_synsets, candidate_voc_topk_synsets], compact=True)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=4, dpi=128)\n",
    "ax[0,0].imshow(np.array(image.resize([256,256])))\n",
    "ax[0,0].axis(False)\n",
    "ax[0,1].imshow(spatial_score.cpu().numpy())\n",
    "ax[0,1].axis(False)\n",
    "ax[0,2].imshow(spatial_ind.cpu().numpy())\n",
    "ax[0,2].axis(False)\n",
    "ax[0,3].imshow(spatial_score.cpu().numpy()>0.6)\n",
    "ax[0,3].axis(False)\n",
    "\n",
    "ax[1,0].imshow(np.array(image.resize([256,256])))\n",
    "ax[1,0].axis(False)\n",
    "ax[1,1].imshow(spatial_score_entire.cpu().numpy())\n",
    "ax[1,1].axis(False)\n",
    "ax[1,2].imshow(spatial_ind_entire.cpu().numpy()==gt_voc_label)\n",
    "ax[1,2].axis(False)\n",
    "ax[1,3].imshow(spatial_score_entire.cpu().numpy()>0.5)\n",
    "ax[1,3].axis(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sim_self.cpu().numpy()>sim_self.flatten().topk(k=10).values[-1].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d0b01-e3dc-4ebd-a3ac-5b18633a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ mapping_vocidx_to_synsets(x.item(), vocab)[0].definition() for x in candidate_voc_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77a81a-7092-4ea4-b5fe-a436208081b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = (features[0, 1:, :]@features[0, 1:, :].t())[(sim_self.cpu().numpy()>sim_self.flatten().topk(k=10).values[-1].item()).flatten()]\n",
    "for i in range(s.size(0)):\n",
    "    plt.imshow(s[i].reshape(14, 14).cpu().numpy()>s[i].topk(k=20).values[-1].item())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9919f-7380-4aa5-9927-a49607e70ffa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Linguistic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d4eea-51fe-48e4-a9d1-d6e8177699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "from PIL import Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fef3e7-1463-4e39-af54-480565eaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mutex_prompt(args, model, pairs):\n",
    "    \"\"\"\n",
    "    return:\n",
    "        class_embedding: tensor([P x D])\n",
    "    \"\"\"\n",
    "    with open('../templates_small_mutex.json', 'rb') as f:\n",
    "        data = json.load(f)['imagenet']\n",
    "        \n",
    "    all_prompts = []\n",
    "    for p in pairs:\n",
    "        prompts = []\n",
    "        for r in data:\n",
    "            prompts.append(r.format(p[0], p[1]))\n",
    "        all_prompts.append(prompts)\n",
    "    all_prompts = np.array(all_prompts)\n",
    "    n_pairs, n_templates = all_prompts.shape\n",
    "    \n",
    "    # model, preprocess = clip.load(args.arch)\n",
    "    # model.to(args.device).eval()\n",
    "    \n",
    "    texts = tokenize(all_prompts.ravel()).to(args.device) # tokenize\n",
    "    class_embeddings = model.encode_text(texts) # embed with text encoder\n",
    "    class_embeddings = class_embeddings.view(n_pairs, n_templates, -1)\n",
    "    class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "    class_embedding = class_embeddings.mean(dim=1)\n",
    "    class_embedding /= class_embedding.norm(dim=-1, keepdim=True)\n",
    "    return class_embedding, all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ae1b5-a2d6-474e-a02b-ffef04608e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(args.arch)\n",
    "model.to(args.device).eval()\n",
    "\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23e684-58a2-4d06-a7fc-a017446cb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_topk_pred_voc_ind = all_clu_pred.topk(k=5).indices\n",
    "class_topk_class_names = np.array([ mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] \n",
    "                                   for x in class_topk_pred_voc_ind.flatten().numpy() ]).reshape(-1, 5)\n",
    "class_mutex_templates = []\n",
    "for row in class_topk_class_names:\n",
    "    class_mutex_templates.append([[x, y] for i, x in enumerate(row) for j, y in enumerate(row) if i!=j])\n",
    "\n",
    "idx_class = 12\n",
    "class_embedding_pair, prompts_pair = build_mutex_prompt(args, model, class_mutex_templates[idx_class])\n",
    "classifier = get_classifier(args)\n",
    "class_embedding_single = classifier[class_topk_pred_voc_ind[idx_class]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5df626-13ac-4b93-9390-2f1152d9be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim = class_embedding_single@class_embedding_single.t()\n",
    "sim_pair = class_embedding_pair.float() @ class_embedding_pair.float().t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd382f8-5568-4978-b3e8-e6585c1d102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        p1 = [i//4, i%4]\n",
    "        p2 = [j//4, j%4]\n",
    "        if (p1[0]==p2[1]) and (p1[1]==p2[0]) and (p1[0]!=p1[1]) and (p2[0]!=p2[1]):\n",
    "            res.append(sim_pair[i, j].item())\n",
    "print(np.mean(res))\n",
    "print(self_sim.triu(1)[self_sim.triu(1).nonzero(as_tuple=True)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bba420-e9b1-4e25-be6d-c2407d9b5d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa441492-f2e6-46db-8c94-d0b7542634c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b6d8b-9bdd-4034-94a5-16d2fdfa4806",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872be6e4-28f3-422b-b7d0-d90c8f554dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect features and labels\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_img_idx = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_img_idx.append(idx_img)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_img_idx = torch.cat(all_img_idx, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dc601-24ca-4ac9-9136-7e8a5f37dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_store = {\n",
    "    'all_gt_label_voc': all_gt_label_voc.cpu(),\n",
    "    'all_gt_label_clu': all_gt_label_clu.cpu(),\n",
    "    'all_img_idx': all_img_idx.cpu(),\n",
    "    'all_features': all_features,\n",
    "}\n",
    "torch.save(clip_store, f'./cache/clip_store-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1114234-f9e4-4274-858f-dfb0f62aa349",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_name = 'make_entity13'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9dbb29-97f8-4457-95de-d8260d896a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Classifier Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052655e-3e69-464b-afe0-0caa99b82767",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_name = 'make_nonliving26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ed488-fab0-4b78-ab5c-78c054069bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()\n",
    "\n",
    "classifier = get_classifier(args)\n",
    "classifier = F.normalize(classifier.float(), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769921b6-b0ae-497d-a178-33c612569d78",
   "metadata": {},
   "source": [
    "collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae32f8-a5ec-4687-8423-296b8ef95c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']\n",
    "\n",
    "\n",
    "### collect features and labels\n",
    "all_knn_classifier_ind = []\n",
    "all_knn_classifier_val = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        _, label_voc, label_clu, idx_img = batch\n",
    "        batch_features = torch.from_numpy(all_features[idx_img.numpy()])\n",
    "        batch_features = F.normalize(batch_features.float(), dim=-1).to(args.device)\n",
    "        sim = batch_features@classifier.t()\n",
    "        sim_topk = sim.topk(k=5)\n",
    "        all_knn_classifier_ind.append(sim_topk.indices.cpu())\n",
    "        all_knn_classifier_val.append(sim_topk.values.cpu())\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "all_knn_classifier_ind = torch.cat(all_knn_classifier_ind, dim=0)\n",
    "all_knn_classifier_val = torch.cat(all_knn_classifier_val, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbaced4-5d9f-41c0-bdfe-a505669394a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*all_knn_classifier_val).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2d647-d200-41f7-a1d6-3f58bf3e8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_knn_classifier_ind, f'./cache/clip_img_knn-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487d13c-0071-428a-9a48-55d903bed11e",
   "metadata": {},
   "source": [
    "#### Classifier study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fdb79-2d76-4965-b730-92335270fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_knn_classifier_ind = torch.load(f'./cache/clip_img_knn-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cca80d-b55c-472c-a607-bbbaaba2eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_knn_classifier_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b1aac-aa7c-4a7e-b635-d168a4ec5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind, val = all_knn_classifier_ind.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a4c1c-c23c-4c0e-9275-d00a3a567bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load SCD results\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24460e4a-1b0b-444a-8351-549de3080b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-clip.npy'))\n",
    "args.num_voc = classifier.size(0)\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_knn_classifier_ind, voc_size=args.num_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee0f9c-f1d5-4e7f-bba5-f2f8e1d7edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "K = all_knn_classifier_ind.size(1)\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=5).indices\n",
    "\n",
    "print('acc', (instance_assigned_pred[:, 0]==all_gt_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f15c4a-bddb-44ce-97d4-b0215a71b063",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_select_idx = 2\n",
    "class_select = (pred_kmeans==class_select_idx)\n",
    "study_candidates = all_clu_pred.topk(k=3).indices[class_select_idx]\n",
    "ind, val = all_gt_voc[class_select].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b9656-c95c-433d-8066-8da67604f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "\n",
    "print([mapping_vocidx_to_synsets(c.item(), vocab)[0].name().split('.')[0] for c in study_candidates])\n",
    "print([mapping_vocidx_to_synsets(c.item(), vocab)[0].definition() for c in study_candidates])\n",
    "\n",
    "# descriptions = \\\n",
    "# [\n",
    "#     \"A photo of an aircraft_carrier. It has a long, flat deck, with a large superstructure at the back, and a tall tower at the front. It is usually painted grey, and has multiple aircrafts parked on the deck.\",\n",
    "#     \"A photo of a parking_meter. A metal box with a coin slot, a digital display, and a lever or button to activate the timer.\",\n",
    "#     \"A photo of an ambulance. A vehicle typically characterized by a bright red or orange color, a siren, and a medical cross symbol.\",\n",
    "# ]\n",
    "descriptions = \\\n",
    "[\n",
    "    \"A photo of a Winnebago. The Winnebago language is characterized by a distinct set of phonemes and a unique set of grammatical structures.\",\n",
    "    \"A photo of an ambulance. A vehicle typically characterized by a bright red or orange color, a siren, and a medical cross symbol.\",\n",
    "    \"A photo of police_van. A large, box-shaped vehicle with a distinctive black and white paint job and a barred window in the back.\"\n",
    "]\n",
    "descriptions = \\\n",
    "[\n",
    "    \"A photo of a gobiesox. Small, slender fish with a laterally compressed body and two separate dorsal fins.\",\n",
    "    \"A photo of a sock. A foot covering that is typically made of cloth, reaching from the ankle to the knee.\",\n",
    "    \"A photo of a athletic_sock. A sock typically made of a lightweight, breathable material with a reinforced heel and toe for added durability.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e07785-bb8e-46b9-948a-b133e44d3413",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_classifier = tokenize(descriptions, truncate=True).to(args.device)\n",
    "study_classifier = model.encode_text(study_classifier)\n",
    "study_classifier = study_classifier/study_classifier.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8242b1-613c-43d9-853d-1bd90c56d530",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96014516-c647-4578-a043-fd6412c4c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = torch.from_numpy(all_features[class_select]).to(args.device)\n",
    "class_label = all_gt_label_voc[class_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf12165-30f2-40fe-949c-e0eeec2b815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind, val = class_label.unique(return_counts=True)\n",
    "mapping_vocidx_to_synsets(ind[val.argmax(dim=-1)].item(), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58536a4-8e31-476a-94c7-094da5d3e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(study_candidates[(class_features.float() @ study_classifier.float().t()).argmax(dim=-1)]==class_label).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062ab4d-c06a-42ba-88ba-af8376ee81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(class_label==study_candidates[2]).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e81c1-70f6-48cd-9d98-04b8b9da769f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a0e6b-bf4b-495e-998b-33284b693507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "\n",
    "def compute_knn_batch(tensor, k=5, exclude_self=False, batch_size=1024, device='cpu'):\n",
    "    n_batch = int(np.ceil(tensor.size(0)/batch_size))\n",
    "    all_topk_ind = []\n",
    "    all_topk_val = []\n",
    "    for b in range(n_batch):\n",
    "        start = b*batch_size\n",
    "        end = min((b+1)*batch_size, tensor.size(0))\n",
    "        batch_tensor = tensor[start:end, :].to(device)\n",
    "        batch_sim = batch_tensor@tensor.t()\n",
    "        batch_sim_topk = batch_sim.topk(k=k)\n",
    "        if exclude_self:\n",
    "            all_topk_ind.append(batch_sim_topk.indices[:, 1:k+1].cpu())\n",
    "            all_topk_val.append(batch_sim_topk.values[:, 1:k+1].cpu())\n",
    "        else:\n",
    "            all_topk_ind.append(batch_sim_topk.indices[:, :k].cpu())\n",
    "            all_topk_val.append(batch_sim_topk.values[:, :k].cpu())\n",
    "    all_topk_ind = torch.cat(all_topk_ind, dim=0)\n",
    "    all_topk_val = torch.cat(all_topk_val, dim=0)\n",
    "    return all_topk_ind, all_topk_val\n",
    "\n",
    "\n",
    "def compute_similarity_with_augmented_classifier(features, candidate_names, \n",
    "                                                 class_name_key_mapping, all_augmented_classifier, \n",
    "                                                 method='ensemble', agg_func=None, return_type='max', **kwargs):\n",
    "    \"\"\" only support single instance \n",
    "    Args:\n",
    "        features: tensor([D])\n",
    "        candidate_names: list([])\n",
    "        class_name_key_mapping: {`class_name`: [`synsets`]}\n",
    "        all_augmented_classifier: {`synset`: tensor([M x D])}\n",
    "    \"\"\"\n",
    "    res_similarity = {}\n",
    "    for c in candidate_names:\n",
    "        res_similarity.setdefault(c, [])\n",
    "        synsets = class_name_key_mapping[c]\n",
    "        for synset in synsets:\n",
    "            if method == 'ensemble':\n",
    "                single_ensembled_classifier = all_augmented_classifier[synset].to(features.device).float().mean(dim=0)\n",
    "                sim = 100 * features.view(1, -1) @ single_ensembled_classifier.view(1, -1).t()\n",
    "                res_similarity[c].append(sim.item())\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "    if agg_func is not None:\n",
    "        for k, v in res_similarity.items():\n",
    "            res_similarity[k] = agg_func(v)\n",
    "        if return_type=='max':\n",
    "            max_k = max(res_similarity, key=lambda x: res_similarity[x])\n",
    "            return max_k\n",
    "        elif return_type=='topk':\n",
    "            top_k = heapq.nlargest(kwargs['k'], res_similarity, key=res_similarity.get)\n",
    "            return top_k\n",
    "    return res_similarity\n",
    "    \n",
    "    \n",
    "def agg_by_pred_cluster(args, pred_kmeans, all_topk_voc, voc_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred_kmeans: np.array([N])\n",
    "        all_topk_voc: np.array([N x K])\n",
    "        voc_size: int\n",
    "    Returns:\n",
    "        all_clu_pred: tensor([C x V])\n",
    "    \"\"\"\n",
    "    print('agg_by_pred_cluster')\n",
    "    all_clu_pred = []\n",
    "    n_count = []\n",
    "    for i in np.unique(pred_kmeans):\n",
    "        selected = (pred_kmeans==i)\n",
    "        n_count.append( selected.sum().item() )\n",
    "        counter_voc_ind, counter_val = np.unique((all_topk_voc[selected]).ravel(), return_counts=True)\n",
    "        # counter_val = counter_val/(n_count+1e-20) # L1 norm\n",
    "        clu_pred = torch.zeros(args.num_voc) # cluster-wise prob\n",
    "        clu_pred[torch.from_numpy(counter_voc_ind).long()] = torch.from_numpy(counter_val).float()\n",
    "        # clu_pred = F.normalize(all_topk_voc[selected].sum(dim=0), dim=-1, p=1)\n",
    "        all_clu_pred.append(clu_pred)\n",
    "    all_clu_pred = torch.stack(all_clu_pred, dim=0).cpu()\n",
    "    n_count = torch.tensor(n_count).cpu()\n",
    "    \n",
    "    # all_clu_pred = setdiff_assignment(all_clu_pred)\n",
    "    \n",
    "    all_clu_pred = all_clu_pred/(n_count.view(-1, 1) + 1e-20)\n",
    "    \n",
    "    print('is mutex assignment::', all_clu_pred.argmax(dim=-1).size(0)==all_clu_pred.argmax(dim=-1).unique().size(0))\n",
    "    print('assignment collision num::', len(list(filter(lambda x: x>1, Counter(all_clu_pred.argmax(dim=-1).numpy()).values()))))\n",
    "    return all_clu_pred\n",
    "\n",
    "def linear_assign(all_clu_pred, pred_kmeans, all_gt_voc):\n",
    "    print('linear_assign')\n",
    "    cost_mat = all_clu_pred.cpu().numpy()\n",
    "    print(f'assignment shape={cost_mat.shape}')\n",
    "    res_ass = linear_assignment(cost_mat.max() - cost_mat)\n",
    "    label_voc_kmeans = torch.tensor([res_ass[1][x.item()] for x in pred_kmeans])\n",
    "    print('instance label acc::', (label_voc_kmeans==all_gt_voc).float().mean().item())\n",
    "    return label_voc_kmeans, res_ass\n",
    "\n",
    "def reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, device, all_prob=None, \n",
    "                             instance_selected=None, \n",
    "                             classifier_selected=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        classifier_selected: tensor([C2])\n",
    "    \"\"\"\n",
    "    print('reassign_by_pred_cluster')\n",
    "    amp_autocast = torch.cuda.amp.autocast\n",
    "    label_voc_kmeans = label_voc_kmeans.to(device)\n",
    "    if all_prob is None:\n",
    "        cluster_ind = []\n",
    "        with tqdm(total=len(loader_f)) as pbar:\n",
    "            if hasattr(model, 'eval'):\n",
    "                model.eval()\n",
    "            for idx_batch, batch in enumerate(loader_f):\n",
    "                images, label_voc, label_clu, idx_img = batch[:4]\n",
    "                images = images.to(device)\n",
    "                if (instance_selected is not None) and ((~instance_selected[idx_img]).all()):\n",
    "                    continue\n",
    "                with amp_autocast():\n",
    "                    with torch.no_grad():\n",
    "                        if (instance_selected is not None):\n",
    "                            logits = model.visual(images[instance_selected[idx_img]])\n",
    "                        else:\n",
    "                            logits = model.visual(images)\n",
    "                            \n",
    "                        logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                        \n",
    "                        if classifier_selected is not None:\n",
    "                            similarity = 100 * logits @ classifier[classifier_selected].t()\n",
    "                            prob = classifier_selected[similarity.softmax(-1)]\n",
    "                            cluster_ind.append(prob.cpu().argmax(dim=-1))\n",
    "                        else:\n",
    "                            similarity = 100 * logits @ classifier.t()\n",
    "                            prob = similarity.softmax(-1)\n",
    "                            cluster_ind.append(prob[:, label_voc_kmeans].cpu().argmax(dim=-1))\n",
    "                pbar.update(1)\n",
    "        cluster_ind = torch.cat(cluster_ind, dim=0)\n",
    "    else:\n",
    "        all_prob = all_prob[:, label_voc_kmeans]\n",
    "        cluster_ind = all_prob.argmax(dim=-1)\n",
    "        \n",
    "    if classifier_selected is not None:\n",
    "        cluster_ind_voc = classifier_selected[cluster_ind]\n",
    "    else:\n",
    "        cluster_ind_voc = label_voc_kmeans[cluster_ind]\n",
    "    mapping_ind = dict(zip(cluster_ind.unique().numpy(), torch.arange(cluster_ind.unique().size(0)).numpy()))\n",
    "    cluster_ind = torch.tensor([mapping_ind[x.item()] for x in cluster_ind])\n",
    "    return cluster_ind, cluster_ind_voc\n",
    "\n",
    "\n",
    "def row_wise_isin(a, b):\n",
    "    n, k = b.size()\n",
    "    results = []\n",
    "    for i in range(1, k+1):\n",
    "        res = torch.zeros_like(a).bool()\n",
    "        for j in range(i):\n",
    "            res = res | (a==b[:, j])\n",
    "        results.append(res)\n",
    "    results = torch.stack(results, dim=1).cpu()\n",
    "    return results\n",
    "\n",
    "import openai\n",
    "def request_gpt(prompt, model_name='text-davinci-003', max_tokens=400, temperature=0.01, best_of=1):\n",
    "    openai.api_key = \"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\"\n",
    "    while 1:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "              model=model_name,\n",
    "              prompt=prompt,\n",
    "              temperature=temperature,\n",
    "              max_tokens=max_tokens,\n",
    "              top_p=1,\n",
    "                best_of=best_of,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0,\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'e={e}')\n",
    "            continue\n",
    "    return response\n",
    "\n",
    "def get_prompt_candidate_discrimination(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    ### 42\n",
    "    prompt = f\"Precisely describe discriminative visual features of each word in {candidate_string}. Describe the color and texture. In two bullet points, each uses the template \\\"{'name'}: {'description'}\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v2(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    prompt = f\"Precisely distinguish discriminative visual features (e.g., {attributes}) of each category in {candidate_string}. Each category is elaborated in separate sentence with template \\\"category_name: description\\\". Do not use comparative degree.\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v3(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    prompt = f\"There are five categories: {candidate_string}. Closely and Precisely mention all discriminative visual differences between each category and others. Each category is described in a caption with template \\\"category_name: description\\\". \"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v4(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    ### 44.8\n",
    "    # prompt = f\"Please generate visual descriptions based on the following five category nouns (taken from WordNet): {candidate_string}. For each category, provide a separate sentence that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others visually.\"\n",
    "    prompt = f\"Please generate visual descriptions based on the following three category nouns (taken from WordNet): {candidate_string}. For each category, sequentially provide a separate sentence that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others. Write in three lines, use template \\\"{'name'}: {'description'}\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_pair(candidates, attributes, index, enable_def=False):\n",
    "    pair = [ candidates[i] for i in index ]\n",
    "    candidate_string = ''\n",
    "    candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "    prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, please generate a separate phrase that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to only emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others in appearance. Write in two lines, use template \\\"name: description\\\".\"\n",
    "    if enable_def:\n",
    "        pair = [ candidates[i] for i in index ]\n",
    "        candidate_string = ''\n",
    "        candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "        prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, please generate a separate phrase that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to only emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others in appearance. Write in two lines, use template \\\"name: description\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_pair_caption(candidates, attributes, index, enable_def=False):\n",
    "    pair = [ candidates[i] for i in index ]\n",
    "    random.shuffle(pair)\n",
    "    candidate_string = ''\n",
    "    candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "    prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, imagine given one photo, please generate a list of frequently co-occurred related words in image caption dataset in descending order. Write in one line for each category. Only mention the word that the other do not have.\"\n",
    "    return prompt\n",
    "\n",
    "def build_classifier_from_prompt_response(args, model, response):\n",
    "    with open('../templates_small_description.json', 'rb') as f:\n",
    "        templates_small = json.load(f)['imagenet']\n",
    "    all_prompts = []\n",
    "    for r in response:\n",
    "        name, description = r.split(': ')[0].lower(), ': '.join(r.split(': ')[1:])\n",
    "        filled_templates_small = [t.format(name, description) for t in templates_small]\n",
    "        all_prompts.append(filled_templates_small)\n",
    "    all_aug_classifiers = []\n",
    "    for prompt in all_prompts:\n",
    "        aug_classifier = tokenize(prompt, truncate=True).to(args.device)\n",
    "        with torch.no_grad():\n",
    "            aug_classifier = model.encode_text(aug_classifier)\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        aug_classifier = aug_classifier.mean(dim=0) ### ensembling\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        all_aug_classifiers.append(aug_classifier)\n",
    "    all_aug_classifiers = torch.stack(all_aug_classifiers, dim=0).to(args.device)\n",
    "    return all_aug_classifiers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c3799-6d65-4dc9-906a-a23e0787498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a864-1216-410d-83c3-8442ba58cc8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline Classifier Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e010fc-ca2a-46cb-aca6-24b7fc442b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from MUST \"\"\"\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()\n",
    "\n",
    "def tokenize(texts: Union[str, List[str]], context_length: int = 77, truncate: bool = False) -> torch.LongTensor:\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        if len(tokens) > context_length:\n",
    "            if truncate:\n",
    "                tokens = tokens[:context_length]\n",
    "                tokens[-1] = eot_token\n",
    "            else:\n",
    "                raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
    "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921a7ce-ded2-4d02-ae7f-a744f4d548c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load prompts and templates\n",
    "output_fpath = './cache/parsed-wn-gpt3-d-2023_02_26.json'\n",
    "with open(output_fpath, 'rb') as f:\n",
    "    all_parse_results = pickle.load(f)\n",
    "\n",
    "with open('../templates_small.json', 'rb') as f:\n",
    "    templates_small = json.load(f)['imagenet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc89912-bcfc-4ffe-a485-ca87a038a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "### synset and prompts\n",
    "text_inputs = {}\n",
    "for k, v in all_parse_results.items():\n",
    "    text_inputs[k] = [t.format(k.split('.')[0]) + f' {v}' for t in templates_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6d0b5-74a7-424a-a8a1-9d980d3b6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class name to synsets mapping\n",
    "class_name_key_mapping = {}\n",
    "for k in text_inputs:\n",
    "    class_name_key_mapping.setdefault(k.split('.')[0], [])\n",
    "    class_name_key_mapping[k.split('.')[0]].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4de6a-0da0-4545-b34f-8f14815fafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract prompt embeddings\n",
    "all_augmented_classifier = {}\n",
    "with tqdm(total=len(text_inputs)) as pbar:\n",
    "    for k, v in text_inputs.items():\n",
    "        aug_classifier = tokenize(v, truncate=True).to(args.device)\n",
    "        with torch.no_grad():\n",
    "            aug_classifier = model.encode_text(aug_classifier)\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        all_augmented_classifier[k] = aug_classifier.cpu()\n",
    "        \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba26ff-f2fb-41c2-aedc-1364b7057d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_classifier = {\n",
    "    'all_augmented_classifier': all_augmented_classifier,\n",
    "    'class_name_key_mapping': class_name_key_mapping,\n",
    "}\n",
    "torch.save(data_augmented_classifier, './cache/all_aug_prompts_embed-wn-gpt3-d-2023_02_26.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61f051-f0e9-4f31-8b0c-8ba7fc2472a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### classifier statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981158e-b75a-43d4-aa6d-4f36fbf625dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load SCD results\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']\n",
    "\n",
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd164501-06dc-44b1-92e6-c1be86cea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85009376-e8d3-4797-a7db-3ed4cef66322",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_all_topk_ind, classifier_all_topk_val = compute_knn_batch(classifier.to(args.device), \n",
    "                                                                     k=5, exclude_self=True, batch_size=512, \n",
    "                                                                     device=args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25305a39-9818-4fe0-a9c0-41fa3cda2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_all_topk_val.mean(dim=-1).mean(), classifier_all_topk_val.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ad7bc-e993-4838-a9e1-966fabb9b9a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in all_gt_label_voc.unique():\n",
    "    select = (all_gt_label_voc==c)\n",
    "    subset_features = torch.from_numpy(all_features[select]).to(args.device)\n",
    "    subset_features = subset_features/subset_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    target_classifier = classifier[c].to(args.device).view(1, -1)\n",
    "    target_classifier = target_classifier/target_classifier.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    sim_intra_img_text = subset_features@target_classifier.t()\n",
    "    print(sim_intra_img_text.mean())\n",
    "    \n",
    "    sim_intra = subset_features@subset_features.t()\n",
    "    mask = torch.ones_like(sim_intra)\n",
    "    mask = torch.scatter(mask, 1, torch.arange(mask.size(0), device=args.device).view(-1, 1), 0).bool()\n",
    "    intra_topk_ind, intra_topk_val = compute_knn_batch(subset_features.to(args.device), \n",
    "                                                       k=5, exclude_self=True, batch_size=512, \n",
    "                                                       device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5f084-6291-4662-a65d-28e17f8eacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_topk_ind, intra_topk_val = compute_knn_batch(torch.from_numpy(all_features).to(args.device), \n",
    "                                                   k=5, exclude_self=True, batch_size=512, \n",
    "                                                   device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44788174-d405-47f9-9a6d-2de1db63abf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in all_gt_label_voc.unique():\n",
    "    select = (all_gt_label_voc==c)\n",
    "    class_features = torch.from_numpy(all_features)[select].to(args.device)\n",
    "    sim = class_features@class_features.t()\n",
    "    mask = torch.ones_like(sim)\n",
    "    mask = torch.scatter(mask, 1, torch.arange(mask.size(0), device=args.device).view(-1, 1), 0).bool()\n",
    "    print(sim[mask].mean(dim=-1).mean())\n",
    "    # intra_topk_ind, intra_topk_val = compute_knn_batch(torch.from_numpy(all_features)[select].to(args.device), \n",
    "    #                                                    k=5, exclude_self=True, batch_size=512, \n",
    "    #                                                    device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dfca8-c0a5-4bd7-9cd5-5579c80972ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_topk_val.mean(dim=-1).mean(), intra_topk_val.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49eb0d-8e63-40bc-94d3-18d1677cec09",
   "metadata": {},
   "source": [
    "### Method test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc0d97-0b29-418b-9bbe-947077fe1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_classifier = torch.load('./cache/all_aug_prompts_embed-wn-gpt3-d-2023_02_26.pth')\n",
    "all_augmented_classifier = data_augmented_classifier['all_augmented_classifier']\n",
    "class_name_key_mapping = data_augmented_classifier['class_name_key_mapping']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c6430-8f89-45cc-8c30-f75caf92b879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710c214-a68f-4c55-81b4-ddb2fd02724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cb0cb-8ea6-430d-ae2b-5d5e68d8c8cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-clip.npy'))\n",
    "# all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_instance_voc_topk_ind, voc_size=args.num_voc)\n",
    "\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "for t in range(3):\n",
    "    record_pred_kmeans_t = pred_kmeans_t\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_instance_voc_topk_ind, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_label_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_label_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_gt_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6616691-c6ee-4165-a0f4-71b5bed8a9be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attributes in [\n",
    "    # 'texture and shape',\n",
    "    # 'shape and texture',\n",
    "    # 'color and shape',\n",
    "    # 'shape and color',\n",
    "    # 'components and color',\n",
    "    # 'color and components',\n",
    "    # 'components and texture',\n",
    "    # 'texture and components',\n",
    "    # 'components and shape',\n",
    "    # 'shape and components',\n",
    "    # 'texture and color',\n",
    "    'color and texture',\n",
    "    # 'components, shape, and color',\n",
    "    # 'shape, color, and components',\n",
    "    # 'color, components, and shape',\n",
    "    # 'components, color, and shape',\n",
    "    # 'shape, components, and color',\n",
    "    # 'color, shape, and components',\n",
    "]:\n",
    "    topK = 3\n",
    "    print(attributes)\n",
    "    cluster_topk_voc_ind = all_clu_pred.topk(k=topK).indices.cpu()\n",
    "    class_prediction = []\n",
    "    record_response = []\n",
    "    all_prompt_response = []\n",
    "    all_aug_classifiers = []\n",
    "    with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "        for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "            candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "            # candidates_def = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "            while 1:\n",
    "                try:\n",
    "                    prompt = get_prompt_candidate_discrimination_v4(candidates, attributes)\n",
    "                    response = request_gpt(prompt, model_name='text-davinci-003')\n",
    "                    response = list(filter(lambda x: len(x), response['choices'][0]['text'].lstrip('\\n').split('\\n')))\n",
    "                    # response = record_response[idx]\n",
    "                    aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "                    assert aug_classifiers.size(0)==topK\n",
    "                    all_prompt_response.append(response)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(response)\n",
    "            \n",
    "            subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "            sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "            ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "            class_prediction.append(cluster_topk_voc_ind[idx, ind[count.argmax()]].item())\n",
    "            record_response.append(response)\n",
    "            all_aug_classifiers.append(aug_classifiers)\n",
    "            pbar.update(1)\n",
    "    class_prediction = torch.tensor(class_prediction)\n",
    "    all_aug_classifiers = torch.cat(all_aug_classifiers, dim=0)\n",
    "\n",
    "    N = pred_kmeans.size(0)\n",
    "    instance_assigned_pred = torch.zeros(N).long()\n",
    "    for c in record_pred_kmeans_t.unique():\n",
    "        select = (record_pred_kmeans_t==c)\n",
    "        instance_assigned_pred[select] = class_prediction[c]\n",
    "    print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "    print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c9bbc-b930-4709-ac72-ff316056a493",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "topK = 3\n",
    "cluster_topk_voc_ind = all_clu_pred.topk(k=topK).indices.cpu()\n",
    "class_prediction = []\n",
    "record_response = []\n",
    "all_prompt_response = []\n",
    "all_aug_classifiers = []\n",
    "with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "    for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "        ### parse candidate class names\n",
    "        candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "        ### get subset features\n",
    "        subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "        ### candidate index flag\n",
    "        curr_candidate_idx_1 = 0 ### head\n",
    "        curr_candidate_idx_2 = 1 ### tail\n",
    "        ### record\n",
    "        pair_prompts = []\n",
    "        while curr_candidate_idx_2<topK:\n",
    "            ### get pair prompts\n",
    "            prompt = get_prompt_candidate_discrimination_pair_caption(candidates, attributes, \n",
    "                                                              index=[curr_candidate_idx_1, curr_candidate_idx_2],\n",
    "                                                             )\n",
    "            ### record\n",
    "            pred_ind = []\n",
    "            pair_repeat_prompts = []\n",
    "            ### repeat\n",
    "            for _ in range(3):\n",
    "                while 1:\n",
    "                    try:\n",
    "                        response = request_gpt(prompt, model_name='text-davinci-003', max_tokens=200, temperature=0.7, best_of=1)\n",
    "                        response = list(filter(lambda x: len(x), response['choices'][0]['text'].lstrip('\\n').split('\\n')))\n",
    "                        aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "                        ### constraint\n",
    "                        assert aug_classifiers.size(0)==2\n",
    "                        ### record\n",
    "                        pair_repeat_prompts.append(response)\n",
    "                        all_aug_classifiers.append(aug_classifiers)\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "                ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "                pred_ind.append(ind[count.argmax()].item())\n",
    "            ind, count = torch.tensor(pred_ind).unique(return_counts=True)\n",
    "            curr_candidate_idx_1 = ind[count.argmax()] ### winner\n",
    "            curr_candidate_idx_2 = curr_candidate_idx_2 + 1\n",
    "            pair_prompts.append(pair_repeat_prompts)\n",
    "        ### results\n",
    "        class_prediction.append(cluster_topk_voc_ind[idx, curr_candidate_idx_1].item())\n",
    "        all_prompt_response.append(pair_prompts)\n",
    "        pbar.update(1)\n",
    "\n",
    "class_prediction = torch.tensor(class_prediction)\n",
    "all_aug_classifiers = torch.cat(all_aug_classifiers, dim=0)\n",
    "\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b161c6d-5e08-4ff1-bad3-eb181ef223da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save({'all_prompt_response': all_prompt_response}, f'./cache/all_prompt_response-{args.dataset_name}-pair.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae5a98-dce3-4218-9b40-1ec1bf55eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### upperbound performance of cluster-wise assignment\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==c].unique(return_counts=True) \n",
    "    instance_assigned_pred[select] = ind_gt[count_gt.argmax()]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))\n",
    "### class recall performance of SCD topK predictions\n",
    "recall = []\n",
    "all_gtlbl = []\n",
    "for idx in range(len(cluster_topk_voc_ind)):\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "    gtlbl = ind_gt[count_gt.argmax()]\n",
    "    recall.append(torch.isin(gtlbl, cluster_topk_voc_ind[idx, :3]).item())\n",
    "    all_gtlbl.append(gtlbl)\n",
    "\n",
    "recall = torch.tensor(recall)\n",
    "all_gtlbl = torch.tensor(all_gtlbl)\n",
    "recall.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9ba57-99c0-4454-b59c-5d7cb72dabc3",
   "metadata": {},
   "source": [
    "entropy partition experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe30e24-2aba-4c6c-bade-cfd76666aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "# normalize_sum = lambda x: x/x.sum(dim=-1, keepdim=True)\n",
    "entropy = lambda p, a=1: -((a*p)*((a*p)+1e-20).log()).sum()\n",
    "record_true = []\n",
    "record_false = []\n",
    "cluster_topk_voc_val = (1 * all_clu_pred.topk(k=topK).values.cpu()).softmax(-1)\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==c].unique(return_counts=True) \n",
    "    if (ind_gt[count_gt.argmax()]==cluster_topk_voc_ind[c][0]).item():\n",
    "        record_true.append(cluster_topk_voc_val[c][0])\n",
    "        # record_true.append(entropy(cluster_topk_voc_val[c]))\n",
    "    else:\n",
    "        record_false.append(cluster_topk_voc_val[c][0])\n",
    "        # record_false.append(entropy(cluster_topk_voc_val[c]))\n",
    "    # break\n",
    "    \n",
    "plt.figure()\n",
    "sns.distplot(torch.tensor(record_true).numpy(), bins=100)\n",
    "sns.distplot(torch.tensor(record_false).numpy(), bins=100)\n",
    "plt.legend(['true', 'false'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec8ff0-6354-4893-aec8-48e73bce1e12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.distplot(torch.tensor(record_true).numpy(), bins=100)\n",
    "sns.distplot(torch.tensor(record_false).numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50233f07-b299-483f-ae58-56348d589103",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cluster_topk_voc_val[:, 0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7f3e6-a244-4e24-8ca0-204032c7be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./all_prompt_response_v4-{args.dataset_name}.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_prompt_response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb788e-a3f1-4710-96fa-53b1cf668822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./all_prompt_response_v4-{args.dataset_name}.pkl', 'rb') as f:\n",
    "#     all_prompt_response = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7759d-ee9f-4ebc-b990-77fb0a72a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pred_idx_list = []\n",
    "for idx in range(len(cluster_topk_voc_ind)):\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "    correct_pred = (ind_gt[count_gt.argmax()] == class_prediction[idx]).item()\n",
    "    if not correct_pred:\n",
    "        false_pred_idx_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cfcd9-04e8-4b78-93e5-5843f2f47106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "idx = np.random.choice(false_pred_idx_list)\n",
    "# idx = idx + 1\n",
    "response = all_prompt_response[idx]\n",
    "aug_classifiers = build_classifier_from_prompt_response(args, model, response)\n",
    "subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "\n",
    "print(all_prompt_response[idx])\n",
    "print(f'ind={ind}, count={count}')\n",
    "print(f'cand={cluster_topk_voc_ind[idx]}, prev_pred={class_prediction[idx]}')\n",
    "print(f'pred={cluster_topk_voc_ind[idx,ind[count.argmax()]]}, gt={ind_gt[count_gt.argmax()]}')\n",
    "print('synset=', mapping_vocidx_to_synsets(ind_gt[count_gt.argmax()].item(), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd72f04-a8a6-437d-8d14-3047a16728f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    'components, shape, and color',\n",
    "    'shape, color, and components',\n",
    "    'color, components, and shape',\n",
    "    'components, color, and shape',\n",
    "    'shape, components, and color',\n",
    "    'color, shape, and components',\n",
    "]\n",
    "print(attributes)\n",
    "cluster_topk_voc_ind = all_clu_pred.topk(k=5).indices.cpu()\n",
    "class_prediction = []\n",
    "record_response = []\n",
    "all_prompt_response = []\n",
    "with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "    for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "        candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:5]]\n",
    "        ensembled_response = []\n",
    "        ensembled_classifier = []\n",
    "        for a in attributes:\n",
    "            prompt = get_prompt_candidate_discrimination(candidates, attributes)\n",
    "            response = request_gpt(prompt, model_name='text-davinci-003')\n",
    "            response = response['choices'][0]['text'].lstrip('\\n\\n').split('\\n\\n')\n",
    "            aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "            ensembled_classifier.append(aug_classifiers)\n",
    "            ensembled_response.append(response)\n",
    "        all_prompt_response.append(ensembled_response)\n",
    "        \n",
    "        ### similarity average ensemble\n",
    "        subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).float()#.to(args.device).float()\n",
    "        a_c = aug_classifiers.float().t().cpu()\n",
    "        ensembled_sim = []\n",
    "        for aug_classifiers in ensembled_classifier:\n",
    "            sim = 100 * subset_features @ a_c\n",
    "            ensembled_sim.append(sim)\n",
    "        ensembled_sim = torch.stack(ensembled_sim, dim=0).mean(dim=0) ### average\n",
    "        ind, count = ensembled_sim.argmax(dim=-1).unique(return_counts=True)\n",
    "        class_prediction.append(cluster_topk_voc_ind[idx, ind[count.argmax()]].item())\n",
    "        record_response.append(response)\n",
    "        pbar.update(1)\n",
    "class_prediction = torch.tensor(class_prediction)\n",
    "\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d990eb6-1b8d-4e9b-b430-7747915e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f./cache/request/equest/ensmbled_prompts-{args.dataset_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(all_prompt_response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d87ae-867b-492a-831a-96278284c467",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_prompt_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eee86-26fe-4714-a0ca-313dd4b57a1b",
   "metadata": {},
   "source": [
    "#### iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01df0d-958d-4ccd-befd-f057ab1dbe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6300e4-132b-4f12-a676-a6ea37857ac0",
   "metadata": {},
   "source": [
    "#### misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b089e8-6c33-4ee0-8165-41c2f24c9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402145b0-b7f5-4bfb-b4ec-c2be49f66007",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred_scd = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred_scd[select] = all_clu_pred[c].argmax(dim=-1)\n",
    "print('acc', (instance_assigned_pred_scd==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654442-2239-42e5-9395-eb2429f9404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_fn = (instance_assigned_pred!=all_gt_label_voc) & (instance_assigned_pred_scd==all_gt_label_voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e9cda-a276-45e1-98c1-b58da5a4272b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('flip rate', (class_prediction == all_clu_pred.argmax(dim=-1)).float().mean())\n",
    "scd_names = np.array([mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_clu_pred.argmax(dim=-1)])\n",
    "updated_names = np.array([mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in class_prediction])\n",
    "\n",
    "np.array(record_response)[class_prediction!=all_clu_pred.argmax(dim=-1)].tolist(), \\\n",
    "updated_names[(scd_names!=updated_names)], scd_names[(scd_names!=updated_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd471dc-dcea-488b-9028-3d60d3fc4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc', (all_clu_pred.argmax(dim=-1)==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8be80-212f-4494-ad71-e1a64827b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "K = prob_k\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=5).indices\n",
    "\n",
    "print('acc', (instance_assigned_pred[:, 0]==all_gt_label_voc).float().mean().item())\n",
    "print('acc instance topk', (torch.from_numpy(all_instance_voc_topk_ind)[:, 0]==all_gt_label_voc).float().mean().item())\n",
    "retrieved_labels = instance_assigned_pred[instance_assigned_pred[:, 0]==all_gt_label_voc][:, 0].unique().numpy()\n",
    "pred_labels = instance_assigned_pred[:, 0].unique().numpy()\n",
    "gt_labels = all_gt_label_voc.unique().numpy()\n",
    "print(f'missing label of retrieval:: {len(set(gt_labels) - set(retrieved_labels))}')\n",
    "print(f'missing label of predict:: {len(set(gt_labels) - set(pred_labels))}')\n",
    "for k in range(1, K):\n",
    "    retrieved_labels_topk = instance_assigned_pred[instance_assigned_pred[:, 0]==all_gt_label_voc][:, :k].flatten().unique().numpy()\n",
    "    print(f'missing label of retieval at k={k}:: {len(set(gt_labels) - set(retrieved_labels_topk))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64614ea-8231-4ca1-aaf3-04cae70f776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_instance_topk = row_wise_isin(all_gt_label_voc, torch.from_numpy(all_instance_voc_topk_ind))\n",
    "\n",
    "isin_instance_topk.float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37ffd9-10cf-4b87-b9f7-89cb3471951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_instance_topk = row_wise_isin(all_gt_label_voc, instance_assigned_pred)\n",
    "isin_instance_topk.float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb3425-be2f-497f-8647-69bb95942c93",
   "metadata": {},
   "source": [
    "instance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae00b29-38ba-446f-aefe-532782fbb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instance_voc_topk_ind\n",
    "\n",
    "candidate_names = \n",
    "compute_similarity_with_augmented_classifier(features, candidate_names, \n",
    "                                             class_name_key_mapping, all_augmented_classifier, \n",
    "                                             method='ensemble', agg_func=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f6783-ef4e-45ed-b623-c27992cc4d84",
   "metadata": {},
   "source": [
    "cluster based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c8500-d3c7-4a61-a87e-9332efcc9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = record_pred_kmeans_t.size(0)\n",
    "K = prob_k\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=10).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b380c5-a65a-4f05-9983-5195b6e9a1fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "all_sample_ind = []\n",
    "with tqdm(total=all_features.shape[0]) as pbar:\n",
    "    for i in range(all_features.shape[0]):\n",
    "        img_feature = torch.from_numpy(all_features[i])#.to(args.device)\n",
    "        candidate_names = [mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] \n",
    "                           for x in instance_assigned_pred[i, :3]]\n",
    "        max_k = \\\n",
    "            compute_similarity_with_augmented_classifier(img_feature, candidate_names, \n",
    "                                                         class_name_key_mapping, all_augmented_classifier, \n",
    "                                                         method='ensemble', agg_func=np.mean, return_indices=True)\n",
    "        idx_max = candidate_names.index(max_k)\n",
    "        \n",
    "        all_sample_ind.append(idx_max)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "all_sample_ind = torch.tensor(all_sample_ind)\n",
    "baseline_instance_pred = instance_assigned_pred.gather(1, all_sample_ind.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c3f47-69b1-4e45-99ec-e5053c6233bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_instance_pred.flatten() == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7c61a-0dc3-4e57-bd73-131e028a32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(instance_assigned_pred[:, 0] == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe399f5-e538-4d0a-9b5a-d9e2b3028338",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names, max_k, mapping_vocidx_to_synsets(all_gt_label_voc[i].item(), vocab), \\\n",
    "baseline_instance_pred[-1], all_gt_label_voc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92846901-17b1-4da1-9f38-c35ec002db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_instance_pred = baseline_instance_pred.flatten()\n",
    "baseline_instance_pred_clu = torch.zeros_like(baseline_instance_pred)\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    val, count = baseline_instance_pred[record_pred_kmeans_t==c].unique(return_counts=True)\n",
    "    baseline_instance_pred_clu[record_pred_kmeans_t==c] = val[count.argmax(dim=-1)].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ceb35-6d5d-4d5e-9875-2808b74894ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_instance_pred_clu == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa10391-ea9d-40f1-acf0-f47e1fdf56ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### reranked KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39be754-2a0d-42d5-a8ed-81a642a88350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" compute top-20 predictions \"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca48837-88e5-439a-b4a0-e4c693a127a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "N = all_instance_voc_topk_ind.shape[0]\n",
    "all_instance_voc_topk_ind_rerank = torch.zeros(N, K).long()\n",
    "with tqdm(total=N) as pbar:\n",
    "    for i in range(all_features.shape[0]):\n",
    "        feature = torch.from_numpy(all_features[i])\n",
    "        candidate_names = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_instance_voc_topk_ind[i, :3] ]\n",
    "        topk_candidate_voc_ind = \\\n",
    "        compute_similarity_with_augmented_classifier(feature, candidate_names, \n",
    "                                                     class_name_key_mapping, all_augmented_classifier, \n",
    "                                                     method='ensemble', agg_func=max, return_type='topk', k=K)\n",
    "        all_instance_voc_topk_ind_rerank[i] = torch.tensor([ vocab.mapping_names_idx[x] for x in topk_candidate_voc_ind ])\n",
    "        pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6049d-fdb0-495f-8b23-24720c278dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.permutation(N)[0]\n",
    "feature = torch.from_numpy(all_features[i])\n",
    "candidate_names = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_instance_voc_topk_ind[i] ]\n",
    "topk_candidate_voc_ind = \\\n",
    "compute_similarity_with_augmented_classifier(feature, candidate_names, \n",
    "                                             class_name_key_mapping, all_augmented_classifier, \n",
    "                                             method='ensemble', agg_func=max, return_type='topk', k=5)\n",
    "all_instance_voc_topk_ind_rerank[i] = torch.tensor([ vocab.mapping_names_idx[x] for x in topk_candidate_voc_ind ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac0558-2e4a-42d9-8ff6-2f0066ff7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_instance_voc_topk_ind_rerank[:, 0]==all_gt_label_voc).float().mean(), \\\n",
    "(torch.from_numpy(all_instance_voc_topk_ind)[:, 0]==all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970564f-36dd-4efa-9c57-d91e09681d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, d = compute_similarity_with_augmented_classifier(torch.rand(512), ['cat', 'dog', 'frog', 'shirt', 'man', 'swarm', 'liquid'], \n",
    "                                                 class_name_key_mapping, all_augmented_classifier, \n",
    "                                                 method='ensemble', agg_func=max, return_type='topk', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3821e-c7b7-4764-8a61-a40698ed997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fpath = './cache/parsed-wn-gpt3-d-2023_02_26.json'\n",
    "with open(output_fpath, 'rb') as f:\n",
    "    all_parse_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a2b64-3e17-4025-9542-46213959d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_vocidx_to_synsets(all_gt_label_voc[i].item(), vocab)[0].name(), \\\n",
    "topk_candidate_voc_ind, \\\n",
    "[mapping_vocidx_to_synsets(x, vocab)[0].name() for x in all_instance_voc_topk_ind[i][:5]], \\\n",
    "[ all_parse_results[mapping_vocidx_to_synsets(x, vocab)[0].name()] for x in all_instance_voc_topk_ind[i][:5] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fb4f2-518b-461d-b14b-784b2354fb96",
   "metadata": {},
   "source": [
    "#### basic observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196adeb7-7e2d-4061-927f-0fad8c484f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" compute top-20 predictions \"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ffe8b-8734-4424-8fdb-8409a242f7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3ba74-5b6e-4a46-9b4d-6fef55fe7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('/home/sheng/dataset/LAION/part-00000-5b54c5d5-bbcf-484d-a2ce-0d6f73df1a36-c000.snappy.parquet', engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "gcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
