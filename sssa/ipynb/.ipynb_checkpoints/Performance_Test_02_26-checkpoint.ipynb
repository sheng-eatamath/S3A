{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a02b61-1bf2-4cca-9755-350ae884d320",
   "metadata": {},
   "source": [
    "complete WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb40fe6d-56fb-4cbf-8bc7-387908e5adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/OSZSL/')\n",
    "sys.path.append('/home/sheng/OSZSL/CLIP/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import math\n",
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import zip_longest\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from ipynb_utils import get_hier_datasets, get_classifier\n",
    "import clip\n",
    "from data.datasets import get_datasets_oszsl, build_transform, Vocab\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from wordnet_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5c8821-985f-4eb0-9335-160b244f60a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = 'cuda:3'\n",
    "    arch = 'ViT-B/16'\n",
    "    dataset_name = 'make_nonliving26'\n",
    "    n_sampled_classes = 100\n",
    "    input_size = 224\n",
    "    \n",
    "    batch_size = 1024\n",
    "    use_def = False\n",
    "    clip_checkpoint = None\n",
    "    vocab_fpath = 'wordnet_nouns_complete4:'\n",
    "    f_classifier = './cache/wordnet_classifier_complete4:_small_def.pth'\n",
    "    \n",
    "    map_vocab_name = False\n",
    "    \n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e68f18db-4216-46c0-a255-cf0820509437",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../templates_small_def.json', 'rb') as f:\n",
    "    templates = json.load(f)\n",
    "\n",
    "def get_vocab(fpath=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        vocab: {`names`: list, `ids`: synset ids, `parents`: [{synset ids}]}\n",
    "    \"\"\"\n",
    "    with open('/home/sheng/dataset/wordnet_nouns.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    if fpath is not None:\n",
    "        with open(f'/home/sheng/dataset/{fpath}.pkl', 'rb') as f:\n",
    "            vocab = pickle.load(f)\n",
    "        \n",
    "    # with open('/home/sheng/dataset/wordnet_nouns_no_abstract.pkl', 'rb') as f:\n",
    "    #     vocab = pickle.load(f)\n",
    "    return vocab\n",
    "\n",
    "vocab = get_vocab(args.vocab_fpath)\n",
    "templates = templates['imagenet']\n",
    "classnames = vocab['names']\n",
    "parents = vocab['parents']\n",
    "defs = vocab['def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ca14ba-2aba-4a1d-94c8-aacd1187b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bfafc-12bb-4027-8c35-b8d9e16be6ef",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120f9ebb-2852-411c-b051-8a5635c6a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 149,620,737\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c168f-b865-44fc-a9ba-46f1a653307b",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d173b98-8294-4219-92fe-0933f67e4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = build_transform(is_train=False, args=args, train_config=None)\n",
    "dataset_raw = get_datasets_oszsl(args, None, is_train=True, transform=transform_val, \n",
    "                                 seed=1, map_vocab_name=args.map_vocab_name)\n",
    "dataset = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_val, seed=1, map_vocab_name=args.map_vocab_name)\n",
    "\n",
    "loader_f = torch.utils.data.DataLoader(dataset, num_workers=8, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e42b4c-7440-4a17-a990-5e58a17e638b",
   "metadata": {},
   "source": [
    "### construct classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40373646-d382-44de-972b-6005c2b1feb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### wordnet classifier with definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e135e8b3-c29f-4111-b499-dd9f955fc07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "641it [04:57,  2.15it/s]                         \n"
     ]
    }
   ],
   "source": [
    "all_class_names = vocab.vocab['names']\n",
    "all_class_defs = vocab.vocab['def']\n",
    "\n",
    "batch_size = 128\n",
    "with torch.no_grad():\n",
    "    zeroshot_weights = []\n",
    "    with tqdm(total=len(vocab.classnames)//batch_size) as pbar:\n",
    "        for idx_set, classname_set in zip(np.array_split(np.arange(len(all_class_names)), len(all_class_names)//batch_size), \n",
    "                                 np.array_split(all_class_names, len(all_class_names)//batch_size)):\n",
    "            texts = [\n",
    "                template.format(classname, all_class_defs[idx])[:77] \n",
    "                for idx, classname in zip(idx_set, classname_set) for template in templates\n",
    "            ]\n",
    "            texts = clip.tokenize(texts).to(args.device) #tokenize\n",
    "            class_embeddings = model.encode_text(texts).float() #embed with text encoder\n",
    "            class_embeddings = class_embeddings.view(-1, len(templates), class_embeddings.size(-1))\n",
    "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "            class_embedding = class_embeddings.mean(dim=1)\n",
    "            class_embedding /= class_embedding.norm(dim=-1, keepdim=True)\n",
    "            zeroshot_weights.append(class_embedding.cpu())\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "classifier = torch.cat(zeroshot_weights, dim=0)\n",
    "torch.save(classifier, './cache/wordnet_classifier_complete4:_small_def.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bec417-2d11-45e3-9812-4e62d6bcaab1",
   "metadata": {},
   "source": [
    "#### LLM-augmented classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2043bca9-c92c-4062-b0cb-3e5bbb3b855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_names = vocab.vocab['names']\n",
    "all_class_defs = vocab.vocab['def']\n",
    "\n",
    "data_augmented_classifier = torch.load('./cache/all_aug_prompts_embed-wn-gpt3-c-2023_02_26.pth')\n",
    "all_augmented_classifier = data_augmented_classifier['all_augmented_classifier']\n",
    "class_name_key_mapping = data_augmented_classifier['class_name_key_mapping']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e22aa5-a449-47f9-bb03-9178ccfa8fd8",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09292a0-917c-4f87-b26b-79b7fb1a1d27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### raw evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f32e4535-211f-49c7-bac9-e3af0244ed8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [04:38<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "args.f_classifier = './cache/wordnet_classifier_complete4:_small_def.pth'\n",
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "# all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_voc = np.array(list(reduce(lambda x, y: x+y, all_gt_label_voc)))\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abdce15d-2477-4ec7-9997-715100e61b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24331713930629306"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(classnames)[all_instance_voc_topk_ind[:, 0]]==np.array(all_gt_label_voc)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85f7f4e3-820c-4bcd-aa67-bfff5fdeb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_label_voc = list(reduce(lambda x, y: x+y, all_gt_label_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e55862-262a-4a8d-b0e6-38775599c494",
   "metadata": {},
   "source": [
    "#### raw evaluation with  LLM-augmented classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ac0c45-f0b2-41b6-9907-6dec66fa48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aug_classifier(all_synset_names, all_augmented_classifier):\n",
    "    all_aug_classifier = torch.stack(list(map(lambda x: all_augmented_classifier[x], all_synset_names)), dim=0)\n",
    "    return all_aug_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec591474-2f4c-4967-82eb-be789e728d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [04:39<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### get aug classifier in sequential order\n",
    "all_synset_names = list(map(lambda x: mapping_ids_synset(x).name(), vocab.vocab['ids']))\n",
    "all_aug_classifier = get_aug_classifier(all_synset_names, all_augmented_classifier).float()\n",
    "### normalization\n",
    "all_aug_classifier = F.normalize(F.normalize(all_aug_classifier, dim=-1).mean(dim=1), dim=-1)\n",
    "all_aug_classifier = all_aug_classifier.to(args.device)\n",
    "\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits.float() @ all_aug_classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "# all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_voc = np.array(list(reduce(lambda x, y: x+y, all_gt_label_voc)))\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84724e0c-d650-417e-b9cb-36729b0c7c67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21282717583700522"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(classnames)[all_instance_voc_topk_ind[:, 0]]==np.array(all_gt_label_voc)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "gcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
