{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c187d77c-026e-4cf7-9000-103a8718cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "# sys.path.append('/home/sheng/sssa/CLIP/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from functools import reduce, partial\n",
    "from itertools import zip_longest\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from wordnet_utils import *\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "from ipynb_utils import get_hier_datasets, get_classifier, MCMF_assign_labels\n",
    "# import clip\n",
    "import model as clip\n",
    "from data.datasets import build_transform, get_hier_datasets, Vocab\n",
    "from data.imagenet_datasets import get_datasets_oszsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184f5eb3-cd49-42e6-87b1-cb7e50d0d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = 'cuda:0'\n",
    "    arch = 'ViT-B/16'\n",
    "    dataset = 'imagenet21k_1'\n",
    "    n_sampled_classes = 100\n",
    "    input_size = 224\n",
    "    seed = 0\n",
    "    \n",
    "    batch_size = 512\n",
    "    use_def = False\n",
    "    clip_checkpoint = None\n",
    "    f_classifier = './cache/wordnet_classifier_in21k_word.pth'\n",
    "    templates_name = 'templates_small'\n",
    "    \n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b6c3e7-a7cf-4d0b-b4f6-2c8f2ae6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates(args):\n",
    "    with open(f'../{args.templates_name}.json', 'rb') as f:\n",
    "        templates = json.load(f)['imagenet']\n",
    "    return templates\n",
    "\n",
    "def get_vocab():\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        vocab: {`names`: list, `ids`: synset ids, `parents`: [{synset ids}]}\n",
    "    \"\"\"\n",
    "    with open('/home/sheng/dataset/wordnet_nouns_with_synset_4.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    return vocab\n",
    "\n",
    "def get_subsample_vocab(sample_synset_id: set):\n",
    "    vocab = get_vocab()\n",
    "    index = np.array([ i for i in range(len(vocab['synsets'])) if vocab['synsets'][i] in sample_synset_id ]).astype(np.int32)\n",
    "    for k in vocab.keys():\n",
    "        vocab[k] = np.array(vocab[k])[index].tolist()\n",
    "    return vocab\n",
    "\n",
    "def read_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "    return data\n",
    "\n",
    "def read_lvis_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/lvis_imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "        # data = list(map(lambda x: x.split('.')[0], data))\n",
    "    return data\n",
    "\n",
    "def load_clip2(args):\n",
    "    model = clip.load(args.arch)\n",
    "    if args.clip_checkpoint:\n",
    "        model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "    model.to(args.device).eval()\n",
    "    input_resolution = model.visual.input_resolution\n",
    "    context_length = model.context_length\n",
    "    vocab_size = model.vocab_size\n",
    "\n",
    "    print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "    print(\"Input resolution:\", input_resolution)\n",
    "    print(\"Context length:\", context_length)\n",
    "    print(\"Vocab size:\", vocab_size)\n",
    "    return model\n",
    "\n",
    "templates = load_templates(args)\n",
    "vocab = get_vocab()\n",
    "nouns = [ wn.synset(s) for s in vocab['synsets'] ]\n",
    "classnames = vocab['names']\n",
    "parents = vocab['parents']\n",
    "defs = vocab['def']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f336c28d-6d12-4c83-be87-a4bf7e8f657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" build entire wn-graph \"\"\"\n",
    "from nxgraph_model import *\n",
    "\n",
    "with open('/home/sheng/dataset/wordnet_nouns_with_synset.pkl', 'rb') as f:\n",
    "    entire_vocab = pickle.load(f)\n",
    "    \n",
    "G = create_graph([wn.synset(x) for x in entire_vocab['synsets']], entire_vocab['ids'], entire_vocab['names'], entire_vocab['def'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2818f39d-9340-4999-857d-2b086c9b0ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 102006\n",
      "missing keys:\n",
      "[]\n",
      "Model parameters: 149,620,737\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "\"\"\" prepare dataset and load CLIP \"\"\"\n",
    "classes = read_imagenet21k_classes() + os.listdir('/home/sheng/dataset/imagenet-img/')\n",
    "classes = [wn.synset_from_pos_and_offset('n', int(x[1:])).name() for x in classes]\n",
    "classes = set(classes)\n",
    "if args.dataset == 'lvis':\n",
    "    classes = read_lvis_imagenet21k_classes()\n",
    "    classes = set(classes)\n",
    "vocab = get_subsample_vocab(classes)\n",
    "vocab = Vocab(vocab=vocab)\n",
    "\n",
    "transform_val = build_transform(is_train=False, args=args, train_config=None)\n",
    "mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "std = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(args.input_size, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(args.input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=torch.tensor(mean),\n",
    "        std=torch.tensor(std))\n",
    "])\n",
    "dataset = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=0)\n",
    "loader_val = torch.utils.data.DataLoader(dataset, num_workers=4, batch_size=256, shuffle=False)\n",
    "print('dataset size', len(dataset))\n",
    "\n",
    "# model, preprocess = load_clip(args)\n",
    "model = load_clip2(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499fb6d7-7d39-4a90-8c65-0af9c5c9374b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [02:03<00:00,  3.22it/s]\n"
     ]
    }
   ],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "all_vfeatures = []\n",
    "all_clu_label = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual.extract_features(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                all_vfeatures.append(deepcopy(logits.cpu().numpy()))\n",
    "                all_clu_label.append(deepcopy(label_clu.numpy()))\n",
    "        pbar.update(1)\n",
    "\n",
    "all_vfeatures = np.concatenate(all_vfeatures)\n",
    "all_clu_label = np.concatenate(all_clu_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a064680-71f5-46fe-a46d-4c846a6ef891",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./cache/features/vfeatures-{args.dataset}.npy', all_vfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c3d403-474b-41c0-a098-9487fa8d524d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=100\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from my_util_package_oszsl.evaluation import cluster_acc\n",
    "K = dataset.num_classes\n",
    "print(f'K={K}')\n",
    "print(np.unique(all_clu_label).shape)\n",
    "# kmeans = MiniBatchKMeans(n_clusters=10*K, batch_size=2048, random_state=0, n_init=10, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "# preds = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e8a66-ce99-4532-8d14-6b2683b8ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_acc(all_clu_label, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d7c3a4-71f7-4229-af50-4159c0c001ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration 0, inertia 46416.8671875\n",
      "Iteration 1, inertia 28931.96484375\n",
      "Iteration 2, inertia 28316.2734375\n",
      "Iteration 3, inertia 28164.236328125\n",
      "Iteration 4, inertia 28106.234375\n",
      "Iteration 5, inertia 28070.68359375\n",
      "Iteration 6, inertia 28047.736328125\n",
      "Iteration 7, inertia 28035.853515625\n",
      "Iteration 8, inertia 28028.47265625\n",
      "Iteration 9, inertia 28023.251953125\n",
      "Iteration 10, inertia 28020.169921875\n",
      "Iteration 11, inertia 28018.150390625\n",
      "Iteration 12, inertia 28016.9921875\n",
      "Iteration 13, inertia 28016.537109375\n",
      "Iteration 14, inertia 28015.81640625\n",
      "Iteration 15, inertia 28015.486328125\n",
      "Iteration 16, inertia 28015.080078125\n",
      "Iteration 17, inertia 28014.76171875\n",
      "Iteration 18, inertia 28014.544921875\n",
      "Iteration 19, inertia 28014.580078125\n",
      "Iteration 20, inertia 28014.484375\n",
      "Iteration 21, inertia 28014.451171875\n",
      "Iteration 22, inertia 28014.45703125\n",
      "Iteration 23, inertia 28014.431640625\n",
      "Iteration 24, inertia 28014.359375\n",
      "Iteration 25, inertia 28014.38671875\n",
      "Iteration 26, inertia 28014.33203125\n",
      "Iteration 27, inertia 28014.2578125\n",
      "Iteration 28, inertia 28014.2421875\n",
      "Iteration 29, inertia 28014.232421875\n",
      "Iteration 30, inertia 28014.259765625\n",
      "Iteration 31, inertia 28014.17578125\n",
      "Iteration 32, inertia 28014.11328125\n",
      "Iteration 33, inertia 28014.140625\n",
      "Iteration 34, inertia 28014.193359375\n",
      "Iteration 35, inertia 28014.1328125\n",
      "Iteration 36, inertia 28014.0859375\n",
      "Iteration 37, inertia 28014.12109375\n",
      "Iteration 38, inertia 28014.115234375\n",
      "Iteration 39, inertia 28014.095703125\n",
      "Iteration 40, inertia 28014.05078125\n",
      "Iteration 41, inertia 28013.994140625\n",
      "Iteration 42, inertia 28013.986328125\n",
      "Iteration 43, inertia 28013.94921875\n",
      "Iteration 44, inertia 28013.900390625\n",
      "Iteration 45, inertia 28013.892578125\n",
      "Iteration 46, inertia 28013.888671875\n",
      "Iteration 47, inertia 28013.876953125\n",
      "Iteration 48, inertia 28013.869140625\n",
      "Iteration 49, inertia 28013.8671875\n",
      "Iteration 50, inertia 28013.8828125\n",
      "Iteration 51, inertia 28013.865234375\n",
      "Iteration 52, inertia 28013.88671875\n",
      "Iteration 53, inertia 28013.8984375\n",
      "Iteration 54, inertia 28013.873046875\n",
      "Iteration 55, inertia 28013.849609375\n",
      "Iteration 56, inertia 28013.83203125\n",
      "Iteration 57, inertia 28013.84765625\n",
      "Iteration 58, inertia 28013.82421875\n",
      "Iteration 59, inertia 28013.810546875\n",
      "Iteration 60, inertia 28013.828125\n",
      "Iteration 61, inertia 28013.87890625\n",
      "Iteration 62, inertia 28013.82421875\n",
      "Iteration 63, inertia 28013.8515625\n",
      "Iteration 64, inertia 28013.939453125\n",
      "Iteration 65, inertia 28013.931640625\n",
      "Iteration 66, inertia 28013.923828125\n",
      "Iteration 67, inertia 28013.97265625\n",
      "Iteration 68, inertia 28013.9453125\n",
      "Iteration 69, inertia 28013.994140625\n",
      "Iteration 70, inertia 28013.953125\n",
      "Iteration 71, inertia 28013.9453125\n",
      "Converged at iteration 71: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46221.7890625\n",
      "Iteration 1, inertia 29073.337890625\n",
      "Iteration 2, inertia 28446.55859375\n",
      "Iteration 3, inertia 28258.650390625\n",
      "Iteration 4, inertia 28175.67578125\n",
      "Iteration 5, inertia 28112.4453125\n",
      "Iteration 6, inertia 28060.791015625\n",
      "Iteration 7, inertia 28034.57421875\n",
      "Iteration 8, inertia 28020.896484375\n",
      "Iteration 9, inertia 28012.25390625\n",
      "Iteration 10, inertia 28005.435546875\n",
      "Iteration 11, inertia 27999.830078125\n",
      "Iteration 12, inertia 27995.83203125\n",
      "Iteration 13, inertia 27992.59765625\n",
      "Iteration 14, inertia 27989.65234375\n",
      "Iteration 15, inertia 27987.111328125\n",
      "Iteration 16, inertia 27984.2734375\n",
      "Iteration 17, inertia 27979.984375\n",
      "Iteration 18, inertia 27974.60546875\n",
      "Iteration 19, inertia 27970.638671875\n",
      "Iteration 20, inertia 27967.96484375\n",
      "Iteration 21, inertia 27965.23828125\n",
      "Iteration 22, inertia 27961.68359375\n",
      "Iteration 23, inertia 27957.796875\n",
      "Iteration 24, inertia 27951.560546875\n",
      "Iteration 25, inertia 27944.900390625\n",
      "Iteration 26, inertia 27942.091796875\n",
      "Iteration 27, inertia 27941.35546875\n",
      "Iteration 28, inertia 27940.681640625\n",
      "Iteration 29, inertia 27939.83203125\n",
      "Iteration 30, inertia 27939.126953125\n",
      "Iteration 31, inertia 27938.560546875\n",
      "Iteration 32, inertia 27937.77734375\n",
      "Iteration 33, inertia 27937.275390625\n",
      "Iteration 34, inertia 27936.7265625\n",
      "Iteration 35, inertia 27936.232421875\n",
      "Iteration 36, inertia 27935.701171875\n",
      "Iteration 37, inertia 27935.505859375\n",
      "Iteration 38, inertia 27935.435546875\n",
      "Iteration 39, inertia 27935.03125\n",
      "Iteration 40, inertia 27934.5859375\n",
      "Iteration 41, inertia 27934.103515625\n",
      "Iteration 42, inertia 27933.423828125\n",
      "Iteration 43, inertia 27932.701171875\n",
      "Iteration 44, inertia 27931.412109375\n",
      "Iteration 45, inertia 27929.681640625\n",
      "Iteration 46, inertia 27928.017578125\n",
      "Iteration 47, inertia 27926.62109375\n",
      "Iteration 48, inertia 27925.19140625\n",
      "Iteration 49, inertia 27924.150390625\n",
      "Iteration 50, inertia 27923.484375\n",
      "Iteration 51, inertia 27922.833984375\n",
      "Iteration 52, inertia 27922.234375\n",
      "Iteration 53, inertia 27921.666015625\n",
      "Iteration 54, inertia 27920.810546875\n",
      "Iteration 55, inertia 27919.99609375\n",
      "Iteration 56, inertia 27919.439453125\n",
      "Iteration 57, inertia 27918.869140625\n",
      "Iteration 58, inertia 27918.33984375\n",
      "Iteration 59, inertia 27918.072265625\n",
      "Iteration 60, inertia 27917.736328125\n",
      "Iteration 61, inertia 27917.59765625\n",
      "Iteration 62, inertia 27917.51953125\n",
      "Iteration 63, inertia 27917.345703125\n",
      "Iteration 64, inertia 27917.291015625\n",
      "Iteration 65, inertia 27917.0234375\n",
      "Iteration 66, inertia 27917.0\n",
      "Iteration 67, inertia 27916.990234375\n",
      "Iteration 68, inertia 27916.859375\n",
      "Iteration 69, inertia 27916.849609375\n",
      "Iteration 70, inertia 27916.845703125\n",
      "Iteration 71, inertia 27916.78125\n",
      "Iteration 72, inertia 27916.755859375\n",
      "Iteration 73, inertia 27916.794921875\n",
      "Iteration 74, inertia 27916.87109375\n",
      "Iteration 75, inertia 27916.83984375\n",
      "Iteration 76, inertia 27916.8046875\n",
      "Iteration 77, inertia 27916.794921875\n",
      "Iteration 78, inertia 27916.73046875\n",
      "Iteration 79, inertia 27916.720703125\n",
      "Iteration 80, inertia 27916.69140625\n",
      "Iteration 81, inertia 27916.642578125\n",
      "Iteration 82, inertia 27916.556640625\n",
      "Iteration 83, inertia 27916.439453125\n",
      "Iteration 84, inertia 27916.509765625\n",
      "Iteration 85, inertia 27916.484375\n",
      "Iteration 86, inertia 27916.453125\n",
      "Iteration 87, inertia 27916.423828125\n",
      "Iteration 88, inertia 27916.447265625\n",
      "Iteration 89, inertia 27916.345703125\n",
      "Iteration 90, inertia 27916.255859375\n",
      "Iteration 91, inertia 27916.169921875\n",
      "Iteration 92, inertia 27916.171875\n",
      "Iteration 93, inertia 27916.142578125\n",
      "Iteration 94, inertia 27916.099609375\n",
      "Iteration 95, inertia 27916.04296875\n",
      "Iteration 96, inertia 27916.017578125\n",
      "Iteration 97, inertia 27916.1328125\n",
      "Iteration 98, inertia 27916.08203125\n",
      "Iteration 99, inertia 27915.99609375\n",
      "Iteration 100, inertia 27915.904296875\n",
      "Iteration 101, inertia 27915.900390625\n",
      "Iteration 102, inertia 27915.787109375\n",
      "Iteration 103, inertia 27915.787109375\n",
      "Iteration 104, inertia 27915.732421875\n",
      "Iteration 105, inertia 27915.75\n",
      "Iteration 106, inertia 27915.703125\n",
      "Iteration 107, inertia 27915.63671875\n",
      "Iteration 108, inertia 27915.55078125\n",
      "Iteration 109, inertia 27915.396484375\n",
      "Iteration 110, inertia 27915.3359375\n",
      "Iteration 111, inertia 27915.35546875\n",
      "Iteration 112, inertia 27915.390625\n",
      "Iteration 113, inertia 27915.259765625\n",
      "Iteration 114, inertia 27915.21875\n",
      "Iteration 115, inertia 27915.1015625\n",
      "Iteration 116, inertia 27915.068359375\n",
      "Iteration 117, inertia 27914.978515625\n",
      "Iteration 118, inertia 27914.9296875\n",
      "Iteration 119, inertia 27914.994140625\n",
      "Iteration 120, inertia 27914.98828125\n",
      "Iteration 121, inertia 27914.9453125\n",
      "Iteration 122, inertia 27914.96484375\n",
      "Iteration 123, inertia 27914.9375\n",
      "Iteration 124, inertia 27914.95703125\n",
      "Iteration 125, inertia 27914.865234375\n",
      "Iteration 126, inertia 27914.828125\n",
      "Iteration 127, inertia 27914.796875\n",
      "Iteration 128, inertia 27914.822265625\n",
      "Iteration 129, inertia 27914.78125\n",
      "Iteration 130, inertia 27914.734375\n",
      "Iteration 131, inertia 27914.6640625\n",
      "Iteration 132, inertia 27914.701171875\n",
      "Iteration 133, inertia 27914.66796875\n",
      "Iteration 134, inertia 27914.67578125\n",
      "Iteration 135, inertia 27914.6796875\n",
      "Iteration 136, inertia 27914.66796875\n",
      "Iteration 137, inertia 27914.751953125\n",
      "Iteration 138, inertia 27914.75390625\n",
      "Converged at iteration 138: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46851.0078125\n",
      "Iteration 1, inertia 29297.958984375\n",
      "Iteration 2, inertia 28579.955078125\n",
      "Iteration 3, inertia 28360.25\n",
      "Iteration 4, inertia 28249.533203125\n",
      "Iteration 5, inertia 28169.4765625\n",
      "Iteration 6, inertia 28134.63671875\n",
      "Iteration 7, inertia 28114.529296875\n",
      "Iteration 8, inertia 28101.6953125\n",
      "Iteration 9, inertia 28090.986328125\n",
      "Iteration 10, inertia 28080.259765625\n",
      "Iteration 11, inertia 28064.095703125\n",
      "Iteration 12, inertia 28055.623046875\n",
      "Iteration 13, inertia 28048.544921875\n",
      "Iteration 14, inertia 28042.09765625\n",
      "Iteration 15, inertia 28036.001953125\n",
      "Iteration 16, inertia 28032.185546875\n",
      "Iteration 17, inertia 28029.87890625\n",
      "Iteration 18, inertia 28028.83203125\n",
      "Iteration 19, inertia 28028.041015625\n",
      "Iteration 20, inertia 28027.16796875\n",
      "Iteration 21, inertia 28026.693359375\n",
      "Iteration 22, inertia 28026.21875\n",
      "Iteration 23, inertia 28025.384765625\n",
      "Iteration 24, inertia 28024.212890625\n",
      "Iteration 25, inertia 28021.603515625\n",
      "Iteration 26, inertia 28016.68359375\n",
      "Iteration 27, inertia 28012.669921875\n",
      "Iteration 28, inertia 28011.71875\n",
      "Iteration 29, inertia 28011.521484375\n",
      "Iteration 30, inertia 28011.3046875\n",
      "Iteration 31, inertia 28010.91796875\n",
      "Iteration 32, inertia 28010.39453125\n",
      "Iteration 33, inertia 28010.015625\n",
      "Iteration 34, inertia 28009.857421875\n",
      "Iteration 35, inertia 28009.5703125\n",
      "Iteration 36, inertia 28009.455078125\n",
      "Iteration 37, inertia 28009.224609375\n",
      "Iteration 38, inertia 28009.25390625\n",
      "Iteration 39, inertia 28009.0546875\n",
      "Iteration 40, inertia 28008.841796875\n",
      "Iteration 41, inertia 28008.6796875\n",
      "Iteration 42, inertia 28008.63671875\n",
      "Iteration 43, inertia 28008.529296875\n",
      "Iteration 44, inertia 28008.37890625\n",
      "Iteration 45, inertia 28008.3984375\n",
      "Iteration 46, inertia 28008.2578125\n",
      "Iteration 47, inertia 28008.35546875\n",
      "Iteration 48, inertia 28008.296875\n",
      "Iteration 49, inertia 28008.263671875\n",
      "Iteration 50, inertia 28008.2734375\n",
      "Iteration 51, inertia 28008.326171875\n",
      "Iteration 52, inertia 28008.34375\n",
      "Iteration 53, inertia 28008.29296875\n",
      "Iteration 54, inertia 28008.3046875\n",
      "Converged at iteration 54: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46651.015625\n",
      "Iteration 1, inertia 29292.66015625\n",
      "Iteration 2, inertia 28686.978515625\n",
      "Iteration 3, inertia 28467.125\n",
      "Iteration 4, inertia 28315.720703125\n",
      "Iteration 5, inertia 28212.990234375\n",
      "Iteration 6, inertia 28167.185546875\n",
      "Iteration 7, inertia 28145.126953125\n",
      "Iteration 8, inertia 28132.5390625\n",
      "Iteration 9, inertia 28124.958984375\n",
      "Iteration 10, inertia 28119.27734375\n",
      "Iteration 11, inertia 28113.513671875\n",
      "Iteration 12, inertia 28108.966796875\n",
      "Iteration 13, inertia 28104.525390625\n",
      "Iteration 14, inertia 28100.12109375\n",
      "Iteration 15, inertia 28096.140625\n",
      "Iteration 16, inertia 28090.98046875\n",
      "Iteration 17, inertia 28082.5\n",
      "Iteration 18, inertia 28069.4609375\n",
      "Iteration 19, inertia 28053.001953125\n",
      "Iteration 20, inertia 28039.53125\n",
      "Iteration 21, inertia 28025.37109375\n",
      "Iteration 22, inertia 28011.28515625\n",
      "Iteration 23, inertia 28002.328125\n",
      "Iteration 24, inertia 27997.328125\n",
      "Iteration 25, inertia 27993.9609375\n",
      "Iteration 26, inertia 27991.66015625\n",
      "Iteration 27, inertia 27990.0078125\n",
      "Iteration 28, inertia 27988.685546875\n",
      "Iteration 29, inertia 27987.833984375\n",
      "Iteration 30, inertia 27987.001953125\n",
      "Iteration 31, inertia 27986.609375\n",
      "Iteration 32, inertia 27986.0234375\n",
      "Iteration 33, inertia 27985.318359375\n",
      "Iteration 34, inertia 27984.8125\n",
      "Iteration 35, inertia 27984.158203125\n",
      "Iteration 36, inertia 27983.375\n",
      "Iteration 37, inertia 27981.900390625\n",
      "Iteration 38, inertia 27980.2578125\n",
      "Iteration 39, inertia 27978.74609375\n",
      "Iteration 40, inertia 27977.755859375\n",
      "Iteration 41, inertia 27977.380859375\n",
      "Iteration 42, inertia 27976.869140625\n",
      "Iteration 43, inertia 27976.662109375\n",
      "Iteration 44, inertia 27976.494140625\n",
      "Iteration 45, inertia 27976.5625\n",
      "Iteration 46, inertia 27976.53125\n",
      "Iteration 47, inertia 27976.5078125\n",
      "Iteration 48, inertia 27976.48046875\n",
      "Iteration 49, inertia 27976.490234375\n",
      "Iteration 50, inertia 27976.421875\n",
      "Iteration 51, inertia 27976.39453125\n",
      "Iteration 52, inertia 27976.396484375\n",
      "Iteration 53, inertia 27976.353515625\n",
      "Iteration 54, inertia 27976.359375\n",
      "Iteration 55, inertia 27976.38671875\n",
      "Iteration 56, inertia 27976.388671875\n",
      "Iteration 57, inertia 27976.39453125\n",
      "Converged at iteration 57: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46462.77734375\n",
      "Iteration 1, inertia 29243.0859375\n",
      "Iteration 2, inertia 28635.568359375\n",
      "Iteration 3, inertia 28372.798828125\n",
      "Iteration 4, inertia 28265.83203125\n",
      "Iteration 5, inertia 28194.314453125\n",
      "Iteration 6, inertia 28149.09765625\n",
      "Iteration 7, inertia 28124.4375\n",
      "Iteration 8, inertia 28109.734375\n",
      "Iteration 9, inertia 28097.5546875\n",
      "Iteration 10, inertia 28086.494140625\n",
      "Iteration 11, inertia 28076.73828125\n",
      "Iteration 12, inertia 28071.978515625\n",
      "Iteration 13, inertia 28069.3359375\n",
      "Iteration 14, inertia 28067.87109375\n",
      "Iteration 15, inertia 28067.2421875\n",
      "Iteration 16, inertia 28066.533203125\n",
      "Iteration 17, inertia 28065.986328125\n",
      "Iteration 18, inertia 28065.484375\n",
      "Iteration 19, inertia 28065.26171875\n",
      "Iteration 20, inertia 28065.046875\n",
      "Iteration 21, inertia 28064.98828125\n",
      "Iteration 22, inertia 28064.751953125\n",
      "Iteration 23, inertia 28064.640625\n",
      "Iteration 24, inertia 28064.5703125\n",
      "Iteration 25, inertia 28064.388671875\n",
      "Iteration 26, inertia 28064.10546875\n",
      "Iteration 27, inertia 28064.08203125\n",
      "Iteration 28, inertia 28064.048828125\n",
      "Iteration 29, inertia 28063.955078125\n",
      "Iteration 30, inertia 28063.859375\n",
      "Iteration 31, inertia 28063.794921875\n",
      "Iteration 32, inertia 28063.5078125\n",
      "Iteration 33, inertia 28063.361328125\n",
      "Iteration 34, inertia 28063.357421875\n",
      "Iteration 35, inertia 28063.333984375\n",
      "Iteration 36, inertia 28063.150390625\n",
      "Iteration 37, inertia 28062.900390625\n",
      "Iteration 38, inertia 28062.74609375\n",
      "Iteration 39, inertia 28062.41796875\n",
      "Iteration 40, inertia 28061.974609375\n",
      "Iteration 41, inertia 28061.208984375\n",
      "Iteration 42, inertia 28060.5546875\n",
      "Iteration 43, inertia 28059.6015625\n",
      "Iteration 44, inertia 28059.015625\n",
      "Iteration 45, inertia 28058.3984375\n",
      "Iteration 46, inertia 28057.9296875\n",
      "Iteration 47, inertia 28057.3125\n",
      "Iteration 48, inertia 28056.73046875\n",
      "Iteration 49, inertia 28056.046875\n",
      "Iteration 50, inertia 28055.33984375\n",
      "Iteration 51, inertia 28054.455078125\n",
      "Iteration 52, inertia 28053.845703125\n",
      "Iteration 53, inertia 28053.232421875\n",
      "Iteration 54, inertia 28052.64453125\n",
      "Iteration 55, inertia 28052.201171875\n",
      "Iteration 56, inertia 28051.697265625\n",
      "Iteration 57, inertia 28051.095703125\n",
      "Iteration 58, inertia 28050.51953125\n",
      "Iteration 59, inertia 28050.142578125\n",
      "Iteration 60, inertia 28049.892578125\n",
      "Iteration 61, inertia 28049.6328125\n",
      "Iteration 62, inertia 28049.19140625\n",
      "Iteration 63, inertia 28048.93359375\n",
      "Iteration 64, inertia 28048.482421875\n",
      "Iteration 65, inertia 28048.091796875\n",
      "Iteration 66, inertia 28047.8671875\n",
      "Iteration 67, inertia 28047.203125\n",
      "Iteration 68, inertia 28046.447265625\n",
      "Iteration 69, inertia 28045.416015625\n",
      "Iteration 70, inertia 28043.58984375\n",
      "Iteration 71, inertia 28041.685546875\n",
      "Iteration 72, inertia 28038.681640625\n",
      "Iteration 73, inertia 28034.056640625\n",
      "Iteration 74, inertia 28030.126953125\n",
      "Iteration 75, inertia 28027.6796875\n",
      "Iteration 76, inertia 28026.154296875\n",
      "Iteration 77, inertia 28024.953125\n",
      "Iteration 78, inertia 28024.4453125\n",
      "Iteration 79, inertia 28024.046875\n",
      "Iteration 80, inertia 28023.50390625\n",
      "Iteration 81, inertia 28023.29296875\n",
      "Iteration 82, inertia 28022.890625\n",
      "Iteration 83, inertia 28022.779296875\n",
      "Iteration 84, inertia 28022.72265625\n",
      "Iteration 85, inertia 28022.677734375\n",
      "Iteration 86, inertia 28022.5625\n",
      "Iteration 87, inertia 28022.455078125\n",
      "Iteration 88, inertia 28022.37109375\n",
      "Iteration 89, inertia 28022.376953125\n",
      "Iteration 90, inertia 28022.341796875\n",
      "Iteration 91, inertia 28022.279296875\n",
      "Iteration 92, inertia 28022.205078125\n",
      "Iteration 93, inertia 28022.095703125\n",
      "Iteration 94, inertia 28022.099609375\n",
      "Iteration 95, inertia 28022.087890625\n",
      "Iteration 96, inertia 28022.037109375\n",
      "Iteration 97, inertia 28022.07421875\n",
      "Iteration 98, inertia 28022.01953125\n",
      "Iteration 99, inertia 28022.0390625\n",
      "Iteration 100, inertia 28022.0546875\n",
      "Iteration 101, inertia 28022.15234375\n",
      "Iteration 102, inertia 28022.177734375\n",
      "Iteration 103, inertia 28022.15625\n",
      "Iteration 104, inertia 28022.171875\n",
      "Converged at iteration 104: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46829.109375\n",
      "Iteration 1, inertia 29416.138671875\n",
      "Iteration 2, inertia 28733.830078125\n",
      "Iteration 3, inertia 28425.62109375\n",
      "Iteration 4, inertia 28270.0625\n",
      "Iteration 5, inertia 28184.79296875\n",
      "Iteration 6, inertia 28120.1171875\n",
      "Iteration 7, inertia 28056.451171875\n",
      "Iteration 8, inertia 28006.599609375\n",
      "Iteration 9, inertia 27976.0\n",
      "Iteration 10, inertia 27954.87890625\n",
      "Iteration 11, inertia 27942.478515625\n",
      "Iteration 12, inertia 27934.484375\n",
      "Iteration 13, inertia 27928.833984375\n",
      "Iteration 14, inertia 27924.3671875\n",
      "Iteration 15, inertia 27921.154296875\n",
      "Iteration 16, inertia 27918.591796875\n",
      "Iteration 17, inertia 27916.75390625\n",
      "Iteration 18, inertia 27915.306640625\n",
      "Iteration 19, inertia 27913.8828125\n",
      "Iteration 20, inertia 27911.943359375\n",
      "Iteration 21, inertia 27909.892578125\n",
      "Iteration 22, inertia 27907.259765625\n",
      "Iteration 23, inertia 27904.544921875\n",
      "Iteration 24, inertia 27902.490234375\n",
      "Iteration 25, inertia 27900.595703125\n",
      "Iteration 26, inertia 27899.435546875\n",
      "Iteration 27, inertia 27898.529296875\n",
      "Iteration 28, inertia 27898.0859375\n",
      "Iteration 29, inertia 27897.513671875\n",
      "Iteration 30, inertia 27897.060546875\n",
      "Iteration 31, inertia 27896.478515625\n",
      "Iteration 32, inertia 27896.015625\n",
      "Iteration 33, inertia 27894.65625\n",
      "Iteration 34, inertia 27891.359375\n",
      "Iteration 35, inertia 27886.07421875\n",
      "Iteration 36, inertia 27879.0234375\n",
      "Iteration 37, inertia 27872.3984375\n",
      "Iteration 38, inertia 27867.91796875\n",
      "Iteration 39, inertia 27865.71484375\n",
      "Iteration 40, inertia 27864.537109375\n",
      "Iteration 41, inertia 27863.228515625\n",
      "Iteration 42, inertia 27862.048828125\n",
      "Iteration 43, inertia 27860.8125\n",
      "Iteration 44, inertia 27859.89453125\n",
      "Iteration 45, inertia 27859.310546875\n",
      "Iteration 46, inertia 27858.54296875\n",
      "Iteration 47, inertia 27857.9453125\n",
      "Iteration 48, inertia 27857.591796875\n",
      "Iteration 49, inertia 27857.12890625\n",
      "Iteration 50, inertia 27856.775390625\n",
      "Iteration 51, inertia 27856.29296875\n",
      "Iteration 52, inertia 27855.9765625\n",
      "Iteration 53, inertia 27855.642578125\n",
      "Iteration 54, inertia 27855.193359375\n",
      "Iteration 55, inertia 27854.740234375\n",
      "Iteration 56, inertia 27854.3828125\n",
      "Iteration 57, inertia 27854.13671875\n",
      "Iteration 58, inertia 27853.80078125\n",
      "Iteration 59, inertia 27853.3984375\n",
      "Iteration 60, inertia 27852.849609375\n",
      "Iteration 61, inertia 27852.44921875\n",
      "Iteration 62, inertia 27852.037109375\n",
      "Iteration 63, inertia 27851.677734375\n",
      "Iteration 64, inertia 27851.205078125\n",
      "Iteration 65, inertia 27850.63671875\n",
      "Iteration 66, inertia 27850.19921875\n",
      "Iteration 67, inertia 27849.3359375\n",
      "Iteration 68, inertia 27848.35546875\n",
      "Iteration 69, inertia 27847.32421875\n",
      "Iteration 70, inertia 27846.353515625\n",
      "Iteration 71, inertia 27845.662109375\n",
      "Iteration 72, inertia 27844.845703125\n",
      "Iteration 73, inertia 27843.861328125\n",
      "Iteration 74, inertia 27842.61328125\n",
      "Iteration 75, inertia 27840.80859375\n",
      "Iteration 76, inertia 27838.443359375\n",
      "Iteration 77, inertia 27833.44140625\n",
      "Iteration 78, inertia 27825.60546875\n",
      "Iteration 79, inertia 27814.21484375\n",
      "Iteration 80, inertia 27802.091796875\n",
      "Iteration 81, inertia 27795.861328125\n",
      "Iteration 82, inertia 27794.451171875\n",
      "Iteration 83, inertia 27794.318359375\n",
      "Iteration 84, inertia 27794.314453125\n",
      "Iteration 85, inertia 27794.2890625\n",
      "Iteration 86, inertia 27794.28125\n",
      "Iteration 87, inertia 27794.177734375\n",
      "Iteration 88, inertia 27794.11328125\n",
      "Iteration 89, inertia 27794.025390625\n",
      "Iteration 90, inertia 27794.064453125\n",
      "Iteration 91, inertia 27794.025390625\n",
      "Iteration 92, inertia 27794.068359375\n",
      "Iteration 93, inertia 27794.068359375\n",
      "Iteration 94, inertia 27794.0390625\n",
      "Iteration 95, inertia 27794.08984375\n",
      "Iteration 96, inertia 27794.064453125\n",
      "Iteration 97, inertia 27794.06640625\n",
      "Converged at iteration 97: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46246.54296875\n",
      "Iteration 1, inertia 29237.416015625\n",
      "Iteration 2, inertia 28651.109375\n",
      "Iteration 3, inertia 28445.119140625\n",
      "Iteration 4, inertia 28349.47265625\n",
      "Iteration 5, inertia 28272.8359375\n",
      "Iteration 6, inertia 28209.291015625\n",
      "Iteration 7, inertia 28150.79296875\n",
      "Iteration 8, inertia 28108.78515625\n",
      "Iteration 9, inertia 28078.619140625\n",
      "Iteration 10, inertia 28054.287109375\n",
      "Iteration 11, inertia 28040.83984375\n",
      "Iteration 12, inertia 28029.59375\n",
      "Iteration 13, inertia 28016.353515625\n",
      "Iteration 14, inertia 28005.03515625\n",
      "Iteration 15, inertia 27998.751953125\n",
      "Iteration 16, inertia 27995.255859375\n",
      "Iteration 17, inertia 27992.265625\n",
      "Iteration 18, inertia 27990.328125\n",
      "Iteration 19, inertia 27988.818359375\n",
      "Iteration 20, inertia 27987.61328125\n",
      "Iteration 21, inertia 27986.642578125\n",
      "Iteration 22, inertia 27985.474609375\n",
      "Iteration 23, inertia 27984.033203125\n",
      "Iteration 24, inertia 27982.603515625\n",
      "Iteration 25, inertia 27981.337890625\n",
      "Iteration 26, inertia 27980.080078125\n",
      "Iteration 27, inertia 27978.962890625\n",
      "Iteration 28, inertia 27977.966796875\n",
      "Iteration 29, inertia 27977.22265625\n",
      "Iteration 30, inertia 27976.6875\n",
      "Iteration 31, inertia 27976.068359375\n",
      "Iteration 32, inertia 27975.572265625\n",
      "Iteration 33, inertia 27975.138671875\n",
      "Iteration 34, inertia 27974.73046875\n",
      "Iteration 35, inertia 27974.330078125\n",
      "Iteration 36, inertia 27973.962890625\n",
      "Iteration 37, inertia 27973.802734375\n",
      "Iteration 38, inertia 27973.3984375\n",
      "Iteration 39, inertia 27972.9375\n",
      "Iteration 40, inertia 27972.25\n",
      "Iteration 41, inertia 27971.55859375\n",
      "Iteration 42, inertia 27970.91796875\n",
      "Iteration 43, inertia 27970.3671875\n",
      "Iteration 44, inertia 27969.87890625\n",
      "Iteration 45, inertia 27969.73046875\n",
      "Iteration 46, inertia 27969.419921875\n",
      "Iteration 47, inertia 27969.171875\n",
      "Iteration 48, inertia 27969.154296875\n",
      "Iteration 49, inertia 27969.03515625\n",
      "Iteration 50, inertia 27968.9296875\n",
      "Iteration 51, inertia 27968.962890625\n",
      "Iteration 52, inertia 27968.94140625\n",
      "Iteration 53, inertia 27968.892578125\n",
      "Iteration 54, inertia 27968.869140625\n",
      "Iteration 55, inertia 27968.896484375\n",
      "Iteration 56, inertia 27968.896484375\n",
      "Iteration 57, inertia 27968.923828125\n",
      "Iteration 58, inertia 27968.900390625\n",
      "Iteration 59, inertia 27968.884765625\n",
      "Iteration 60, inertia 27968.8828125\n",
      "Iteration 61, inertia 27968.876953125\n",
      "Converged at iteration 61: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46648.75\n",
      "Iteration 1, inertia 29154.111328125\n",
      "Iteration 2, inertia 28657.556640625\n",
      "Iteration 3, inertia 28466.9453125\n",
      "Iteration 4, inertia 28336.279296875\n",
      "Iteration 5, inertia 28240.193359375\n",
      "Iteration 6, inertia 28169.470703125\n",
      "Iteration 7, inertia 28113.375\n",
      "Iteration 8, inertia 28073.38671875\n",
      "Iteration 9, inertia 28047.869140625\n",
      "Iteration 10, inertia 28021.42578125\n",
      "Iteration 11, inertia 27998.42578125\n",
      "Iteration 12, inertia 27992.234375\n",
      "Iteration 13, inertia 27988.875\n",
      "Iteration 14, inertia 27986.478515625\n",
      "Iteration 15, inertia 27984.634765625\n",
      "Iteration 16, inertia 27982.947265625\n",
      "Iteration 17, inertia 27981.251953125\n",
      "Iteration 18, inertia 27979.56640625\n",
      "Iteration 19, inertia 27978.322265625\n",
      "Iteration 20, inertia 27977.15234375\n",
      "Iteration 21, inertia 27975.857421875\n",
      "Iteration 22, inertia 27975.1171875\n",
      "Iteration 23, inertia 27974.40234375\n",
      "Iteration 24, inertia 27973.615234375\n",
      "Iteration 25, inertia 27972.84765625\n",
      "Iteration 26, inertia 27971.931640625\n",
      "Iteration 27, inertia 27970.83984375\n",
      "Iteration 28, inertia 27969.880859375\n",
      "Iteration 29, inertia 27969.51171875\n",
      "Iteration 30, inertia 27968.888671875\n",
      "Iteration 31, inertia 27968.1796875\n",
      "Iteration 32, inertia 27966.80078125\n",
      "Iteration 33, inertia 27965.4296875\n",
      "Iteration 34, inertia 27964.38671875\n",
      "Iteration 35, inertia 27963.572265625\n",
      "Iteration 36, inertia 27963.111328125\n",
      "Iteration 37, inertia 27962.740234375\n",
      "Iteration 38, inertia 27962.29296875\n",
      "Iteration 39, inertia 27961.798828125\n",
      "Iteration 40, inertia 27961.32421875\n",
      "Iteration 41, inertia 27961.076171875\n",
      "Iteration 42, inertia 27960.685546875\n",
      "Iteration 43, inertia 27960.33203125\n",
      "Iteration 44, inertia 27960.2109375\n",
      "Iteration 45, inertia 27960.140625\n",
      "Iteration 46, inertia 27960.083984375\n",
      "Iteration 47, inertia 27960.056640625\n",
      "Iteration 48, inertia 27960.0078125\n",
      "Iteration 49, inertia 27959.90625\n",
      "Iteration 50, inertia 27959.921875\n",
      "Iteration 51, inertia 27959.880859375\n",
      "Iteration 52, inertia 27959.888671875\n",
      "Iteration 53, inertia 27959.888671875\n",
      "Iteration 54, inertia 27959.826171875\n",
      "Iteration 55, inertia 27959.8046875\n",
      "Iteration 56, inertia 27959.751953125\n",
      "Iteration 57, inertia 27959.724609375\n",
      "Iteration 58, inertia 27959.74609375\n",
      "Iteration 59, inertia 27959.76171875\n",
      "Iteration 60, inertia 27959.78515625\n",
      "Iteration 61, inertia 27959.69921875\n",
      "Iteration 62, inertia 27959.62109375\n",
      "Iteration 63, inertia 27959.498046875\n",
      "Iteration 64, inertia 27959.37890625\n",
      "Iteration 65, inertia 27959.251953125\n",
      "Iteration 66, inertia 27959.07421875\n",
      "Iteration 67, inertia 27958.9375\n",
      "Iteration 68, inertia 27958.828125\n",
      "Iteration 69, inertia 27958.625\n",
      "Iteration 70, inertia 27958.23828125\n",
      "Iteration 71, inertia 27957.75\n",
      "Iteration 72, inertia 27957.091796875\n",
      "Iteration 73, inertia 27955.80078125\n",
      "Iteration 74, inertia 27953.955078125\n",
      "Iteration 75, inertia 27950.63671875\n",
      "Iteration 76, inertia 27947.09765625\n",
      "Iteration 77, inertia 27944.51171875\n",
      "Iteration 78, inertia 27942.833984375\n",
      "Iteration 79, inertia 27941.783203125\n",
      "Iteration 80, inertia 27941.203125\n",
      "Iteration 81, inertia 27940.982421875\n",
      "Iteration 82, inertia 27940.708984375\n",
      "Iteration 83, inertia 27940.5390625\n",
      "Iteration 84, inertia 27940.447265625\n",
      "Iteration 85, inertia 27940.318359375\n",
      "Iteration 86, inertia 27940.26953125\n",
      "Iteration 87, inertia 27940.27734375\n",
      "Iteration 88, inertia 27940.310546875\n",
      "Iteration 89, inertia 27940.291015625\n",
      "Iteration 90, inertia 27940.310546875\n",
      "Iteration 91, inertia 27940.255859375\n",
      "Iteration 92, inertia 27940.181640625\n",
      "Iteration 93, inertia 27940.17578125\n",
      "Iteration 94, inertia 27940.23828125\n",
      "Iteration 95, inertia 27940.201171875\n",
      "Iteration 96, inertia 27940.17578125\n",
      "Converged at iteration 96: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46368.66796875\n",
      "Iteration 1, inertia 29113.880859375\n",
      "Iteration 2, inertia 28630.416015625\n",
      "Iteration 3, inertia 28477.5078125\n",
      "Iteration 4, inertia 28395.587890625\n",
      "Iteration 5, inertia 28332.126953125\n",
      "Iteration 6, inertia 28275.33203125\n",
      "Iteration 7, inertia 28239.537109375\n",
      "Iteration 8, inertia 28211.671875\n",
      "Iteration 9, inertia 28191.5390625\n",
      "Iteration 10, inertia 28176.052734375\n",
      "Iteration 11, inertia 28163.681640625\n",
      "Iteration 12, inertia 28151.76171875\n",
      "Iteration 13, inertia 28133.818359375\n",
      "Iteration 14, inertia 28116.841796875\n",
      "Iteration 15, inertia 28109.369140625\n",
      "Iteration 16, inertia 28102.119140625\n",
      "Iteration 17, inertia 28094.21484375\n",
      "Iteration 18, inertia 28085.283203125\n",
      "Iteration 19, inertia 28078.15625\n",
      "Iteration 20, inertia 28072.03515625\n",
      "Iteration 21, inertia 28066.005859375\n",
      "Iteration 22, inertia 28060.724609375\n",
      "Iteration 23, inertia 28057.298828125\n",
      "Iteration 24, inertia 28052.572265625\n",
      "Iteration 25, inertia 28045.677734375\n",
      "Iteration 26, inertia 28039.1484375\n",
      "Iteration 27, inertia 28037.234375\n",
      "Iteration 28, inertia 28036.599609375\n",
      "Iteration 29, inertia 28036.09375\n",
      "Iteration 30, inertia 28035.935546875\n",
      "Iteration 31, inertia 28035.5625\n",
      "Iteration 32, inertia 28035.263671875\n",
      "Iteration 33, inertia 28034.888671875\n",
      "Iteration 34, inertia 28033.943359375\n",
      "Iteration 35, inertia 28024.732421875\n",
      "Iteration 36, inertia 27976.77734375\n",
      "Iteration 37, inertia 27949.84375\n",
      "Iteration 38, inertia 27949.525390625\n",
      "Iteration 39, inertia 27949.427734375\n",
      "Iteration 40, inertia 27949.462890625\n",
      "Iteration 41, inertia 27949.333984375\n",
      "Iteration 42, inertia 27949.283203125\n",
      "Iteration 43, inertia 27949.306640625\n",
      "Iteration 44, inertia 27949.265625\n",
      "Iteration 45, inertia 27949.263671875\n",
      "Iteration 46, inertia 27949.208984375\n",
      "Iteration 47, inertia 27949.181640625\n",
      "Iteration 48, inertia 27949.21875\n",
      "Iteration 49, inertia 27949.2421875\n",
      "Iteration 50, inertia 27949.162109375\n",
      "Iteration 51, inertia 27949.154296875\n",
      "Iteration 52, inertia 27949.078125\n",
      "Iteration 53, inertia 27949.08203125\n",
      "Iteration 54, inertia 27949.107421875\n",
      "Iteration 55, inertia 27949.05078125\n",
      "Iteration 56, inertia 27949.0234375\n",
      "Iteration 57, inertia 27949.03125\n",
      "Iteration 58, inertia 27949.060546875\n",
      "Iteration 59, inertia 27949.06640625\n",
      "Iteration 60, inertia 27949.06640625\n",
      "Converged at iteration 60: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46064.015625\n",
      "Iteration 1, inertia 29190.48046875\n",
      "Iteration 2, inertia 28573.865234375\n",
      "Iteration 3, inertia 28377.91015625\n",
      "Iteration 4, inertia 28283.650390625\n",
      "Iteration 5, inertia 28201.79296875\n",
      "Iteration 6, inertia 28135.228515625\n",
      "Iteration 7, inertia 28086.791015625\n",
      "Iteration 8, inertia 28040.55859375\n",
      "Iteration 9, inertia 27994.2890625\n",
      "Iteration 10, inertia 27964.681640625\n",
      "Iteration 11, inertia 27949.353515625\n",
      "Iteration 12, inertia 27939.49609375\n",
      "Iteration 13, inertia 27932.03515625\n",
      "Iteration 14, inertia 27926.962890625\n",
      "Iteration 15, inertia 27922.052734375\n",
      "Iteration 16, inertia 27916.416015625\n",
      "Iteration 17, inertia 27910.62109375\n",
      "Iteration 18, inertia 27906.779296875\n",
      "Iteration 19, inertia 27904.82421875\n",
      "Iteration 20, inertia 27903.70703125\n",
      "Iteration 21, inertia 27902.765625\n",
      "Iteration 22, inertia 27901.646484375\n",
      "Iteration 23, inertia 27900.599609375\n",
      "Iteration 24, inertia 27899.857421875\n",
      "Iteration 25, inertia 27899.005859375\n",
      "Iteration 26, inertia 27898.21484375\n",
      "Iteration 27, inertia 27897.544921875\n",
      "Iteration 28, inertia 27896.80859375\n",
      "Iteration 29, inertia 27896.279296875\n",
      "Iteration 30, inertia 27895.7265625\n",
      "Iteration 31, inertia 27895.599609375\n",
      "Iteration 32, inertia 27895.333984375\n",
      "Iteration 33, inertia 27895.232421875\n",
      "Iteration 34, inertia 27895.01171875\n",
      "Iteration 35, inertia 27894.845703125\n",
      "Iteration 36, inertia 27894.751953125\n",
      "Iteration 37, inertia 27894.556640625\n",
      "Iteration 38, inertia 27894.390625\n",
      "Iteration 39, inertia 27894.380859375\n",
      "Iteration 40, inertia 27894.427734375\n",
      "Iteration 41, inertia 27894.34765625\n",
      "Iteration 42, inertia 27894.341796875\n",
      "Iteration 43, inertia 27894.32421875\n",
      "Iteration 44, inertia 27894.296875\n",
      "Iteration 45, inertia 27894.244140625\n",
      "Iteration 46, inertia 27894.265625\n",
      "Iteration 47, inertia 27894.275390625\n",
      "Converged at iteration 47: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 47097.5546875\n",
      "Iteration 1, inertia 29556.10546875\n",
      "Iteration 2, inertia 28799.6484375\n",
      "Iteration 3, inertia 28506.771484375\n",
      "Iteration 4, inertia 28349.330078125\n",
      "Iteration 5, inertia 28240.509765625\n",
      "Iteration 6, inertia 28173.4296875\n",
      "Iteration 7, inertia 28118.08984375\n",
      "Iteration 8, inertia 28082.365234375\n",
      "Iteration 9, inertia 28057.1796875\n",
      "Iteration 10, inertia 28032.794921875\n",
      "Iteration 11, inertia 28003.849609375\n",
      "Iteration 12, inertia 27990.62109375\n",
      "Iteration 13, inertia 27983.44140625\n",
      "Iteration 14, inertia 27978.60546875\n",
      "Iteration 15, inertia 27975.150390625\n",
      "Iteration 16, inertia 27972.787109375\n",
      "Iteration 17, inertia 27970.607421875\n",
      "Iteration 18, inertia 27968.3046875\n",
      "Iteration 19, inertia 27965.24609375\n",
      "Iteration 20, inertia 27962.30859375\n",
      "Iteration 21, inertia 27959.18359375\n",
      "Iteration 22, inertia 27955.619140625\n",
      "Iteration 23, inertia 27952.078125\n",
      "Iteration 24, inertia 27948.505859375\n",
      "Iteration 25, inertia 27945.265625\n",
      "Iteration 26, inertia 27943.244140625\n",
      "Iteration 27, inertia 27941.716796875\n",
      "Iteration 28, inertia 27940.916015625\n",
      "Iteration 29, inertia 27939.84765625\n",
      "Iteration 30, inertia 27939.4296875\n",
      "Iteration 31, inertia 27938.755859375\n",
      "Iteration 32, inertia 27938.2578125\n",
      "Iteration 33, inertia 27937.8046875\n",
      "Iteration 34, inertia 27937.494140625\n",
      "Iteration 35, inertia 27937.080078125\n",
      "Iteration 36, inertia 27936.55859375\n",
      "Iteration 37, inertia 27935.791015625\n",
      "Iteration 38, inertia 27935.2109375\n",
      "Iteration 39, inertia 27934.51171875\n",
      "Iteration 40, inertia 27933.70703125\n",
      "Iteration 41, inertia 27933.353515625\n",
      "Iteration 42, inertia 27932.91796875\n",
      "Iteration 43, inertia 27932.4609375\n",
      "Iteration 44, inertia 27932.265625\n",
      "Iteration 45, inertia 27932.0625\n",
      "Iteration 46, inertia 27931.79296875\n",
      "Iteration 47, inertia 27931.6328125\n",
      "Iteration 48, inertia 27931.390625\n",
      "Iteration 49, inertia 27931.298828125\n",
      "Iteration 50, inertia 27931.111328125\n",
      "Iteration 51, inertia 27930.958984375\n",
      "Iteration 52, inertia 27930.908203125\n",
      "Iteration 53, inertia 27930.66015625\n",
      "Iteration 54, inertia 27930.61328125\n",
      "Iteration 55, inertia 27930.380859375\n",
      "Iteration 56, inertia 27930.27734375\n",
      "Iteration 57, inertia 27930.1953125\n",
      "Iteration 58, inertia 27930.12109375\n",
      "Iteration 59, inertia 27930.033203125\n",
      "Iteration 60, inertia 27929.990234375\n",
      "Iteration 61, inertia 27929.92578125\n",
      "Iteration 62, inertia 27929.982421875\n",
      "Iteration 63, inertia 27930.005859375\n",
      "Iteration 64, inertia 27929.982421875\n",
      "Iteration 65, inertia 27929.951171875\n",
      "Iteration 66, inertia 27929.943359375\n",
      "Iteration 67, inertia 27929.94140625\n",
      "Iteration 68, inertia 27929.91796875\n",
      "Iteration 69, inertia 27929.884765625\n",
      "Iteration 70, inertia 27929.857421875\n",
      "Iteration 71, inertia 27929.869140625\n",
      "Iteration 72, inertia 27929.85546875\n",
      "Iteration 73, inertia 27929.845703125\n",
      "Converged at iteration 73: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 47230.03125\n",
      "Iteration 1, inertia 29578.560546875\n",
      "Iteration 2, inertia 28808.046875\n",
      "Iteration 3, inertia 28491.65234375\n",
      "Iteration 4, inertia 28340.49609375\n",
      "Iteration 5, inertia 28256.923828125\n",
      "Iteration 6, inertia 28201.98828125\n",
      "Iteration 7, inertia 28146.158203125\n",
      "Iteration 8, inertia 28076.07421875\n",
      "Iteration 9, inertia 28034.037109375\n",
      "Iteration 10, inertia 28003.08203125\n",
      "Iteration 11, inertia 27976.546875\n",
      "Iteration 12, inertia 27960.857421875\n",
      "Iteration 13, inertia 27953.685546875\n",
      "Iteration 14, inertia 27948.029296875\n",
      "Iteration 15, inertia 27941.296875\n",
      "Iteration 16, inertia 27932.40625\n",
      "Iteration 17, inertia 27924.1953125\n",
      "Iteration 18, inertia 27918.123046875\n",
      "Iteration 19, inertia 27912.43359375\n",
      "Iteration 20, inertia 27906.80859375\n",
      "Iteration 21, inertia 27900.671875\n",
      "Iteration 22, inertia 27895.34375\n",
      "Iteration 23, inertia 27890.19140625\n",
      "Iteration 24, inertia 27885.462890625\n",
      "Iteration 25, inertia 27881.783203125\n",
      "Iteration 26, inertia 27879.87109375\n",
      "Iteration 27, inertia 27878.173828125\n",
      "Iteration 28, inertia 27877.15625\n",
      "Iteration 29, inertia 27876.333984375\n",
      "Iteration 30, inertia 27875.94140625\n",
      "Iteration 31, inertia 27875.509765625\n",
      "Iteration 32, inertia 27874.884765625\n",
      "Iteration 33, inertia 27874.212890625\n",
      "Iteration 34, inertia 27873.279296875\n",
      "Iteration 35, inertia 27872.23046875\n",
      "Iteration 36, inertia 27871.212890625\n",
      "Iteration 37, inertia 27870.7265625\n",
      "Iteration 38, inertia 27870.357421875\n",
      "Iteration 39, inertia 27870.171875\n",
      "Iteration 40, inertia 27870.076171875\n",
      "Iteration 41, inertia 27869.947265625\n",
      "Iteration 42, inertia 27869.779296875\n",
      "Iteration 43, inertia 27869.623046875\n",
      "Iteration 44, inertia 27869.619140625\n",
      "Iteration 45, inertia 27869.515625\n",
      "Iteration 46, inertia 27869.546875\n",
      "Iteration 47, inertia 27869.60546875\n",
      "Iteration 48, inertia 27869.56640625\n",
      "Iteration 49, inertia 27869.568359375\n",
      "Iteration 50, inertia 27869.537109375\n",
      "Iteration 51, inertia 27869.537109375\n",
      "Iteration 52, inertia 27869.544921875\n",
      "Iteration 53, inertia 27869.560546875\n",
      "Iteration 54, inertia 27869.599609375\n",
      "Iteration 55, inertia 27869.63671875\n",
      "Iteration 56, inertia 27869.66015625\n",
      "Iteration 57, inertia 27869.646484375\n",
      "Iteration 58, inertia 27869.626953125\n",
      "Iteration 59, inertia 27869.62109375\n",
      "Iteration 60, inertia 27869.59375\n",
      "Iteration 61, inertia 27869.599609375\n",
      "Iteration 62, inertia 27869.60546875\n",
      "Iteration 63, inertia 27869.59375\n",
      "Converged at iteration 63: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46429.9140625\n",
      "Iteration 1, inertia 29402.5703125\n",
      "Iteration 2, inertia 28837.4296875\n",
      "Iteration 3, inertia 28575.65234375\n",
      "Iteration 4, inertia 28359.61328125\n",
      "Iteration 5, inertia 28201.69921875\n",
      "Iteration 6, inertia 28122.009765625\n",
      "Iteration 7, inertia 28080.61328125\n",
      "Iteration 8, inertia 28048.6328125\n",
      "Iteration 9, inertia 28024.724609375\n",
      "Iteration 10, inertia 28005.634765625\n",
      "Iteration 11, inertia 27996.4609375\n",
      "Iteration 12, inertia 27991.873046875\n",
      "Iteration 13, inertia 27988.80078125\n",
      "Iteration 14, inertia 27984.8515625\n",
      "Iteration 15, inertia 27977.263671875\n",
      "Iteration 16, inertia 27966.369140625\n",
      "Iteration 17, inertia 27957.00390625\n",
      "Iteration 18, inertia 27953.005859375\n",
      "Iteration 19, inertia 27950.517578125\n",
      "Iteration 20, inertia 27949.08203125\n",
      "Iteration 21, inertia 27948.037109375\n",
      "Iteration 22, inertia 27947.20703125\n",
      "Iteration 23, inertia 27946.380859375\n",
      "Iteration 24, inertia 27945.828125\n",
      "Iteration 25, inertia 27945.298828125\n",
      "Iteration 26, inertia 27944.908203125\n",
      "Iteration 27, inertia 27944.18359375\n",
      "Iteration 28, inertia 27943.345703125\n",
      "Iteration 29, inertia 27942.32421875\n",
      "Iteration 30, inertia 27940.97265625\n",
      "Iteration 31, inertia 27938.833984375\n",
      "Iteration 32, inertia 27935.48828125\n",
      "Iteration 33, inertia 27930.03515625\n",
      "Iteration 34, inertia 27921.869140625\n",
      "Iteration 35, inertia 27911.720703125\n",
      "Iteration 36, inertia 27906.32421875\n",
      "Iteration 37, inertia 27905.119140625\n",
      "Iteration 38, inertia 27904.994140625\n",
      "Iteration 39, inertia 27904.99609375\n",
      "Iteration 40, inertia 27904.9453125\n",
      "Iteration 41, inertia 27904.921875\n",
      "Iteration 42, inertia 27904.779296875\n",
      "Iteration 43, inertia 27904.81640625\n",
      "Iteration 44, inertia 27904.80859375\n",
      "Iteration 45, inertia 27904.74609375\n",
      "Iteration 46, inertia 27904.708984375\n",
      "Iteration 47, inertia 27904.724609375\n",
      "Iteration 48, inertia 27904.732421875\n",
      "Converged at iteration 48: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 47265.47265625\n",
      "Iteration 1, inertia 29372.876953125\n",
      "Iteration 2, inertia 28636.99609375\n",
      "Iteration 3, inertia 28377.599609375\n",
      "Iteration 4, inertia 28230.09375\n",
      "Iteration 5, inertia 28162.46875\n",
      "Iteration 6, inertia 28124.08203125\n",
      "Iteration 7, inertia 28095.583984375\n",
      "Iteration 8, inertia 28073.12890625\n",
      "Iteration 9, inertia 28056.923828125\n",
      "Iteration 10, inertia 28045.158203125\n",
      "Iteration 11, inertia 28034.87109375\n",
      "Iteration 12, inertia 28024.708984375\n",
      "Iteration 13, inertia 28017.16796875\n",
      "Iteration 14, inertia 28012.974609375\n",
      "Iteration 15, inertia 28010.927734375\n",
      "Iteration 16, inertia 28009.69921875\n",
      "Iteration 17, inertia 28009.162109375\n",
      "Iteration 18, inertia 28008.66796875\n",
      "Iteration 19, inertia 28008.1796875\n",
      "Iteration 20, inertia 28007.798828125\n",
      "Iteration 21, inertia 28007.419921875\n",
      "Iteration 22, inertia 28006.95703125\n",
      "Iteration 23, inertia 28006.681640625\n",
      "Iteration 24, inertia 28006.291015625\n",
      "Iteration 25, inertia 28005.8984375\n",
      "Iteration 26, inertia 28005.673828125\n",
      "Iteration 27, inertia 28005.478515625\n",
      "Iteration 28, inertia 28005.3984375\n",
      "Iteration 29, inertia 28005.16015625\n",
      "Iteration 30, inertia 28005.0234375\n",
      "Iteration 31, inertia 28004.791015625\n",
      "Iteration 32, inertia 28004.625\n",
      "Iteration 33, inertia 28004.3046875\n",
      "Iteration 34, inertia 28003.666015625\n",
      "Iteration 35, inertia 28002.283203125\n",
      "Iteration 36, inertia 27998.029296875\n",
      "Iteration 37, inertia 27993.23046875\n",
      "Iteration 38, inertia 27991.306640625\n",
      "Iteration 39, inertia 27990.40625\n",
      "Iteration 40, inertia 27989.486328125\n",
      "Iteration 41, inertia 27988.330078125\n",
      "Iteration 42, inertia 27987.626953125\n",
      "Iteration 43, inertia 27986.95703125\n",
      "Iteration 44, inertia 27986.443359375\n",
      "Iteration 45, inertia 27986.123046875\n",
      "Iteration 46, inertia 27985.70703125\n",
      "Iteration 47, inertia 27985.392578125\n",
      "Iteration 48, inertia 27985.2734375\n",
      "Iteration 49, inertia 27985.177734375\n",
      "Iteration 50, inertia 27985.12890625\n",
      "Iteration 51, inertia 27985.009765625\n",
      "Iteration 52, inertia 27984.955078125\n",
      "Iteration 53, inertia 27984.87890625\n",
      "Iteration 54, inertia 27984.83984375\n",
      "Iteration 55, inertia 27984.837890625\n",
      "Iteration 56, inertia 27984.76171875\n",
      "Iteration 57, inertia 27984.75\n",
      "Iteration 58, inertia 27984.748046875\n",
      "Iteration 59, inertia 27984.716796875\n",
      "Iteration 60, inertia 27984.6875\n",
      "Iteration 61, inertia 27984.6875\n",
      "Iteration 62, inertia 27984.669921875\n",
      "Iteration 63, inertia 27984.689453125\n",
      "Iteration 64, inertia 27984.70703125\n",
      "Iteration 65, inertia 27984.705078125\n",
      "Iteration 66, inertia 27984.677734375\n",
      "Iteration 67, inertia 27984.708984375\n",
      "Iteration 68, inertia 27984.677734375\n",
      "Iteration 69, inertia 27984.6796875\n",
      "Iteration 70, inertia 27984.669921875\n",
      "Iteration 71, inertia 27984.66015625\n",
      "Iteration 72, inertia 27984.65625\n",
      "Converged at iteration 72: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46347.93359375\n",
      "Iteration 1, inertia 29170.75\n",
      "Iteration 2, inertia 28550.61328125\n",
      "Iteration 3, inertia 28366.421875\n",
      "Iteration 4, inertia 28263.697265625\n",
      "Iteration 5, inertia 28201.47265625\n",
      "Iteration 6, inertia 28155.068359375\n",
      "Iteration 7, inertia 28119.521484375\n",
      "Iteration 8, inertia 28086.755859375\n",
      "Iteration 9, inertia 28053.048828125\n",
      "Iteration 10, inertia 28035.099609375\n",
      "Iteration 11, inertia 28025.134765625\n",
      "Iteration 12, inertia 28018.125\n",
      "Iteration 13, inertia 28012.919921875\n",
      "Iteration 14, inertia 28008.650390625\n",
      "Iteration 15, inertia 28005.35546875\n",
      "Iteration 16, inertia 28002.392578125\n",
      "Iteration 17, inertia 27999.095703125\n",
      "Iteration 18, inertia 27995.63671875\n",
      "Iteration 19, inertia 27992.658203125\n",
      "Iteration 20, inertia 27990.28515625\n",
      "Iteration 21, inertia 27988.65625\n",
      "Iteration 22, inertia 27987.01171875\n",
      "Iteration 23, inertia 27985.58984375\n",
      "Iteration 24, inertia 27984.33984375\n",
      "Iteration 25, inertia 27983.36328125\n",
      "Iteration 26, inertia 27982.482421875\n",
      "Iteration 27, inertia 27981.78125\n",
      "Iteration 28, inertia 27981.171875\n",
      "Iteration 29, inertia 27980.666015625\n",
      "Iteration 30, inertia 27980.24609375\n",
      "Iteration 31, inertia 27979.595703125\n",
      "Iteration 32, inertia 27978.751953125\n",
      "Iteration 33, inertia 27977.6640625\n",
      "Iteration 34, inertia 27976.251953125\n",
      "Iteration 35, inertia 27974.6328125\n",
      "Iteration 36, inertia 27973.26953125\n",
      "Iteration 37, inertia 27971.09375\n",
      "Iteration 38, inertia 27965.857421875\n",
      "Iteration 39, inertia 27951.931640625\n",
      "Iteration 40, inertia 27940.548828125\n",
      "Iteration 41, inertia 27934.494140625\n",
      "Iteration 42, inertia 27932.3359375\n",
      "Iteration 43, inertia 27931.833984375\n",
      "Iteration 44, inertia 27931.53515625\n",
      "Iteration 45, inertia 27931.24609375\n",
      "Iteration 46, inertia 27931.138671875\n",
      "Iteration 47, inertia 27930.974609375\n",
      "Iteration 48, inertia 27930.892578125\n",
      "Iteration 49, inertia 27930.810546875\n",
      "Iteration 50, inertia 27930.791015625\n",
      "Iteration 51, inertia 27930.724609375\n",
      "Iteration 52, inertia 27930.736328125\n",
      "Iteration 53, inertia 27930.7578125\n",
      "Iteration 54, inertia 27930.72265625\n",
      "Iteration 55, inertia 27930.6796875\n",
      "Iteration 56, inertia 27930.671875\n",
      "Iteration 57, inertia 27930.716796875\n",
      "Iteration 58, inertia 27930.73828125\n",
      "Iteration 59, inertia 27930.724609375\n",
      "Iteration 60, inertia 27930.701171875\n",
      "Iteration 61, inertia 27930.642578125\n",
      "Iteration 62, inertia 27930.611328125\n",
      "Iteration 63, inertia 27930.607421875\n",
      "Iteration 64, inertia 27930.615234375\n",
      "Iteration 65, inertia 27930.58984375\n",
      "Iteration 66, inertia 27930.599609375\n",
      "Iteration 67, inertia 27930.6015625\n",
      "Iteration 68, inertia 27930.591796875\n",
      "Iteration 69, inertia 27930.587890625\n",
      "Iteration 70, inertia 27930.572265625\n",
      "Iteration 71, inertia 27930.546875\n",
      "Iteration 72, inertia 27930.5078125\n",
      "Iteration 73, inertia 27930.50390625\n",
      "Iteration 74, inertia 27930.482421875\n",
      "Iteration 75, inertia 27930.484375\n",
      "Iteration 76, inertia 27930.484375\n",
      "Iteration 77, inertia 27930.482421875\n",
      "Iteration 78, inertia 27930.484375\n",
      "Iteration 79, inertia 27930.501953125\n",
      "Iteration 80, inertia 27930.517578125\n",
      "Iteration 81, inertia 27930.51171875\n",
      "Converged at iteration 81: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 47324.015625\n",
      "Iteration 1, inertia 29281.3203125\n",
      "Iteration 2, inertia 28584.349609375\n",
      "Iteration 3, inertia 28323.537109375\n",
      "Iteration 4, inertia 28193.43359375\n",
      "Iteration 5, inertia 28103.275390625\n",
      "Iteration 6, inertia 28045.34375\n",
      "Iteration 7, inertia 28019.75390625\n",
      "Iteration 8, inertia 28004.841796875\n",
      "Iteration 9, inertia 27992.7421875\n",
      "Iteration 10, inertia 27982.115234375\n",
      "Iteration 11, inertia 27975.9921875\n",
      "Iteration 12, inertia 27972.4921875\n",
      "Iteration 13, inertia 27969.01171875\n",
      "Iteration 14, inertia 27965.57421875\n",
      "Iteration 15, inertia 27963.228515625\n",
      "Iteration 16, inertia 27961.59375\n",
      "Iteration 17, inertia 27960.037109375\n",
      "Iteration 18, inertia 27958.341796875\n",
      "Iteration 19, inertia 27956.07421875\n",
      "Iteration 20, inertia 27953.734375\n",
      "Iteration 21, inertia 27951.20703125\n",
      "Iteration 22, inertia 27948.45703125\n",
      "Iteration 23, inertia 27945.4921875\n",
      "Iteration 24, inertia 27943.197265625\n",
      "Iteration 25, inertia 27941.564453125\n",
      "Iteration 26, inertia 27940.375\n",
      "Iteration 27, inertia 27939.50390625\n",
      "Iteration 28, inertia 27938.943359375\n",
      "Iteration 29, inertia 27938.216796875\n",
      "Iteration 30, inertia 27936.9296875\n",
      "Iteration 31, inertia 27935.328125\n",
      "Iteration 32, inertia 27933.76953125\n",
      "Iteration 33, inertia 27932.484375\n",
      "Iteration 34, inertia 27931.30078125\n",
      "Iteration 35, inertia 27930.333984375\n",
      "Iteration 36, inertia 27929.458984375\n",
      "Iteration 37, inertia 27928.001953125\n",
      "Iteration 38, inertia 27926.646484375\n",
      "Iteration 39, inertia 27925.138671875\n",
      "Iteration 40, inertia 27923.017578125\n",
      "Iteration 41, inertia 27920.58203125\n",
      "Iteration 42, inertia 27918.3671875\n",
      "Iteration 43, inertia 27916.876953125\n",
      "Iteration 44, inertia 27916.130859375\n",
      "Iteration 45, inertia 27915.3984375\n",
      "Iteration 46, inertia 27914.80859375\n",
      "Iteration 47, inertia 27914.126953125\n",
      "Iteration 48, inertia 27913.208984375\n",
      "Iteration 49, inertia 27912.564453125\n",
      "Iteration 50, inertia 27911.587890625\n",
      "Iteration 51, inertia 27910.69921875\n",
      "Iteration 52, inertia 27909.982421875\n",
      "Iteration 53, inertia 27909.376953125\n",
      "Iteration 54, inertia 27908.84375\n",
      "Iteration 55, inertia 27908.3828125\n",
      "Iteration 56, inertia 27908.052734375\n",
      "Iteration 57, inertia 27907.619140625\n",
      "Iteration 58, inertia 27907.35546875\n",
      "Iteration 59, inertia 27907.10546875\n",
      "Iteration 60, inertia 27906.763671875\n",
      "Iteration 61, inertia 27906.521484375\n",
      "Iteration 62, inertia 27906.392578125\n",
      "Iteration 63, inertia 27906.1875\n",
      "Iteration 64, inertia 27906.12109375\n",
      "Iteration 65, inertia 27906.03125\n",
      "Iteration 66, inertia 27905.982421875\n",
      "Iteration 67, inertia 27905.8359375\n",
      "Iteration 68, inertia 27905.654296875\n",
      "Iteration 69, inertia 27905.146484375\n",
      "Iteration 70, inertia 27904.21875\n",
      "Iteration 71, inertia 27902.2734375\n",
      "Iteration 72, inertia 27899.228515625\n",
      "Iteration 73, inertia 27896.5390625\n",
      "Iteration 74, inertia 27894.904296875\n",
      "Iteration 75, inertia 27894.232421875\n",
      "Iteration 76, inertia 27894.048828125\n",
      "Iteration 77, inertia 27893.859375\n",
      "Iteration 78, inertia 27893.763671875\n",
      "Iteration 79, inertia 27893.66015625\n",
      "Iteration 80, inertia 27893.712890625\n",
      "Iteration 81, inertia 27893.771484375\n",
      "Iteration 82, inertia 27893.779296875\n",
      "Iteration 83, inertia 27893.7734375\n",
      "Iteration 84, inertia 27893.775390625\n",
      "Iteration 85, inertia 27893.77734375\n",
      "Iteration 86, inertia 27893.79296875\n",
      "Converged at iteration 86: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46847.27734375\n",
      "Iteration 1, inertia 29292.033203125\n",
      "Iteration 2, inertia 28529.5390625\n",
      "Iteration 3, inertia 28292.001953125\n",
      "Iteration 4, inertia 28200.119140625\n",
      "Iteration 5, inertia 28131.369140625\n",
      "Iteration 6, inertia 28080.673828125\n",
      "Iteration 7, inertia 28045.474609375\n",
      "Iteration 8, inertia 28023.0546875\n",
      "Iteration 9, inertia 28010.0625\n",
      "Iteration 10, inertia 27998.029296875\n",
      "Iteration 11, inertia 27984.18359375\n",
      "Iteration 12, inertia 27966.6171875\n",
      "Iteration 13, inertia 27948.91015625\n",
      "Iteration 14, inertia 27933.9609375\n",
      "Iteration 15, inertia 27922.7109375\n",
      "Iteration 16, inertia 27913.611328125\n",
      "Iteration 17, inertia 27904.962890625\n",
      "Iteration 18, inertia 27899.34765625\n",
      "Iteration 19, inertia 27896.642578125\n",
      "Iteration 20, inertia 27894.73046875\n",
      "Iteration 21, inertia 27892.6953125\n",
      "Iteration 22, inertia 27891.353515625\n",
      "Iteration 23, inertia 27889.96484375\n",
      "Iteration 24, inertia 27888.7265625\n",
      "Iteration 25, inertia 27887.755859375\n",
      "Iteration 26, inertia 27886.984375\n",
      "Iteration 27, inertia 27886.50390625\n",
      "Iteration 28, inertia 27886.0625\n",
      "Iteration 29, inertia 27885.89453125\n",
      "Iteration 30, inertia 27885.5703125\n",
      "Iteration 31, inertia 27885.27734375\n",
      "Iteration 32, inertia 27884.978515625\n",
      "Iteration 33, inertia 27884.927734375\n",
      "Iteration 34, inertia 27884.869140625\n",
      "Iteration 35, inertia 27884.669921875\n",
      "Iteration 36, inertia 27884.505859375\n",
      "Iteration 37, inertia 27884.173828125\n",
      "Iteration 38, inertia 27884.0078125\n",
      "Iteration 39, inertia 27883.509765625\n",
      "Iteration 40, inertia 27883.2734375\n",
      "Iteration 41, inertia 27882.900390625\n",
      "Iteration 42, inertia 27882.23828125\n",
      "Iteration 43, inertia 27881.119140625\n",
      "Iteration 44, inertia 27880.166015625\n",
      "Iteration 45, inertia 27878.96875\n",
      "Iteration 46, inertia 27877.8203125\n",
      "Iteration 47, inertia 27877.02734375\n",
      "Iteration 48, inertia 27876.685546875\n",
      "Iteration 49, inertia 27876.328125\n",
      "Iteration 50, inertia 27876.06640625\n",
      "Iteration 51, inertia 27876.015625\n",
      "Iteration 52, inertia 27875.8125\n",
      "Iteration 53, inertia 27875.734375\n",
      "Iteration 54, inertia 27875.76953125\n",
      "Iteration 55, inertia 27875.75390625\n",
      "Iteration 56, inertia 27875.701171875\n",
      "Iteration 57, inertia 27875.681640625\n",
      "Iteration 58, inertia 27875.65234375\n",
      "Iteration 59, inertia 27875.67578125\n",
      "Iteration 60, inertia 27875.64453125\n",
      "Iteration 61, inertia 27875.66015625\n",
      "Converged at iteration 61: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46787.36328125\n",
      "Iteration 1, inertia 29159.35546875\n",
      "Iteration 2, inertia 28594.98046875\n",
      "Iteration 3, inertia 28373.9375\n",
      "Iteration 4, inertia 28271.33984375\n",
      "Iteration 5, inertia 28215.265625\n",
      "Iteration 6, inertia 28180.638671875\n",
      "Iteration 7, inertia 28161.599609375\n",
      "Iteration 8, inertia 28152.62890625\n",
      "Iteration 9, inertia 28146.576171875\n",
      "Iteration 10, inertia 28140.728515625\n",
      "Iteration 11, inertia 28133.830078125\n",
      "Iteration 12, inertia 28126.69921875\n",
      "Iteration 13, inertia 28120.755859375\n",
      "Iteration 14, inertia 28116.6484375\n",
      "Iteration 15, inertia 28113.224609375\n",
      "Iteration 16, inertia 28108.962890625\n",
      "Iteration 17, inertia 28104.412109375\n",
      "Iteration 18, inertia 28099.09765625\n",
      "Iteration 19, inertia 28092.380859375\n",
      "Iteration 20, inertia 28085.5390625\n",
      "Iteration 21, inertia 28080.998046875\n",
      "Iteration 22, inertia 28078.421875\n",
      "Iteration 23, inertia 28076.42578125\n",
      "Iteration 24, inertia 28075.0\n",
      "Iteration 25, inertia 28073.3359375\n",
      "Iteration 26, inertia 28072.037109375\n",
      "Iteration 27, inertia 28070.75390625\n",
      "Iteration 28, inertia 28069.705078125\n",
      "Iteration 29, inertia 28068.064453125\n",
      "Iteration 30, inertia 28066.841796875\n",
      "Iteration 31, inertia 28065.666015625\n",
      "Iteration 32, inertia 28064.412109375\n",
      "Iteration 33, inertia 28062.76171875\n",
      "Iteration 34, inertia 28060.828125\n",
      "Iteration 35, inertia 28058.318359375\n",
      "Iteration 36, inertia 28056.1953125\n",
      "Iteration 37, inertia 28054.23046875\n",
      "Iteration 38, inertia 28053.154296875\n",
      "Iteration 39, inertia 28052.24609375\n",
      "Iteration 40, inertia 28051.724609375\n",
      "Iteration 41, inertia 28051.578125\n",
      "Iteration 42, inertia 28051.431640625\n",
      "Iteration 43, inertia 28051.248046875\n",
      "Iteration 44, inertia 28051.208984375\n",
      "Iteration 45, inertia 28051.05859375\n",
      "Iteration 46, inertia 28051.01953125\n",
      "Iteration 47, inertia 28050.98828125\n",
      "Iteration 48, inertia 28050.96875\n",
      "Iteration 49, inertia 28050.90234375\n",
      "Iteration 50, inertia 28050.853515625\n",
      "Iteration 51, inertia 28050.861328125\n",
      "Iteration 52, inertia 28050.841796875\n",
      "Iteration 53, inertia 28050.84375\n",
      "Iteration 54, inertia 28050.849609375\n",
      "Iteration 55, inertia 28050.86328125\n",
      "Converged at iteration 55: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 46885.3671875\n",
      "Iteration 1, inertia 29564.087890625\n",
      "Iteration 2, inertia 28811.0703125\n",
      "Iteration 3, inertia 28477.48046875\n",
      "Iteration 4, inertia 28327.578125\n",
      "Iteration 5, inertia 28241.31640625\n",
      "Iteration 6, inertia 28172.66796875\n",
      "Iteration 7, inertia 28121.23046875\n",
      "Iteration 8, inertia 28085.744140625\n",
      "Iteration 9, inertia 28057.9453125\n",
      "Iteration 10, inertia 28036.646484375\n",
      "Iteration 11, inertia 28021.6015625\n",
      "Iteration 12, inertia 28012.197265625\n",
      "Iteration 13, inertia 28003.693359375\n",
      "Iteration 14, inertia 27992.7734375\n",
      "Iteration 15, inertia 27981.544921875\n",
      "Iteration 16, inertia 27974.556640625\n",
      "Iteration 17, inertia 27970.421875\n",
      "Iteration 18, inertia 27966.912109375\n",
      "Iteration 19, inertia 27962.24609375\n",
      "Iteration 20, inertia 27955.57421875\n",
      "Iteration 21, inertia 27949.873046875\n",
      "Iteration 22, inertia 27946.048828125\n",
      "Iteration 23, inertia 27943.650390625\n",
      "Iteration 24, inertia 27942.1171875\n",
      "Iteration 25, inertia 27940.77734375\n",
      "Iteration 26, inertia 27939.814453125\n",
      "Iteration 27, inertia 27939.240234375\n",
      "Iteration 28, inertia 27938.4140625\n",
      "Iteration 29, inertia 27937.99609375\n",
      "Iteration 30, inertia 27937.5546875\n",
      "Iteration 31, inertia 27937.0078125\n",
      "Iteration 32, inertia 27936.1796875\n",
      "Iteration 33, inertia 27935.3359375\n",
      "Iteration 34, inertia 27933.900390625\n",
      "Iteration 35, inertia 27932.650390625\n",
      "Iteration 36, inertia 27931.640625\n",
      "Iteration 37, inertia 27930.92578125\n",
      "Iteration 38, inertia 27930.751953125\n",
      "Iteration 39, inertia 27930.529296875\n",
      "Iteration 40, inertia 27930.515625\n",
      "Iteration 41, inertia 27930.3671875\n",
      "Iteration 42, inertia 27930.208984375\n",
      "Iteration 43, inertia 27930.087890625\n",
      "Iteration 44, inertia 27930.0078125\n",
      "Iteration 45, inertia 27929.96484375\n",
      "Iteration 46, inertia 27929.79296875\n",
      "Iteration 47, inertia 27929.669921875\n",
      "Iteration 48, inertia 27929.703125\n",
      "Iteration 49, inertia 27929.634765625\n",
      "Iteration 50, inertia 27929.564453125\n",
      "Iteration 51, inertia 27929.51953125\n",
      "Iteration 52, inertia 27929.462890625\n",
      "Iteration 53, inertia 27929.435546875\n",
      "Iteration 54, inertia 27929.38671875\n",
      "Iteration 55, inertia 27929.17578125\n",
      "Iteration 56, inertia 27929.244140625\n",
      "Iteration 57, inertia 27928.935546875\n",
      "Iteration 58, inertia 27928.8671875\n",
      "Iteration 59, inertia 27928.84375\n",
      "Iteration 60, inertia 27928.744140625\n",
      "Iteration 61, inertia 27928.681640625\n",
      "Iteration 62, inertia 27928.541015625\n",
      "Iteration 63, inertia 27928.529296875\n",
      "Iteration 64, inertia 27928.3515625\n",
      "Iteration 65, inertia 27928.171875\n",
      "Iteration 66, inertia 27928.19921875\n",
      "Iteration 67, inertia 27928.1484375\n",
      "Iteration 68, inertia 27927.923828125\n",
      "Iteration 69, inertia 27927.8359375\n",
      "Iteration 70, inertia 27927.78515625\n",
      "Iteration 71, inertia 27927.705078125\n",
      "Iteration 72, inertia 27927.69921875\n",
      "Iteration 73, inertia 27927.701171875\n",
      "Iteration 74, inertia 27927.654296875\n",
      "Iteration 75, inertia 27927.669921875\n",
      "Iteration 76, inertia 27927.68359375\n",
      "Iteration 77, inertia 27927.68359375\n",
      "Iteration 78, inertia 27927.68359375\n",
      "Iteration 79, inertia 27927.671875\n",
      "Converged at iteration 79: strict convergence.\n",
      "Initialization complete\n",
      "Iteration 0, inertia 47185.62890625\n",
      "Iteration 1, inertia 29563.509765625\n",
      "Iteration 2, inertia 28779.375\n",
      "Iteration 3, inertia 28479.107421875\n",
      "Iteration 4, inertia 28354.705078125\n",
      "Iteration 5, inertia 28282.833984375\n",
      "Iteration 6, inertia 28240.830078125\n",
      "Iteration 7, inertia 28207.056640625\n",
      "Iteration 8, inertia 28182.482421875\n",
      "Iteration 9, inertia 28165.828125\n",
      "Iteration 10, inertia 28153.642578125\n",
      "Iteration 11, inertia 28145.078125\n",
      "Iteration 12, inertia 28138.646484375\n",
      "Iteration 13, inertia 28132.77734375\n",
      "Iteration 14, inertia 28128.3203125\n",
      "Iteration 15, inertia 28123.6328125\n",
      "Iteration 16, inertia 28116.765625\n",
      "Iteration 17, inertia 28108.46875\n",
      "Iteration 18, inertia 28100.43359375\n",
      "Iteration 19, inertia 28097.10546875\n",
      "Iteration 20, inertia 28094.62109375\n",
      "Iteration 21, inertia 28092.083984375\n",
      "Iteration 22, inertia 28088.0390625\n",
      "Iteration 23, inertia 28078.052734375\n",
      "Iteration 24, inertia 28052.828125\n",
      "Iteration 25, inertia 28026.21875\n",
      "Iteration 26, inertia 28011.34765625\n",
      "Iteration 27, inertia 28005.626953125\n",
      "Iteration 28, inertia 28003.98046875\n",
      "Iteration 29, inertia 28002.794921875\n",
      "Iteration 30, inertia 28002.08984375\n",
      "Iteration 31, inertia 28001.65234375\n",
      "Iteration 32, inertia 28001.263671875\n",
      "Iteration 33, inertia 28000.900390625\n",
      "Iteration 34, inertia 28000.501953125\n",
      "Iteration 35, inertia 28000.21875\n",
      "Iteration 36, inertia 27999.7421875\n",
      "Iteration 37, inertia 27999.142578125\n",
      "Iteration 38, inertia 27998.501953125\n",
      "Iteration 39, inertia 27997.9765625\n",
      "Iteration 40, inertia 27997.34375\n",
      "Iteration 41, inertia 27996.966796875\n",
      "Iteration 42, inertia 27996.45703125\n",
      "Iteration 43, inertia 27996.09375\n",
      "Iteration 44, inertia 27995.69921875\n",
      "Iteration 45, inertia 27995.48828125\n",
      "Iteration 46, inertia 27995.23828125\n",
      "Iteration 47, inertia 27995.0078125\n",
      "Iteration 48, inertia 27994.982421875\n",
      "Iteration 49, inertia 27994.89453125\n",
      "Iteration 50, inertia 27994.740234375\n",
      "Iteration 51, inertia 27994.748046875\n",
      "Iteration 52, inertia 27994.78125\n",
      "Iteration 53, inertia 27994.646484375\n",
      "Iteration 54, inertia 27994.677734375\n",
      "Iteration 55, inertia 27994.642578125\n",
      "Iteration 56, inertia 27994.5703125\n",
      "Iteration 57, inertia 27994.572265625\n",
      "Iteration 58, inertia 27994.5546875\n",
      "Iteration 59, inertia 27994.537109375\n",
      "Iteration 60, inertia 27994.546875\n",
      "Iteration 61, inertia 27994.541015625\n",
      "Iteration 62, inertia 27994.537109375\n",
      "Iteration 63, inertia 27994.53515625\n",
      "Iteration 64, inertia 27994.5234375\n",
      "Iteration 65, inertia 27994.515625\n",
      "Iteration 66, inertia 27994.51953125\n",
      "Iteration 67, inertia 27994.544921875\n",
      "Iteration 68, inertia 27994.53125\n",
      "Iteration 69, inertia 27994.5625\n",
      "Iteration 70, inertia 27994.490234375\n",
      "Iteration 71, inertia 27994.513671875\n",
      "Iteration 72, inertia 27994.453125\n",
      "Iteration 73, inertia 27994.44921875\n",
      "Iteration 74, inertia 27994.4453125\n",
      "Iteration 75, inertia 27994.455078125\n",
      "Iteration 76, inertia 27994.455078125\n",
      "Iteration 77, inertia 27994.451171875\n",
      "Converged at iteration 77: strict convergence.\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=K, random_state=0, n_init=20, max_iter=1000, verbose=1).fit(all_vfeatures)\n",
    "preds = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fd625a-49ec-4ee2-a3a9-be5aed13bf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017822481030528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_acc(all_clu_label, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc7ac05-c81b-4d6d-b9d6-8dded5a49e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./cache/cluster/kmeans-{args.dataset}.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c62d6-a5a2-4de6-94b1-43d8d3cf0c9d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dataset_name in ['make_entity13', 'imagenet', 'make_entity30', 'make_living17']:\n",
    "    print(f'cluster {dataset_name}')\n",
    "    args.dataset_name = dataset_name\n",
    "    dataset = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_val, seed=0)\n",
    "    loader_val = torch.utils.data.DataLoader(dataset, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "    print('dataset size', len(dataset))\n",
    "    \n",
    "    ### inference\n",
    "    amp_autocast = torch.cuda.amp.autocast\n",
    "    all_vfeatures = []\n",
    "    all_clu_label = []\n",
    "    with tqdm(total=len(loader_val)) as pbar:\n",
    "        model.eval()\n",
    "        for idx_batch, batch in enumerate(loader_val):\n",
    "            images, label_voc, label_clu, idx_img = batch\n",
    "            images = images.to(args.device)\n",
    "            with amp_autocast():\n",
    "                with torch.no_grad():\n",
    "                    logits = model.visual.extract_features(images)\n",
    "                    logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                    all_vfeatures.append(logits.cpu().numpy())\n",
    "                    all_clu_label.append(label_clu.numpy())\n",
    "            pbar.update(1)\n",
    "\n",
    "    all_vfeatures = np.concatenate(all_vfeatures)\n",
    "    all_clu_label = np.concatenate(all_clu_label)\n",
    "    \n",
    "    \n",
    "    # K = dataset.num_classes\n",
    "    K = 2000\n",
    "    kmeans = MiniBatchKMeans(n_clusters=K, batch_size=2048, \n",
    "                             random_state=0, n_init=10, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "    preds = kmeans.labels_\n",
    "    print(cluster_acc(all_clu_label, preds))\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=K, random_state=0, n_init=3, max_iter=500, verbose=2).fit(all_vfeatures)\n",
    "    preds = kmeans.labels_\n",
    "    print(cluster_acc(all_clu_label, preds))\n",
    "    np.save(f'./cache/cluster/kmeans-{args.dataset_name}-2k.npy', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7586ee-6282-4a15-8375-bf77fc869308",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(vec_count.topk(k=voc_beta*dataset.num_classes).values.cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381a3c8-f1a3-429f-b4b6-13a312c5edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'acc={(all_pred_voc == all_gt_voc).float().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d205833-451c-4539-b20f-227ed64045d9",
   "metadata": {},
   "source": [
    "upperbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bc5cb-e5af-4528-aabb-a6854c51db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "mask = torch.zeros(classifier.size(0), device=args.device)\n",
    "mapping_classifier = torch.tensor(sorted(set(dataset.labels)), device=args.device)\n",
    "mask = torch.scatter(mask, 0, mapping_classifier, 1)\n",
    "classifier = classifier[mask.bool()]\n",
    "\n",
    "all_pred_voc = []\n",
    "all_gt_voc = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                all_pred_voc.append(prob.argmax(dim=-1).cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "\n",
    "all_pred_voc = torch.gather(mapping_classifier.cpu(), 0, all_pred_voc)\n",
    "\n",
    "print(f'acc={(all_pred_voc == all_gt_voc).float().mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52897615-fcd6-4c26-ac22-b75be99ff3a1",
   "metadata": {},
   "source": [
    "hierarchy accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef9118-91fc-47ad-9de9-a44437a83c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "\n",
    "all_pred_voc = []\n",
    "all_gt_voc = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                all_pred_voc.append(prob.argmax(dim=-1).cpu())\n",
    "                # label_voc = torch.tensor(list(map(lambda x: vocab.mapping_names_idx[x], label_voc)))\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9519a02-6a92-4b2d-b350-05d5f4d83c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_i2gi = vocab.mapping_idx_global_idx\n",
    "isin = lambda x, y: np.array([xx in y for xx in x])\n",
    "all_pred_hier = []\n",
    "for i in range(len(all_gt_voc)):\n",
    "    cond1 = isin(mapping_i2gi[all_gt_voc[i].item()], reduce(lambda x,y: x|y, [parents[p] for p in mapping_i2gi[all_pred_voc[i].item()]])).any()\n",
    "    cond2 = isin(mapping_i2gi[all_pred_voc[i].item()], reduce(lambda x,y: x|y, [parents[p] for p in mapping_i2gi[all_gt_voc[i].item()]])).any()\n",
    "    pred_hier = cond1 | cond2\n",
    "    all_pred_hier.append(pred_hier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b82639-e18e-4da9-a0b7-36f32dfc184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_pred_hier).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a45ccd-0b81-4faa-833d-27d9ee4e4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_pred_voc==all_gt_voc).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d1a80-6c76-41d2-97d3-3863a16490c0",
   "metadata": {},
   "source": [
    "KNN performance investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb43e8-525b-4d08-a46d-96f8c19d655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "# classifier = F.normalize(classifier, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deebbc7-f951-40f6-bbe2-19ea353341c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = classifier@classifier.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ab39c-83e4-4414-9282-85f5db9b1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "topk_ind = similarity.topk(k=K+1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5457c3-7439-43d6-88f0-56949b23ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(map(lambda x: list(map(lambda y: classnames[y], x)), topk_ind.cpu().numpy().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040aa32-b9f8-49d0-b48f-14063c0d670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251c532a-61b0-48f6-a987-22a327fa77bc",
   "metadata": {},
   "source": [
    "similarity inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c86cca-e05e-435f-894c-1052d2f0841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "all_sim_topk = []\n",
    "all_sim_topk_val = []\n",
    "all_gt_label_voc = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_val)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_val):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = logits @ classifier.t()\n",
    "                sim_topk = similarity.topk(k=10)\n",
    "                all_sim_topk.append(sim_topk.indices.cpu())\n",
    "                all_sim_topk_val.append(sim_topk.values.cpu())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_features.append(logits.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_sim_topk = torch.cat(all_sim_topk, dim=0)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_sim_topk_val = torch.cat(all_sim_topk_val, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b28b9-6b27-47d4-a840-1c2dacad56cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea0560-9495-459f-9295-40090979c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./pred_clu-{args.dataset_name}-train-{arch}.npy', pred_clu)\n",
    "# pred_clu = np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090ee39-4248-4c84-95f9-61f6e8baf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_features = all_features.to(args.device)\n",
    "sim = all_features@all_features.t()\n",
    "np.save(f'./knn_ind-{args.dataset_name}-train-{arch}.npy', sim.topk(k=300).indices.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e20167-6022-4ee0-8e95-ddd93dde38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "cluster_acc(pred_clu, all_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee72e71e-2619-4f46-884d-630ce5ca068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "cluster_acc(pred_clu, all_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d59f21-7e3a-4d8d-9d92-564e0b290224",
   "metadata": {},
   "source": [
    "CLIP clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b1f66-2810-4e10-a66f-1e5e8ef58010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_clu = np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bf01e-46bb-4aaa-ae59-260bfc32baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CLIP clustering acc \"\"\"\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_idx_img = []\n",
    "model.eval()\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    for batch in loader_f:\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images)\n",
    "                features = F.normalize(features, dim=-1).float()\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "        all_features.append(features.detach().cpu())\n",
    "        all_labels.append(label_clu)\n",
    "        all_idx_img.append(idx_img)\n",
    "        \n",
    "        pbar.update(1)\n",
    "        \n",
    "all_features = torch.cat(all_features, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "all_idx_img = torch.cat(all_idx_img, dim=0)\n",
    "\n",
    "# cluster_acc(pred_clu, all_labels.numpy())\n",
    "\n",
    "kmeans = KMeans(n_clusters=len(all_labels.unique()), n_init=100, max_iter=1000, random_state=43)\n",
    "pred_clu = kmeans.fit_predict(all_features.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d553326-8716-4ad4-b895-c507c99fb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./pred_clu-{args.dataset_name}-train-clip.npy', pred_clu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f4feb-e99d-4d4c-aa7c-5c4a801f030c",
   "metadata": {},
   "source": [
    "Cluster navigation (depends on clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de786f98-6bb8-4643-b070-de7187cd46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" topk prediction from CLIP \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_labels = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0cdc6a-707c-45cf-8bda-d76f80bed2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "### per predicted-cluster voting\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "\n",
    "pred_kmeans_t = pred_kmeans\n",
    "# for it in range(10):\n",
    "#     print(f'iteration {it}')\n",
    "\n",
    "# cluster agg\n",
    "all_clu_pred = []\n",
    "for i in range(len(all_gt_voc.unique())):\n",
    "    selected = (pred_kmeans==i)\n",
    "    clu_pred = F.normalize(all_topk_voc[selected].sum(dim=0), dim=-1, p=1)\n",
    "    all_clu_pred.append(clu_pred)\n",
    "all_clu_pred = torch.stack(all_clu_pred, dim=0)\n",
    "\n",
    "# linear assignment\n",
    "print('is mutex assignment::', all_clu_pred.argmax(dim=-1).size(0)==all_clu_pred.argmax(dim=-1).unique().size(0))\n",
    "print('assignment collision num::', len(list(filter(lambda x: x>1, Counter(all_clu_pred.argmax(dim=-1).numpy()).values()))))\n",
    "\n",
    "cost_mat = all_clu_pred.cpu().numpy()\n",
    "res_ass = linear_assignment(cost_mat.max() - cost_mat)\n",
    "label_kmeans_voc = torch.tensor([res_ass[1][x.item()] for x in pred_kmeans])\n",
    "\n",
    "print('instance label acc::', (label_kmeans_voc==all_gt_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4979ece-f872-406c-ad93-72b2970f0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_labels = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f56c2b-1baf-434d-a4fe-7a35fc495272",
   "metadata": {},
   "outputs": [],
   "source": [
    "### subset vocab\n",
    "col_subset = all_clu_pred.nonzero()[:, 1]\n",
    "col_subset = col_subset.unique().sort().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bf5fc-fcbb-49df-a2c0-a6155255e9c3",
   "metadata": {},
   "source": [
    "KNN investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52721295-8e5c-4baf-9e70-0434168d1867",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "neighborhood_size = np.arange(5, 500, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    topk_res = similarity.topk(k=K+1)\n",
    "    topk_ind = topk_res.indices[:, 1:]\n",
    "    topk_match = torch.gather(label_match, 1, topk_ind)\n",
    "    topk_acc = topk_match.float().mean(dim=-1).mean()\n",
    "    print(f'K={K} acc={topk_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45519d41-07c4-44e5-b649-5b170e3e1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_util_package.graph import compute_consensus_on_features\n",
    "neighborhood_size = np.arange(5, 50, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    _, _, pred_affinity = compute_consensus_on_features(all_features, k=K+1, q=0.8)\n",
    "    acc = ((pred_affinity & label_match).float().sum(1)/(pred_affinity.float().sum(1)+1e-10)).mean()\n",
    "    n_nn = pred_affinity.float().sum(1).mean()\n",
    "    print(f'K={K} acc={acc} n_nn={n_nn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970ede6-7bd9-408d-a903-30200acf6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_size = np.arange(5, 50, 5)\n",
    "similarity = all_features@all_features.T\n",
    "label_match = all_labels.view(-1, 1)==all_labels.view(1, -1)\n",
    "for K in neighborhood_size:\n",
    "    _, _, pred_affinity = compute_consensus_on_features(all_features, k=K+1, q=0.5)\n",
    "    acc = ((pred_affinity & label_match).float().sum(1)/(pred_affinity.float().sum(1)+1e-10)).mean()\n",
    "    n_nn = pred_affinity.float().sum(1).mean()\n",
    "    print(f'K={K} acc={acc} n_nn={n_nn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a399a6e-531d-41bd-b16e-c8b0b40f9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" KNN matrix output \"\"\"\n",
    "neighborhood_size = 315\n",
    "similarity = all_features@all_features.T\n",
    "label_match = (all_labels.view(-1, 1)==all_labels.view(1, -1))\n",
    "K = neighborhood_size\n",
    "topk_res = similarity.topk(k=K+1)\n",
    "topk_ind = topk_res.indices\n",
    "\n",
    "torch.save(topk_ind, f'./cache/{args.dataset_name}-clip-knn-{neighborhood_size}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eeb7ed-a204-471f-bdf1-4472658c6669",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_normalize = lambda x: x/x[:, 0].view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc8f4d-0f9e-4300-a049-7d9da7a6b6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 3\n",
    "weight_normalize(instance_weight)[(instance_pred[:, 0]==all_gt_voc)][:, idx].mean(), \\\n",
    "weight_normalize(instance_weight)[(instance_pred[:, idx]==all_gt_voc)][:, idx].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ed802-7bfe-4264-b0a6-3e2568fdfc09",
   "metadata": {},
   "source": [
    "spatial features reweighting and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6086c-c4f7-40aa-adf7-8456702d768c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" visual reranking computation based on spatial features \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "instance_topk_voclabel_by_scd = all_clu_pred.topk(k=5).indices.index_select(0, record_pred_kmeans_t)\n",
    "all_spatial_label_pred = []\n",
    "all_label_voc = []\n",
    "all_label_match_rerank = []\n",
    "all_label_pred = []\n",
    "all_rerank_pred_voc = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                spatial_similarity = model.logit_scale.exp() * (features @ classifier[instance_topk_voclabel_by_scd[idx_img]].permute(0,2,1))\n",
    "                spatial_label_pred = spatial_similarity[:, 1:, :].topk(k=10, dim=1).values.mean(dim=1).argmax(dim=-1)\n",
    "                all_spatial_label_pred.append(spatial_label_pred.cpu())\n",
    "                all_label_voc.append(label_voc)\n",
    "                \n",
    "                ### global-spatial reranking\n",
    "                # global_label_attn = spatial_similarity[:, 0, :].softmax(dim=-1)\n",
    "                # global_spatial_mixed_sim_after_scaling = (spatial_similarity[:, 0, :].unsqueeze(1)*spatial_similarity[:, 1:, :])/100\n",
    "                # topk_spatial_sim_ind = spatial_similarity[:, 1:, :].topk(k=10, dim=1).indices\n",
    "                # spatial_label_attn = torch.gather(global_spatial_mixed_sim_after_scaling , 1, topk_spatial_sim_ind ).mean(dim=1).softmax(dim=-1)\n",
    "                # ind_increment = torch.arange(idx_img.size(0), device=args.device)\n",
    "                # global_spatial_mixed_sim_argmax = (global_label_attn.pow(0.75)*spatial_label_attn.pow(0.25)).argmax(dim=-1)\n",
    "                # GSRerank_pred_voc = instance_topk_voclabel_by_scd[idx_img][ind_increment, global_spatial_mixed_sim_argmax]\n",
    "                # label_match_rerank = GSRerank_pred_voc==label_voc\n",
    "                ### global-attention based spatial voting\n",
    "                global_spatial_attn = features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1)\n",
    "                topk_spatial_ind = global_spatial_attn.topk(k=10).indices\n",
    "                topk_spatial_features = torch.gather(features[:, 1:, :], 1, topk_spatial_ind)\n",
    "                sim_topk_spatial_features = \\\n",
    "                    model.logit_scale.exp() * (topk_spatial_features @ classifier.unsqueeze(0).permute(0,2,1))\n",
    "                \n",
    "                \n",
    "            all_label_match_rerank.append(label_match_rerank.cpu())\n",
    "            all_label_pred.append(global_label_attn.argmax(dim=-1).cpu())\n",
    "            all_rerank_pred_voc.append(GSRerank_pred_voc.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_spatial_label_pred = torch.cat(all_spatial_label_pred, dim=0)\n",
    "all_label_voc = torch.cat(all_label_voc, dim=0)\n",
    "all_label_match_rerank = torch.cat(all_label_match_rerank, dim=0)\n",
    "all_label_pred = torch.cat(all_label_pred, dim=0)\n",
    "all_rerank_pred_voc = torch.cat(all_rerank_pred_voc, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684b3fc-7acd-4294-9af4-b081250a0fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'GSReranked instance Acc:: all_label_match_rerank={all_label_match_rerank.float().mean()}')\n",
    "print(f'SCD:: instance_topk_voclabel_by_scd={(instance_topk_voclabel_by_scd[:, 0]==all_label_voc).float().mean()}')\n",
    "print(f'GSR missing label:: N={len(set(all_gt_voc.unique().cpu().numpy()) - set(all_rerank_pred_voc.unique().cpu().numpy()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f391e4-e326-41dd-9134-a2699e2eba6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" visual spatial features \n",
    "- KNN difference between CLS and tokens\n",
    "\"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "instance_topk_voclabel_by_scd = all_clu_pred.topk(k=5).indices.index_select(0, record_pred_kmeans_t)\n",
    "\n",
    "method = ['cls-spatial-voting', \n",
    "          'cls-spatial-classifier-similarity-inspect',\n",
    "          'cls'][1]\n",
    "all_global_spatial_features = []\n",
    "all_labels_voc_gt = []\n",
    "all_scdknn_classifier_features = []\n",
    "all_entire_spatial_voting = []\n",
    "all_all_voting_voc_ind = []\n",
    "all_pred_voc_label = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                if method == 'cls-spatial-voting':\n",
    "                    # scdknn_classifier_features = classifier[instance_topk_voclabel_by_scd[idx_img]]\n",
    "                    cls_spatial_sim = (features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1))\n",
    "                    cls_knn_token = cls_spatial_sim.topk(k=10).indices\n",
    "                    token_similarity = model.logit_scale.exp() * (features @ classifier.unsqueeze(0).permute(0,2,1))\n",
    "                    knn_token = token_similarity.topk(k=5).indices\n",
    "                    voting_voc_ind = torch.gather(knn_token, 1, cls_knn_token.permute(0,2,1).repeat(1,1,5)).flatten(1)\n",
    "                    all_voting_voc_ind = []\n",
    "                    for i in range(voting_voc_ind.size(0)):\n",
    "                        val, ind = voting_voc_ind[i].unique(return_counts=True)\n",
    "                        all_voting_voc_ind.append(val[ind.topk(k=5).indices].cpu())\n",
    "                    all_voting_voc_ind = torch.stack(all_voting_voc_ind, dim=0)\n",
    "                    all_all_voting_voc_ind.append(all_voting_voc_ind)\n",
    "                elif method == 'cls-spatial-classifier-similarity-inspect': ### corrected, consider projection head\n",
    "                    n_similar_token = 20\n",
    "                    n_vote = 5\n",
    "                    token_similarity = model.logit_scale.exp() * (features @ classifier.unsqueeze(0).permute(0,2,1)) ### B x L+1 x V\n",
    "                    knn_token = token_similarity.topk(k=n_vote).indices ### B x L+1 x n_vote\n",
    "                    cls_spatial_sim = (features[:, 0, :].unsqueeze(1) @ features[:, 1:, :].permute(0,2,1))\n",
    "                    cls_knn_token = cls_spatial_sim.topk(k=n_similar_token).indices + 1 ### B x 1 x n_similar_token\n",
    "                    # knn_token.gather(1, cls_knn_token)\n",
    "                    all_voting_voc_ind = []\n",
    "                    for i in range(idx_img.size(0)):\n",
    "                        val, count = knn_token[i, cls_knn_token[i, 0, :], :].flatten().unique(return_counts=True) ### n_similar_token x n_vote\n",
    "                        all_voting_voc_ind.append(val[count.topk(k=n_vote).indices].cpu())\n",
    "                    all_voting_voc_ind = torch.stack(all_voting_voc_ind, dim=0)\n",
    "                    all_all_voting_voc_ind.append(all_voting_voc_ind)\n",
    "                    \n",
    "                    all_pred_voc_label.append((features[:, 0, :]@classifier.t()).argmax(dim=-1).cpu())\n",
    "                    \n",
    "                elif method == 'cls':\n",
    "                    similarity = features[:, 0, :]@classifier.t()\n",
    "                    all_pred_voc_label.append(similarity.argmax(dim=-1).cpu())\n",
    "                # entire_spatial_voting = (features[:, 0:, :] @ classifier.unsqueeze(0).permute(0,2,1)).topk(k=5).indices\n",
    "                # torch.scatter_add(p, 1, entire_spatial_voting.flatten(1), torch.ones_like(entire_spatial_voting.flatten(1)).float()).argmax(dim=-1)\n",
    "#             all_global_spatial_features.append(features.cpu())\n",
    "            all_labels_voc_gt.append(label_voc)\n",
    "#             all_scdknn_classifier_features.append(scdknn_classifier_features.cpu().numpy())\n",
    "#             # all_entire_spatial_voting.append(entire_spatial_voting.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "# all_global_spatial_features = torch.cat(all_global_spatial_features, dim=0)\n",
    "all_labels_voc_gt = torch.cat(all_labels_voc_gt, dim=0)\n",
    "# all_scdknn_classifier_features = np.concatenate(all_scdknn_classifier_features)\n",
    "# # all_entire_spatial_voting = torch.cat(all_entire_spatial_voting, dim=0)\n",
    "all_all_voting_voc_ind = torch.cat(all_all_voting_voc_ind, dim=0)\n",
    "all_pred_voc_label = torch.cat(all_pred_voc_label, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e331be-480d-4c28-b77c-11acc0524cc0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" offline clustering for visual spatial features \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "cluster_kmeans = {}\n",
    "cluster_spectral = {}\n",
    "n_clusters = 10\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed')\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images, return_spatial=True)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "        batch_size = features.size(0)\n",
    "        for i in range(batch_size):\n",
    "            self_sim = features[i]@features[i].t()\n",
    "            pred_spectral = spectral.fit_predict(self_sim.cpu().numpy())\n",
    "            pred_kmeans = kmeans.fit_predict(features[i].cpu().numpy())\n",
    "        cluster_kmeans[idx_img[i]] = pred_kmeans\n",
    "        cluster_spectral[idx_img[i]] = pred_spectral\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780607e-52bb-43cc-88e4-91f1bccdbb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870300b9-1da8-432a-a39c-a61999920035",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" clustering performance comparison \"\"\"\n",
    "n_clusters = 10\n",
    "idx = np.random.randint(low=0, high=510, size=1)\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', n_init=30)\n",
    "begin = time.time()\n",
    "pred_spectral = spectral.fit_predict(self_sim[idx].cpu().numpy())\n",
    "end = time.time()\n",
    "print(f'time={end-begin}')\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "begin = time.time()\n",
    "pred_kmeans = kmeans.fit_predict(features[idx].cpu().numpy())\n",
    "end = time.time()\n",
    "print(f'time={end-begin}')\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=0)\n",
    "tsne_features_tr = tsne.fit_transform(features[idx].cpu().numpy())\n",
    "\n",
    "plt.figure(dpi=64)\n",
    "plt.scatter(x=tsne_features_tr[:, 0], y=tsne_features_tr[:, 1], c=pred_spectral, s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=tsne_features_tr[pred_spectral==pred_spectral[0], 0], y=tsne_features_tr[pred_spectral==pred_spectral[0], 1], c='r', s=5) ### CLS\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=64)\n",
    "plt.scatter(x=tsne_features_tr[:, 0], y=tsne_features_tr[:, 1], c=pred_kmeans, s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=tsne_features_tr[pred_kmeans==pred_kmeans[0], 0], y=tsne_features_tr[pred_kmeans==pred_kmeans[0], 1], c='r', s=5) ### CLS\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eec163-3209-4dc2-8877-9a046f9f54e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self_sim.mean(dim=[1,2]).mean(), self_sim.std(dim=[1,2]).mean(), self_sim_classifier.mean(dim=[0,1]), self_sim_classifier.std(dim=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257ce01-470a-4fca-ad9d-575e2933d6af",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = torch.zeros([512, classifier.size(0)], device=args.device)\n",
    "torch.scatter_add(p, 1, entire_spatial_voting.flatten(1), torch.ones_like(entire_spatial_voting.flatten(1)).float()).argmax(dim=-1), entire_spatial_voting.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10308782-81f6-4b32-ab51-6866c79676e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### dimensionality reduction with TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "np.random.seed(2)\n",
    "idx = np.random.randint(low=0, high=len(all_global_spatial_features), size=[1])[0]\n",
    "image_features = all_global_spatial_features[idx]\n",
    "knn_classifier_features = torch.from_numpy(all_scdknn_classifier_features[idx])\n",
    "Nimg = image_features.size(0)\n",
    "tsne_features_input = torch.cat([image_features, knn_classifier_features], dim=0)\n",
    "tsne = TSNE(n_components=2, verbose=2)\n",
    "tsne_features_tr = tsne.fit_transform(tsne_features_input.numpy())\n",
    "image_features_tr = tsne_features_tr[:Nimg]\n",
    "knn_classifier_features_tr = tsne_features_tr[Nimg:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacb99d0-1961-450a-b23d-9d01776d773c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=image_features_tr[1:, 0], y=image_features_tr[1:, 1], c='g', s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=image_features_tr[0, 0], y=image_features_tr[0, 1], c='r', s=5) ### CLS\n",
    "plt.scatter(x=knn_classifier_features_tr[:, 0], y=knn_classifier_features_tr[:, 1], c='b', s=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e0118-2026-4af4-865a-797ab80e1dd7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx = np.random.randint(low=0, high=len(all_global_spatial_features), size=[1])[0]\n",
    "image_features = all_global_spatial_features[idx]\n",
    "knn_classifier_features = torch.from_numpy(all_scdknn_classifier_features[idx])\n",
    "\n",
    "Nimg = image_features.size(0)\n",
    "N2 = knn_classifier_features.size(0)\n",
    "all_knn_classifier_features = classifier[(image_features.to(args.device) @ classifier.t()).topk(k=5).indices.flatten().unique()].cpu()\n",
    "tsne_features_input = torch.cat([image_features, knn_classifier_features, all_knn_classifier_features], dim=0)\n",
    "tsne = TSNE(n_components=2, verbose=2)\n",
    "tsne_features_tr = tsne.fit_transform(tsne_features_input.numpy())\n",
    "image_features_tr = tsne_features_tr[:Nimg]\n",
    "knn_classifier_features_tr = tsne_features_tr[Nimg:Nimg+N2]\n",
    "all_knn_classifier_features_tr = tsne_features_tr[Nimg+N2:]\n",
    "\n",
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=image_features_tr[1:, 0], y=image_features_tr[1:, 1], c='g', s=5, alpha=0.6) ### SPATIAL\n",
    "plt.scatter(x=image_features_tr[0, 0], y=image_features_tr[0, 1], c='r', s=5) ### CLS\n",
    "plt.scatter(x=all_knn_classifier_features_tr[:, 0], y=all_knn_classifier_features_tr[:, 1], c='y', s=5) ### spatial KNN\n",
    "plt.scatter(x=knn_classifier_features_tr[:, 0], y=knn_classifier_features_tr[:, 1], c='b', s=5) ### cluster KNN\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b5ba19-3fd9-4329-86aa-8b38eaab0c49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_knn, spatial_knn_counts = (image_features.to(args.device) @ classifier.t()).topk(k=5).indices[:, 0].unique(return_counts=True)\n",
    "(spatial_knn==all_labels_voc_gt[idx]).nonzero(), spatial_knn_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f2346-76ba-4b23-9ad5-75e81ff32394",
   "metadata": {},
   "source": [
    "SCD with shrinked vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e6634-c549-416e-89ff-34041414068b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" SCD with shrinked vocab \"\"\"\n",
    "classifier_selected = None\n",
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier[classifier_selected].t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                ### mapping @selected to vocab ind\n",
    "                B, C = prob_topk_ind.shape\n",
    "                prob_topk_ind = classifier_selected[prob_topk_ind.view(-1)].view(B, C)\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# pred_kmeans = torch.from_numpy(np.load(f'/home/sheng/OSZSL/ipynb/pred_clu-{args.dataset_name}-train-vit_dino-dino_stage1.npy'))\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "for t in range(3):\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d409fc-0177-4e54-b270-7f7d0f452870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_all_clu_pred = all_clu_pred\n",
    "# len(set_gt - set(final_all_clu_pred.topk(k=2).indices.flatten().unique().numpy().tolist()))\n",
    "\n",
    "# len(set_gt - set(all_clu_pred.topk(k=3).indices.flatten().unique().numpy().tolist()))\n",
    "\n",
    "# select_correct = (cluster_ind_voc.cpu()==all_gt_voc)\n",
    "\n",
    "# all_topk_val = torch.from_numpy(all_topk_val)#[select_correct]\n",
    "# prob_all_topk_val = torch.cat([all_topk_val, 1-all_topk_val.sum(dim=-1, keepdim=True)], dim=-1)\n",
    "\n",
    "# ent = - (prob_all_topk_val * (prob_all_topk_val+1e-30).log()).sum(dim=-1)\n",
    "\n",
    "# # import seaborn as sns\n",
    "# # sns.distplot(prob_all_topk_val[select_correct, 0], bins=100)\n",
    "# # sns.distplot(prob_all_topk_val[~select_correct, 0], bins=100)\n",
    "# # sns.scatterplot(x=prob_all_topk_val[:, 0], y=select_correct.float(), s=3, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9395f6-9497-4a0c-90aa-e85c2f26e81d",
   "metadata": {},
   "source": [
    "collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfb1e2-f2da-4787-b872-d08922d43bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "all_topk_val = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                topk_res = prob.topk(k=prob_k, dim=-1)\n",
    "                prob_topk_ind = topk_res.indices\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_topk_val.append(topk_res.values.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "all_topk_val = np.concatenate(all_topk_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc17b14-894c-4cab-bf09-1cd6e4636a09",
   "metadata": {},
   "source": [
    "confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc944ec3-21e1-4577-a721-d969514552e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# classifier = get_classifier(args)\n",
    "# classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "# args.num_voc = classifier.size(0)\n",
    "# amp_autocast = torch.cuda.amp.autocast\n",
    "# ### collect variables\n",
    "# prob_k = 5\n",
    "# all_topk_voc = []\n",
    "# all_gt_voc = []\n",
    "# all_label_clu = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = 100 * logits @ classifier.t()\n",
    "#                 prob = similarity.softmax(-1)\n",
    "#                 prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "#                 all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "#                 all_gt_voc.append(label_voc)\n",
    "#                 all_label_clu.append(label_clu)\n",
    "#         pbar.update(1)\n",
    "\n",
    "# all_topk_voc = np.concatenate(all_topk_voc)\n",
    "# all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "# all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "use_confidence = True\n",
    "th_confidence = 0.5\n",
    "pred_kmeans = torch.from_numpy(np.load(f'/home/sheng/OSZSL/ipynb/pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "\n",
    "if use_confidence:\n",
    "    # ### SSL feature extraction\n",
    "    # ssl_prototypes = torch.zeros([pred_kmeans.unique().size(0), 768], device=args.device, dtype=torch.float64) ### C x D\n",
    "    # ssl_counter = torch.zeros(pred_kmeans.unique().size(0))\n",
    "    # with tqdm(total=len(loader_f)) as pbar:\n",
    "    #     modelf.eval()\n",
    "    #     modelf.to(args.device)\n",
    "    #     for idx_batch, batch in enumerate(loader_f):\n",
    "    #         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "    #         images = images.to(args.device)\n",
    "    #         with torch.no_grad():\n",
    "    #             features = modelf(images.float())\n",
    "    #             features = F.normalize(features, dim=-1)\n",
    "    #             for p in range(idx_img.size(0)):\n",
    "    #                 ssl_prototypes[pred_kmeans[p].long()] += features.to(torch.float64)[p]\n",
    "    #             # ssl_prototypes = torch.scatter_add(ssl_prototypes, 0, pred_kmeans[idx_img.long()].to(args.device).long(), features.to(torch.float64))\n",
    "    #             counter_voc_ind, counter_val = pred_kmeans[idx_img].unique(return_counts=True)\n",
    "    #             ssl_counter[counter_voc_ind.long()] += counter_val\n",
    "    #         pbar.update(1)\n",
    "    # ssl_prototypes = ssl_prototypes/ssl_counter.to(args.device).unsqueeze(-1)\n",
    "    # ssl_prototypes = F.normalize(ssl_prototypes, dim=-1)\n",
    "    # ### select confident instances\n",
    "    # all_prob = []\n",
    "    # all_sim = []\n",
    "    # with tqdm(total=len(loader_f)) as pbar:\n",
    "    #     modelf.eval()\n",
    "    #     modelf.to(args.device)\n",
    "    #     for idx_batch, batch in enumerate(loader_f):\n",
    "    #         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "    #         images = images.to(args.device)\n",
    "    #         with torch.no_grad():\n",
    "    #             features = modelf(images)\n",
    "    #             features = F.normalize(features, dim=-1)\n",
    "    #             sim = features@ssl_prototypes.float().t()\n",
    "    #             prob = (sim/1.0).amax(dim=-1)\n",
    "    #             all_prob.append(prob.cpu())\n",
    "    #             all_sim.append(sim.cpu())\n",
    "    #         pbar.update(1)\n",
    "    # all_prob = torch.cat(all_prob, dim=0)\n",
    "    # all_sim = torch.cat(all_sim, dim=0)\n",
    "    ### confidence thresholding\n",
    "    q = np.quantile(all_prob.numpy(), q=0.5)\n",
    "    selected = (all_prob>q)\n",
    "    ### computing\n",
    "    pred_kmeans_t = pred_kmeans[selected]\n",
    "    for t in range(3):\n",
    "        all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc[selected], voc_size=args.num_voc)\n",
    "        label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc[selected])\n",
    "        pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, \n",
    "                                                                  all_prob=None, instance_selected=selected)\n",
    "        set_pred = set(res_ass[1].tolist())\n",
    "        set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "        print('missing label::', len(set_gt - set_pred))\n",
    "        print('cluster acc', cluster_acc(y_true=all_label_clu[selected].numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "else:\n",
    "    pred_kmeans_t = pred_kmeans\n",
    "    for t in range(3):\n",
    "        all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "        label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "        pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "        set_pred = set(res_ass[1].tolist())\n",
    "        set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "        print('missing label::', len(set_gt - set_pred))\n",
    "        print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9cac48-7b09-47ac-b5f6-d67a19966a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" inspect cluster topk assigned classes \"\"\"\n",
    "# topk_cluster_label = all_clu_pred.topk(k=5).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40ee62-0996-46bf-8e3b-40d9b0fc1997",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # pred_kmeans_t = pred_kmeans\n",
    "# # for t in range(5):\n",
    "# #     all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t, all_topk_voc)\n",
    "# #     label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "# #     pred_kmeans_t = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args, all_prob=None)\n",
    "# #     set_pred = set(res_ass[1].tolist())\n",
    "# #     set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "# #     print('missing label::', len(set_gt - set_pred))\n",
    "# #     print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "\n",
    "\n",
    "# \"\"\" get confident prediction \"\"\"\n",
    "# th = 0.5\n",
    "# amp_autocast = torch.cuda.amp.autocast\n",
    "# label_voc_kmeans_t = label_voc_kmeans_t.to(args.device)\n",
    "# cluster_ind = []\n",
    "# selected_ind = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = 100 * logits @ classifier.t()\n",
    "#                 prob = similarity[:, label_voc_kmeans_t].softmax(dim=-1)\n",
    "#                 selected = (prob.amax(dim=-1)>th)\n",
    "#                 selected_ind.append(selected.cpu())\n",
    "#         pbar.update(1)\n",
    "# selected_ind = torch.cat(selected_ind, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "# # precision = cluster_acc(y_true=all_label_clu[selected_ind].numpy(), y_pred=pred_kmeans_t[selected_ind].numpy())\n",
    "# # recall = selected_ind.mean()\n",
    "# print(f'confidence selection precision={precision} recall={recall}')\n",
    "\n",
    "# # np.save(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy', pred_kmeans_t.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688f3cb-d754-4c42-bf39-242029dbd35c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# 1. inverse entropy of prototype\n",
    "\n",
    "# 2. top1 sim of proto-image\n",
    "\n",
    "# 3. top1 sim of image-proto\n",
    "\n",
    "# \"\"\"\n",
    "# # candidate_ind = res_ass[1].unique()\n",
    "# # cls_proto_similarity = torch.zeros([len(dataset_f), candidate_ind.size()])\n",
    "# all_sim_proto_image_pred = []\n",
    "# all_sim_proto_image_gt = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch\n",
    "#         images = images.to(args.device)\n",
    "#         label_voc = label_voc.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "#                 similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "#                 prob = similarity.softmax(dim=-1)\n",
    "#                 all_sim_proto_image_pred.append(similarity[:, prob.argmax(dim=-1)].cpu())\n",
    "#                 all_sim_proto_image_gt.append(similarity[:, label_voc].cpu())\n",
    "#         pbar.update(1)\n",
    "        \n",
    "# all_sim_proto_image_pred = torch.cat(all_sim_proto_image_pred, dim=0)\n",
    "# all_sim_proto_image_gt = torch.cat(all_sim_proto_image_gt, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05625353-4773-4ed7-951c-d8974dfb3b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_sim_proto_image_pred = torch.cat(all_sim_proto_image_pred, dim=0)\n",
    "# all_sim_proto_image_gt = torch.cat(all_sim_proto_image_gt, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "# label_match = all_label_clu.view(-1, 1)@all_label_clu.view(1, -1)\n",
    "# pred_match_init = pred_kmeans.view(-1, 1)@pred_kmeans.view(1, -1)\n",
    "# pred_match = pred_kmeans_t.view(-1, 1)@pred_kmeans_t.view(1, -1)\n",
    "\n",
    "# pred_consensus = (pred_match_init==pred_match) \n",
    "# ((pred_consensus & label_match).float().sum(dim=-1) / (pred_consensus.sum(dim=-1)+1e-20)).mean()\n",
    "\n",
    "# (pred_consensus & label_match).float().sum(dim=-1).bool().float().mean()\n",
    "\n",
    "# all_clu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d94cc9-d78b-4cc7-b347-e73d7fc03602",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_topk_voc.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "\n",
    "all_topk_voc = np.concatenate(all_topk_voc)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# ### MCMF\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "class_topk_assignment = MCMF_assign_labels(all_clu_pred.cpu().numpy(), K=2)\n",
    "\n",
    "# ### collect variables\n",
    "# prob_k = 5\n",
    "# all_mcmf_rerank_pred = []\n",
    "# all_gt_voc = []\n",
    "# all_label_clu = []\n",
    "# with tqdm(total=len(loader_f)) as pbar:\n",
    "#     if hasattr(model, 'eval'):\n",
    "#         model.eval()\n",
    "#     for idx_batch, batch in enumerate(loader_f):\n",
    "#         images, label_voc, label_clu, idx_img = batch[:4]\n",
    "#         images = images.to(args.device)\n",
    "#         with amp_autocast():\n",
    "#             with torch.no_grad():\n",
    "#                 logits = model.visual(images)\n",
    "#                 logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "#                 valid_classifier_ind = class_topk_assignment[pred_kmeans[idx_img].long()].to(args.device)\n",
    "#                 bb, kk = valid_classifier_ind.size()\n",
    "#                 valid_classifier = classifier[valid_classifier_ind.flatten()].view(bb, kk, -1).permute(0,2,1)\n",
    "                \n",
    "#                 similarity = 100 * logits.unsqueeze(1) @ valid_classifier\n",
    "#                 prob = similarity.softmax(-1)\n",
    "                \n",
    "#                 all_mcmf_rerank_pred.append(valid_classifier_ind[prob.argmax(dim=-1)].cpu().numpy())\n",
    "#                 all_gt_voc.append(label_voc)\n",
    "#                 all_label_clu.append(label_clu)\n",
    "#         pbar.update(1)\n",
    "\n",
    "# all_mcmf_rerank_pred = np.concatenate(all_mcmf_rerank_pred)\n",
    "# all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "# all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "        \n",
    "# instance_assignment_pred = torch.zeros(all_mcmf_rerank_pred.shape[0])\n",
    "# for c in pred_kmeans.unique():\n",
    "#     select = (pred_kmeans==c)\n",
    "#     unique_ind, unique_count = torch.from_numpy(all_mcmf_rerank_pred[select]).unique(return_counts=True)\n",
    "#     instance_assignment_pred[select] = unique_ind[unique_count.argsort()[-1]].item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb5d88-4184-408c-9363-ac2e0d74144f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### class-wise assignment to instance prediction\n",
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0), class_topk_assignment.size(1)).to(class_topk_assignment.device).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = class_topk_assignment[c].view(-1, class_topk_assignment.size(1))\n",
    "\n",
    "all_mcmf_instance_pred = []\n",
    "all_gt_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                valid_classifier_ind = instance_assignment_pred[idx_img].long().to(args.device)\n",
    "                bb, kk = valid_classifier_ind.size()\n",
    "                valid_classifier = classifier[valid_classifier_ind.flatten()].view(bb, kk, -1).permute(0,2,1)\n",
    "                \n",
    "                similarity = 100 * logits.unsqueeze(1) @ valid_classifier\n",
    "                prob = similarity.softmax(-1)\n",
    "                \n",
    "                all_mcmf_instance_pred.append(valid_classifier_ind[torch.arange(valid_classifier_ind.size(0)), \n",
    "                                                                   prob.argmax(dim=-1).squeeze(-1)].cpu().numpy())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "    \n",
    "all_mcmf_instance_pred = np.concatenate(all_mcmf_instance_pred)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "# pred_kmeans_t = pred_kmeans\n",
    "\n",
    "# history_set_pred = []\n",
    "# for t in range(3):\n",
    "#     record_pred_kmeans_t = pred_kmeans_t\n",
    "#     all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_topk_voc, voc_size=args.num_voc)\n",
    "#     label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_voc)\n",
    "#     pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "#     set_pred = set(res_ass[1].tolist())\n",
    "#     set_gt = set(all_gt_voc.unique().numpy().tolist())\n",
    "#     print('missing label::', len(set_gt - set_pred))\n",
    "#     print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "#     history_set_pred.append(set_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06cace-457b-4845-bfbe-78954de01973",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0)).to(pred_kmeans.device).long()\n",
    "cluster_assignment_argmax = all_clu_pred.argmax(dim=-1)\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = cluster_assignment_argmax[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf2c04-7a24-4da7-9bb5-4a1771cb3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_assignment_pred = torch.zeros(pred_kmeans.size(0), class_topk_assignment.size(1)).to(class_topk_assignment.device).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assignment_pred[select] = class_topk_assignment[c].view(-1, class_topk_assignment.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddf3a3-5c40-411a-94b0-0f8fd1033079",
   "metadata": {},
   "outputs": [],
   "source": [
    "((instance_assignment_pred[:, 0]==all_gt_voc) | (instance_assignment_pred[:, 1]==all_gt_voc)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff5b8b-7e5a-4501-813e-a8b8f49b9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.from_numpy(all_mcmf_instance_pred)==all_gt_voc).float().mean(), (instance_assignment_pred==all_gt_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3dfd7-b123-48ed-8b03-f0412b0fba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "(instance_assignment_pred==all_gt_voc).float().mean(), len(set(all_gt_voc.unique().numpy()) - set(class_topk_assignment.unique().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43394174-62af-486b-9343-d8b2a4ff98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_topk_assignment.flatten().unique().long(), all_gt_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9f42b-9961-4a24-b172-265501467003",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_mcmf_rerank_pred.squeeze(1), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2b726-9910-44ba-bd22-f9232e038cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isin(all_gt_voc.unique(), instance_assignment_pred.unique().long()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa41c0-83b6-4343-96ec-26b7a5abff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ind, unique_count = torch.from_numpy(all_mcmf_rerank_pred[select]).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc8434-c573-4e2b-8ff8-90f6cb4cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ind[unique_count.argsort()[-1]].item(), unique_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8830f-3235-4f83-a063-a332d6236112",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56630fb-9c21-4b54-a78f-06c271abc438",
   "metadata": {},
   "source": [
    "test for MCMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196a123-fccb-4f9a-bc97-88427099915d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "class_topk_assignment = MCMF_assign_labels(all_clu_pred.cpu().numpy(), K=K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e9e34a-29d8-4855-998d-c1a06d283db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" overlap with SCD linear assignment prediction \n",
    "NOTE: MCMF is not ordered prediction\n",
    "\"\"\"\n",
    "for i in range(K):\n",
    "    overlap = (all_clu_pred.argmax(dim=-1).cpu()==class_topk_assignment[:, i]).sum()\n",
    "    print(overlap.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f584cab-0721-4b67-9223-2097b76a8cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('missing label:', len(set_gt - set(class_topk_assignment.unique().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4082f41-7789-4577-b505-2eb33b6788b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" reranking with voting similarity \"\"\"\n",
    "class_topk_assignment_ordered = torch.gather(class_topk_assignment, 1, torch.gather(all_clu_pred, 1, class_topk_assignment).argsort(descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab171407-10f8-4d1a-b1bd-7068d4ac5556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(class_topk_assignment_ordered[record_pred_kmeans_t][:, 1]==all_gt_voc).float().mean() #, (class_topk_assignment_ordered[record_pred_kmeans_t][:, 0]==cluster_ind_voc.cpu()).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde93f02-13a3-498c-ba18-67de692b8e3b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641aa10-d6ea-4434-b4b3-57058a9e1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()\n",
    "input_resolution = model.visual.input_resolution\n",
    "context_length = model.context_length\n",
    "vocab_size = model.vocab_size\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d793092-23ab-497e-9759-714c91e55e51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac099527-5211-4e10-a50f-1ebc926834c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" topk prediction from CLIP \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "use_norm = True\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True) if use_norm else classifier\n",
    "\n",
    "# initial topK prediction from CLIP\n",
    "prob_k = 5\n",
    "all_topk_voc = []\n",
    "all_gt_voc = []\n",
    "all_prob = []\n",
    "all_max_ind = []\n",
    "all_topk_vocinds = []\n",
    "all_label_clu = []\n",
    "all_topk_vals = []\n",
    "all_topk_inds = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True) if use_norm else logits\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                pred_topk_scattered = torch.scatter(torch.zeros([images.size(0), classifier.size(0)], \n",
    "                                                                device=args.device), 1, prob_topk_ind, 1)\n",
    "                all_topk_voc.append(pred_topk_scattered.cpu())\n",
    "                all_gt_voc.append(label_voc)\n",
    "                all_label_clu.append(label_clu)\n",
    "                all_max_ind.append(prob.argmax(dim=-1).cpu())\n",
    "                all_topk_vocinds.append(prob.topk(k=10, dim=-1).indices.cpu())\n",
    "                \n",
    "                batch_topk_res = prob.topk(k=20, dim=-1)\n",
    "                all_topk_vals.append(batch_topk_res.values.cpu())\n",
    "                all_topk_inds.append(batch_topk_res.indices.cpu())\n",
    "        pbar.update(1)\n",
    "\n",
    "# all_prob = torch.cat(all_prob, dim=0)\n",
    "all_topk_voc = torch.cat(all_topk_voc, dim=0)\n",
    "all_gt_voc = torch.cat(all_gt_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "all_max_ind = torch.cat(all_max_ind, dim=0)\n",
    "all_topk_vocinds = torch.cat(all_topk_vocinds, dim=0)\n",
    "all_topk_vals = torch.cat(all_topk_vals, dim=0)\n",
    "all_topk_inds = torch.cat(all_topk_inds, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b4a31-0d72-45d8-bcdd-97c69944fecb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### text proto inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159430a-4362-40b9-9181-1c08c1de63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN proto analysis\n",
    "text_sim = classifier[all_gt_voc.unique(), :]@classifier.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5c99a-edbd-485e-9082-ab819e27db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_topk = text_sim.topk(k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a41ba7-f29d-4697-ae19-399d222cc970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(np.array([vocab.mapping_idx_names[t.item()] for t in text_topk.indices[:, :].flatten().cpu()]).reshape(text_sim.size(0), -1).tolist(), compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f20703-1fc0-4791-9242-591d6a7b10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "sns.distplot(all_topk_vals[:, 0].cpu().numpy(), bins=200)\n",
    "sns.distplot(all_topk_vals[:, 1].cpu().numpy(), bins=200)\n",
    "sns.distplot(all_topk_vals[:, 2].cpu().numpy(), bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075cda2-8944-48de-b2f5-8e9517de5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = (all_topk_vals[:, 0]>0.7)\n",
    "'top1 acc', (all_gt_voc[selected] == all_max_ind[selected]).float().mean(), \\\n",
    "'selected percentile', selected.float().mean(), \\\n",
    "'class diversity', len(set(all_gt_voc.unique().numpy()) - set(all_max_ind[selected].unique().numpy())), \\\n",
    "'topk inclusion', torch.stack([all_topk_vocinds[selected, i]==all_gt_voc[selected] for i in range(all_topk_vocinds.size(1))], dim=1).float().sum(dim=-1).bool().float().mean(), \\\n",
    "'selected sample pred voc size', len(all_max_ind[selected].unique()), \\\n",
    "'average selected instance number per class', selected.sum()/len(all_gt_voc.unique()),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e444ff3-7837-4e21-a5eb-d21c6111fd73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" initial clip assignment \"\"\"\n",
    "list(filter(lambda x: x[1]<100, [(i.item(), (all_max_ind==i).sum().item()) for i in all_gt_voc.unique()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15937caa-ab71-4efd-b334-634f64485d73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### text to image entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9165942-c523-4821-9ddf-da7e57c3e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "### get all label and predicted label\n",
    "all_label_voc = []\n",
    "all_pred_voc = []\n",
    "all_label_clu = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                pred_voc = prob.argmax(dim=-1)\n",
    "        all_label_voc.append(label_voc)\n",
    "        all_pred_voc.append(pred_voc.cpu())\n",
    "        all_label_clu.append(label_clu)\n",
    "        pbar.update(1)\n",
    "all_label_voc = torch.cat(all_label_voc, dim=0)\n",
    "all_pred_voc = torch.cat(all_pred_voc, dim=0)\n",
    "all_label_clu = torch.cat(all_label_clu, dim=0)\n",
    "\n",
    "                \n",
    "### compute entropy\n",
    "set_all_label_voc = all_label_voc.unique()\n",
    "set_all_pred_voc = all_pred_voc.unique()\n",
    "selected_classifier_ind = torch.cat([set_all_label_voc, set_all_pred_voc], dim=0).unique()\n",
    "all_similarity = []\n",
    "all_selected_sim = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        label_voc = label_voc.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = model.logit_scale.exp() * logits @ classifier.t()\n",
    "                all_selected_sim.append(similarity[:, selected_classifier_ind].cpu())\n",
    "                all_similarity.append(similarity.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "        \n",
    "all_selected_sim = torch.cat(all_selected_sim, dim=0)\n",
    "all_similarity = np.concatenate(all_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ded316-eb1c-43f6-93a0-b65682197242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kmeans_t = torch.from_numpy(np.load(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy'))\n",
    "classwise_all_selected_sim = []\n",
    "for c in pred_kmeans_t.unique():\n",
    "    subset = (pred_kmeans_t==c)\n",
    "    classwise_all_selected_sim.append(all_selected_sim[subset, :].mean(dim=0).cpu())\n",
    "classwise_all_selected_sim = torch.stack(classwise_all_selected_sim, dim=0)\n",
    "p = classwise_all_selected_sim.float().softmax(dim=0)\n",
    "ent = (-p*(p+1e-10).log2()).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446d82a-1e89-4e68-a08f-2924614cc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "softmax(all_similarity, axis=0)\n",
    "pred_kmeans_t = torch.from_numpy(np.load(f'./pred_clu_clip-{args.dataset_name}-train-{arch}.npy'))\n",
    "classwise_all_sim = []\n",
    "for c in pred_kmeans_t.unique():\n",
    "    subset = (pred_kmeans_t==c)\n",
    "    classwise_all_sim.append(all_selected_sim[subset, :].mean(dim=0).cpu())\n",
    "classwise_all_sim = torch.stack(classwise_all_sim, dim=0)\n",
    "p_all = classwise_all_sim.float().softmax(dim=0)\n",
    "ent_all = (-p_all*(p_all+1e-10).log2()).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f95cb-d240-4f8e-bff3-89d1ee2b0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent = torch.nan_to_num(ent)\n",
    "ent_gt = ent[torch.isin(selected_classifier_ind, set_all_label_voc)]\n",
    "ent_pred = ent[torch.isin(selected_classifier_ind, set_all_pred_voc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2bd40-54aa-4cd3-8b70-9818908b212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=128)\n",
    "sns.distplot(ent_gt.numpy(), bins=100)\n",
    "sns.distplot(ent_pred.numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5420f-f0cd-4283-b407-23b711156895",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ent_gt>2).sum(), (ent_gt>3).sum(), \\\n",
    "(ent_pred<2).sum(), (ent_pred<3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423501f-0554-4cfc-8457-5d5b2deb434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ent_gt>2).sum(), (ent_gt>3).sum(), \\\n",
    "(ent_pred<2).sum(), (ent_pred<3).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b0a19-6e75-46b1-bc28-c977acbaca11",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### class-wise distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907b0c5-c4ad-47e4-b212-871cf13a6ae9",
   "metadata": {},
   "source": [
    "collect variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb4816-1225-43a5-a842-f42334f28c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" collect variables \"\"\"\n",
    "classifier = get_classifier(args)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# initial topK prediction from CLIP\n",
    "prob_k = 5\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_inst_topk_ind_voc = []\n",
    "all_inst_topk_val_voc = []\n",
    "all_inst_max_pred = []\n",
    "all_img_idx = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk = prob.topk(k=prob_k, dim=-1)\n",
    "                \n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_inst_topk_ind_voc.append(prob_topk.indices[:, :prob_k+1].cpu())\n",
    "                all_inst_topk_val_voc.append(prob_topk.values[:, :prob_k+1].cpu())\n",
    "                all_inst_max_pred.append(prob.argmax(dim=-1).cpu())\n",
    "                all_img_idx.append(idx_img)\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_inst_topk_ind_voc = torch.cat(all_inst_topk_ind_voc, dim=0)\n",
    "all_inst_topk_val_voc = torch.cat(all_inst_topk_val_voc, dim=0)\n",
    "all_inst_max_pred = torch.cat(all_inst_max_pred, dim=0)\n",
    "all_img_idx = torch.cat(all_img_idx, dim=0)\n",
    "\n",
    "# res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "# all_clu_pred = res['all_clu_pred']\n",
    "# label_voc_kmeans = res['label_voc_kmeans']\n",
    "# pred_kmeans_t = res['pred_kmeans_t']\n",
    "# cluster_ind_voc = res['cluster_ind_voc']\n",
    "# record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "# all_gt_voc = res['all_gt_voc']\n",
    "# all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0c7c3-a560-4944-be35-4984d7286aac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "args.num_voc = classifier.size(0)\n",
    "\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "history_mapping_assignment_clu = []\n",
    "for t in range(3):\n",
    "    record_pred_kmeans_t = pred_kmeans_t\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_inst_topk_ind_voc, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_label_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_label_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    history_mapping_assignment_clu.append(pred_kmeans_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37f3f70-fa95-4d12-8a68-db76c60f3f72",
   "metadata": {},
   "source": [
    "##### class-wise feaature space with KNN prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bb374-07de-4539-8b90-a1c2f1c419f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "\n",
    "all_class_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                features = model.visual(images)\n",
    "                features = features/features.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                # if select[idx_img].sum().item()==0:\n",
    "                #     pbar.update(1)\n",
    "                #     continue\n",
    "                all_class_features.append(features.cpu().numpy())\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "all_class_features = np.concatenate(all_class_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6367e97-4145-40a5-b4c1-cac6d43e0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### randomly select a class of features \n",
    "np.random.seed(5)\n",
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "selected_all_class_features = torch.from_numpy(all_class_features)[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8553e-8c3f-4b8c-811f-d66ab399638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute scd confusing classifier\n",
    "i = torch.arange(select.size(0))[select]\n",
    "for x in history_mapping_assignment_clu[:-1]:\n",
    "    i = x[i]\n",
    "ind, counts = i.unique(return_counts=True)\n",
    "all_confusing_classifier_ind = all_clu_pred[ind[counts.argmax()]].topk(k=3).indices\n",
    "\n",
    "confusing_classifier = classifier[all_confusing_classifier_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299acae-d0bb-4b15-8169-b2b28c2d2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "### distances among confusing classifiers\n",
    "triu_confusing_classifier = (confusing_classifier@confusing_classifier.t()).triu(1)\n",
    "dist_confusing_classifier = triu_confusing_classifier[triu_confusing_classifier.nonzero(as_tuple=True)]\n",
    "print(dist_confusing_classifier.mean(), dist_confusing_classifier.max(), dist_confusing_classifier.min())\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(dist_confusing_classifier.cpu().numpy(), bins=10)\n",
    "plt.show()\n",
    "\n",
    "### distances among gt classifier and confusing classifiers\n",
    "gt_voc_label = all_gt_label_voc[select].unique()[0].item()\n",
    "classifier[gt_voc_label].view(1, -1)@confusing_classifier.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0c3dd-d4d5-43ed-a22d-2718d9f1ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_voc_label in all_confusing_classifier_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39606dc-cf07-4b8c-996c-70f8f9f85e93",
   "metadata": {},
   "source": [
    "visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c855b4-e5a0-489f-8de1-1b443c5426a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.random.choice(all_gt_label_clu.unique().numpy())\n",
    "select = (all_gt_label_clu==c.item())\n",
    "selected_all_class_features = all_class_features[select.numpy()]\n",
    "\n",
    "### compute scd confusing classifier\n",
    "i = torch.arange(select.size(0))[select]\n",
    "for x in history_mapping_assignment_clu[:-1]:\n",
    "    i = x[i]\n",
    "ind, counts = i.unique(return_counts=True)\n",
    "all_confusing_classifier_ind = list(set(all_clu_pred[ind[counts.argmax()]].topk(k=5).indices.flatten().numpy()) )\n",
    "                                    # | set(all_inst_topk_ind_voc[select].unique().numpy()))\n",
    "\n",
    "all_confusing_classifier = classifier[torch.tensor(all_confusing_classifier_ind), :].cpu().numpy()\n",
    "all_features_vis = np.concatenate([selected_all_class_features, all_confusing_classifier, classifier[c].view(1, -1).cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9f2ca-ec79-4687-b78f-4bf020dc5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, \n",
    "            n_iter=1000, \n",
    "            # perplexity=10,\n",
    "            method='exact',\n",
    "           )\n",
    "tr_all_features_vis = tsne.fit_transform(all_features_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f19e5b-a25c-4ba8-b292-f5cd06956856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(dpi=128)\n",
    "plt.scatter(x=tr_all_features_vis[:selected_all_class_features.shape[0], 0], y=tr_all_features_vis[:selected_all_class_features.shape[0], 1], s=5, c='b', alpha=0.6)\n",
    "plt.scatter(x=tr_all_features_vis[selected_all_class_features.shape[0]:-1, 0], y=tr_all_features_vis[selected_all_class_features.shape[0]:-1, 1], s=5, c='g', alpha=0.8)\n",
    "plt.scatter(x=tr_all_features_vis[-1, 0], y=tr_all_features_vis[-1, 1], s=8, c='r', alpha=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fdeec-8a34-4438-b8d8-e49fbe8a6843",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### spatial region visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220fb90-11d5-42c5-aa86-fc28ab55c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "from PIL import Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea03a00-fc6f-43c0-9aef-35e9153ed7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. collect variables\n",
    "upper bound visualization test\n",
    "\"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-vit_dino.npy'))\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_inst_topk_ind_voc, voc_size=args.num_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6ad22-bf9a-42f9-9af6-bb752ac2fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "### cluster to instance topk\n",
    "cluster_topk_ind = all_clu_pred.topk(k=5).indices\n",
    "inst_topk_ind = cluster_topk_ind[pred_kmeans.long(), ...]\n",
    "### sample one cluster \n",
    "sampled_cluster_idx = torch.randint(low=0, high=all_gt_label_clu.max(), size=[1])\n",
    "inst_select = all_gt_label_clu==sampled_cluster_idx.item()\n",
    "\n",
    "sampled_img_idx = np.random.choice(inst_select.nonzero().flatten().numpy(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb46779-a632-4c67-a04e-9d1d378f9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "model.eval()\n",
    "with amp_autocast():\n",
    "    with torch.no_grad():\n",
    "        image, label_voc, label_clu, _ = dataset_f[sampled_img_idx[idx]]\n",
    "        image = image.to(args.device)\n",
    "        \n",
    "        candidate_voc_labels = inst_topk_ind[sampled_img_idx[idx]]\n",
    "        candidate_voc_synsets = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name() for x in candidate_voc_labels ]\n",
    "        gt_class_label = mapping_vocidx_to_synsets(label_voc, vocab)[0].name()\n",
    "        \n",
    "        features = model.visual(image.unsqueeze(0), return_spatial=True)\n",
    "        features = F.normalize(features, dim=-1)\n",
    "        \n",
    "        spatial_sim = 100 * features[0, 1:, :]@classifier[candidate_voc_labels].t()\n",
    "        spatial_softmax = spatial_sim.softmax(dim=-1)\n",
    "        spatial_ind = spatial_softmax.argmax(dim=-1).reshape(14, 14)\n",
    "        spatial_score = spatial_softmax.amax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        spatial_sim_entire = 100 * features[0, 1:, :]@classifier.t()\n",
    "        spatial_softmax_entire = spatial_sim_entire.softmax(dim=-1)\n",
    "        spatial_sim_entire = spatial_sim_entire[:, candidate_voc_labels]\n",
    "        spatial_ind_entire = spatial_softmax_entire.argmax(dim=-1).reshape(14, 14)\n",
    "        spatial_score_entire = spatial_softmax_entire.amax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        sim_self = 10 * features[0, 0, :]@features[0, 1:, :].t()\n",
    "        sim_self = sim_self.softmax(dim=-1).reshape(14, 14)\n",
    "        \n",
    "        candidate_voc_topk_labels = (100 * features[0, 0, :]@classifier.t()).topk(k=10).indices\n",
    "        candidate_voc_topk_synsets = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name() for x in candidate_voc_topk_labels ]\n",
    "        \n",
    "        features = model.visual(image.unsqueeze(0), return_spatial=True, with_proj=False)\n",
    "        features = F.normalize(features, dim=-1)\n",
    "        \n",
    "        image, label_voc, label_clu, _ = dataset_r[sampled_img_idx[idx]]\n",
    "        sim_self = 10 * features[0, 0, :]@features[0, 1:, :].t()\n",
    "        sim_self = sim_self.softmax(dim=-1).reshape(14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d16c8-f23a-4ef2-900b-fdb41006bbdc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_ind, spatial_score, spatial_ind_entire, spatial_score_entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e305481-005d-4d73-914b-011aa97fa716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint([gt_class_label, candidate_voc_synsets, candidate_voc_topk_synsets], compact=True)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=4, dpi=128)\n",
    "ax[0,0].imshow(np.array(image.resize([256,256])))\n",
    "ax[0,0].axis(False)\n",
    "ax[0,1].imshow(spatial_score.cpu().numpy())\n",
    "ax[0,1].axis(False)\n",
    "ax[0,2].imshow(spatial_ind.cpu().numpy())\n",
    "ax[0,2].axis(False)\n",
    "ax[0,3].imshow(spatial_score.cpu().numpy()>0.6)\n",
    "ax[0,3].axis(False)\n",
    "\n",
    "ax[1,0].imshow(np.array(image.resize([256,256])))\n",
    "ax[1,0].axis(False)\n",
    "ax[1,1].imshow(spatial_score_entire.cpu().numpy())\n",
    "ax[1,1].axis(False)\n",
    "ax[1,2].imshow(spatial_ind_entire.cpu().numpy()==gt_voc_label)\n",
    "ax[1,2].axis(False)\n",
    "ax[1,3].imshow(spatial_score_entire.cpu().numpy()>0.5)\n",
    "ax[1,3].axis(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(sim_self.cpu().numpy()>sim_self.flatten().topk(k=10).values[-1].item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d0b01-e3dc-4ebd-a3ac-5b18633a9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ mapping_vocidx_to_synsets(x.item(), vocab)[0].definition() for x in candidate_voc_labels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77a81a-7092-4ea4-b5fe-a436208081b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "s = (features[0, 1:, :]@features[0, 1:, :].t())[(sim_self.cpu().numpy()>sim_self.flatten().topk(k=10).values[-1].item()).flatten()]\n",
    "for i in range(s.size(0)):\n",
    "    plt.imshow(s[i].reshape(14, 14).cpu().numpy()>s[i].topk(k=20).values[-1].item())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9919f-7380-4aa5-9927-a49607e70ffa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Linguistic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d4eea-51fe-48e4-a9d1-d6e8177699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "from PIL import Image\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fef3e7-1463-4e39-af54-480565eaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mutex_prompt(args, model, pairs):\n",
    "    \"\"\"\n",
    "    return:\n",
    "        class_embedding: tensor([P x D])\n",
    "    \"\"\"\n",
    "    with open('../templates_small_mutex.json', 'rb') as f:\n",
    "        data = json.load(f)['imagenet']\n",
    "        \n",
    "    all_prompts = []\n",
    "    for p in pairs:\n",
    "        prompts = []\n",
    "        for r in data:\n",
    "            prompts.append(r.format(p[0], p[1]))\n",
    "        all_prompts.append(prompts)\n",
    "    all_prompts = np.array(all_prompts)\n",
    "    n_pairs, n_templates = all_prompts.shape\n",
    "    \n",
    "    # model, preprocess = clip.load(args.arch)\n",
    "    # model.to(args.device).eval()\n",
    "    \n",
    "    texts = tokenize(all_prompts.ravel()).to(args.device) # tokenize\n",
    "    class_embeddings = model.encode_text(texts) # embed with text encoder\n",
    "    class_embeddings = class_embeddings.view(n_pairs, n_templates, -1)\n",
    "    class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "    class_embedding = class_embeddings.mean(dim=1)\n",
    "    class_embedding /= class_embedding.norm(dim=-1, keepdim=True)\n",
    "    return class_embedding, all_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ae1b5-a2d6-474e-a02b-ffef04608e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(args.arch)\n",
    "model.to(args.device).eval()\n",
    "\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23e684-58a2-4d06-a7fc-a017446cb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_topk_pred_voc_ind = all_clu_pred.topk(k=5).indices\n",
    "class_topk_class_names = np.array([ mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] \n",
    "                                   for x in class_topk_pred_voc_ind.flatten().numpy() ]).reshape(-1, 5)\n",
    "class_mutex_templates = []\n",
    "for row in class_topk_class_names:\n",
    "    class_mutex_templates.append([[x, y] for i, x in enumerate(row) for j, y in enumerate(row) if i!=j])\n",
    "\n",
    "idx_class = 12\n",
    "class_embedding_pair, prompts_pair = build_mutex_prompt(args, model, class_mutex_templates[idx_class])\n",
    "classifier = get_classifier(args)\n",
    "class_embedding_single = classifier[class_topk_pred_voc_ind[idx_class]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5df626-13ac-4b93-9390-2f1152d9be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim = class_embedding_single@class_embedding_single.t()\n",
    "sim_pair = class_embedding_pair.float() @ class_embedding_pair.float().t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd382f8-5568-4978-b3e8-e6585c1d102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        p1 = [i//4, i%4]\n",
    "        p2 = [j//4, j%4]\n",
    "        if (p1[0]==p2[1]) and (p1[1]==p2[0]) and (p1[0]!=p1[1]) and (p2[0]!=p2[1]):\n",
    "            res.append(sim_pair[i, j].item())\n",
    "print(np.mean(res))\n",
    "print(self_sim.triu(1)[self_sim.triu(1).nonzero(as_tuple=True)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bba420-e9b1-4e25-be6d-c2407d9b5d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa441492-f2e6-46db-8c94-d0b7542634c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2b6d8b-9bdd-4034-94a5-16d2fdfa4806",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872be6e4-28f3-422b-b7d0-d90c8f554dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### collect features and labels\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_img_idx = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_img_idx.append(idx_img)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "                \n",
    "        pbar.update(1)\n",
    "\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_img_idx = torch.cat(all_img_idx, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dc601-24ca-4ac9-9136-7e8a5f37dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_store = {\n",
    "    'all_gt_label_voc': all_gt_label_voc.cpu(),\n",
    "    'all_gt_label_clu': all_gt_label_clu.cpu(),\n",
    "    'all_img_idx': all_img_idx.cpu(),\n",
    "    'all_features': all_features,\n",
    "}\n",
    "torch.save(clip_store, f'./cache/clip_store-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1114234-f9e4-4274-858f-dfb0f62aa349",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_name = 'make_entity13'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9dbb29-97f8-4457-95de-d8260d896a28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Classifier Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052655e-3e69-464b-afe0-0caa99b82767",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_name = 'make_nonliving26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ed488-fab0-4b78-ab5c-78c054069bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f)\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)\n",
    "dataset_r = get_datasets_oszsl(args, vocab, is_train=True, transform=None, seed=1)\n",
    "\n",
    "if subset == 'train':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-{arch}.npy'))\n",
    "elif subset == 'val':\n",
    "    pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-val-{arch}.npy'))\n",
    "    \n",
    "model, preprocess = clip.load(args.arch)\n",
    "if args.clip_checkpoint:\n",
    "    model.load_state_dict({k[len('model.'):]:v for k, v in torch.load(args.clip_checkpoint, map_location='cpu')['model'].items()}, strict=False)\n",
    "model.to(args.device).eval()\n",
    "\n",
    "classifier = get_classifier(args)\n",
    "classifier = F.normalize(classifier.float(), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769921b6-b0ae-497d-a178-33c612569d78",
   "metadata": {},
   "source": [
    "collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae32f8-a5ec-4687-8423-296b8ef95c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']\n",
    "\n",
    "\n",
    "### collect features and labels\n",
    "all_knn_classifier_ind = []\n",
    "all_knn_classifier_val = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        _, label_voc, label_clu, idx_img = batch\n",
    "        batch_features = torch.from_numpy(all_features[idx_img.numpy()])\n",
    "        batch_features = F.normalize(batch_features.float(), dim=-1).to(args.device)\n",
    "        sim = batch_features@classifier.t()\n",
    "        sim_topk = sim.topk(k=5)\n",
    "        all_knn_classifier_ind.append(sim_topk.indices.cpu())\n",
    "        all_knn_classifier_val.append(sim_topk.values.cpu())\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "all_knn_classifier_ind = torch.cat(all_knn_classifier_ind, dim=0)\n",
    "all_knn_classifier_val = torch.cat(all_knn_classifier_val, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbaced4-5d9f-41c0-bdfe-a505669394a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(100*all_knn_classifier_val).softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2d647-d200-41f7-a1d6-3f58bf3e8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_knn_classifier_ind, f'./cache/clip_img_knn-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487d13c-0071-428a-9a48-55d903bed11e",
   "metadata": {},
   "source": [
    "#### Classifier study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30fdb79-2d76-4965-b730-92335270fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_knn_classifier_ind = torch.load(f'./cache/clip_img_knn-{args.dataset_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cca80d-b55c-472c-a607-bbbaaba2eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_knn_classifier_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b1aac-aa7c-4a7e-b635-d168a4ec5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind, val = all_knn_classifier_ind.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a4c1c-c23c-4c0e-9275-d00a3a567bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load SCD results\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24460e4a-1b0b-444a-8351-549de3080b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-clip.npy'))\n",
    "args.num_voc = classifier.size(0)\n",
    "all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_knn_classifier_ind, voc_size=args.num_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee0f9c-f1d5-4e7f-bba5-f2f8e1d7edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "K = all_knn_classifier_ind.size(1)\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in pred_kmeans.unique():\n",
    "    select = (pred_kmeans==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=5).indices\n",
    "\n",
    "print('acc', (instance_assigned_pred[:, 0]==all_gt_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f15c4a-bddb-44ce-97d4-b0215a71b063",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_select_idx = 2\n",
    "class_select = (pred_kmeans==class_select_idx)\n",
    "study_candidates = all_clu_pred.topk(k=3).indices[class_select_idx]\n",
    "ind, val = all_gt_voc[class_select].unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b9656-c95c-433d-8066-8da67604f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "\n",
    "print([mapping_vocidx_to_synsets(c.item(), vocab)[0].name().split('.')[0] for c in study_candidates])\n",
    "print([mapping_vocidx_to_synsets(c.item(), vocab)[0].definition() for c in study_candidates])\n",
    "\n",
    "# descriptions = \\\n",
    "# [\n",
    "#     \"A photo of an aircraft_carrier. It has a long, flat deck, with a large superstructure at the back, and a tall tower at the front. It is usually painted grey, and has multiple aircrafts parked on the deck.\",\n",
    "#     \"A photo of a parking_meter. A metal box with a coin slot, a digital display, and a lever or button to activate the timer.\",\n",
    "#     \"A photo of an ambulance. A vehicle typically characterized by a bright red or orange color, a siren, and a medical cross symbol.\",\n",
    "# ]\n",
    "descriptions = \\\n",
    "[\n",
    "    \"A photo of a Winnebago. The Winnebago language is characterized by a distinct set of phonemes and a unique set of grammatical structures.\",\n",
    "    \"A photo of an ambulance. A vehicle typically characterized by a bright red or orange color, a siren, and a medical cross symbol.\",\n",
    "    \"A photo of police_van. A large, box-shaped vehicle with a distinctive black and white paint job and a barred window in the back.\"\n",
    "]\n",
    "descriptions = \\\n",
    "[\n",
    "    \"A photo of a gobiesox. Small, slender fish with a laterally compressed body and two separate dorsal fins.\",\n",
    "    \"A photo of a sock. A foot covering that is typically made of cloth, reaching from the ankle to the knee.\",\n",
    "    \"A photo of a athletic_sock. A sock typically made of a lightweight, breathable material with a reinforced heel and toe for added durability.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e07785-bb8e-46b9-948a-b133e44d3413",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_classifier = tokenize(descriptions, truncate=True).to(args.device)\n",
    "study_classifier = model.encode_text(study_classifier)\n",
    "study_classifier = study_classifier/study_classifier.norm(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8242b1-613c-43d9-853d-1bd90c56d530",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96014516-c647-4578-a043-fd6412c4c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_features = torch.from_numpy(all_features[class_select]).to(args.device)\n",
    "class_label = all_gt_label_voc[class_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf12165-30f2-40fe-949c-e0eeec2b815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind, val = class_label.unique(return_counts=True)\n",
    "mapping_vocidx_to_synsets(ind[val.argmax(dim=-1)].item(), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58536a4-8e31-476a-94c7-094da5d3e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(study_candidates[(class_features.float() @ study_classifier.float().t()).argmax(dim=-1)]==class_label).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3062ab4d-c06a-42ba-88ba-af8376ee81a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(class_label==study_candidates[2]).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e81c1-70f6-48cd-9d98-04b8b9da769f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a0e6b-bf4b-495e-998b-33284b693507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordnet_utils import *\n",
    "\n",
    "def compute_knn_batch(tensor, k=5, exclude_self=False, batch_size=1024, device='cpu'):\n",
    "    n_batch = int(np.ceil(tensor.size(0)/batch_size))\n",
    "    all_topk_ind = []\n",
    "    all_topk_val = []\n",
    "    for b in range(n_batch):\n",
    "        start = b*batch_size\n",
    "        end = min((b+1)*batch_size, tensor.size(0))\n",
    "        batch_tensor = tensor[start:end, :].to(device)\n",
    "        batch_sim = batch_tensor@tensor.t()\n",
    "        batch_sim_topk = batch_sim.topk(k=k)\n",
    "        if exclude_self:\n",
    "            all_topk_ind.append(batch_sim_topk.indices[:, 1:k+1].cpu())\n",
    "            all_topk_val.append(batch_sim_topk.values[:, 1:k+1].cpu())\n",
    "        else:\n",
    "            all_topk_ind.append(batch_sim_topk.indices[:, :k].cpu())\n",
    "            all_topk_val.append(batch_sim_topk.values[:, :k].cpu())\n",
    "    all_topk_ind = torch.cat(all_topk_ind, dim=0)\n",
    "    all_topk_val = torch.cat(all_topk_val, dim=0)\n",
    "    return all_topk_ind, all_topk_val\n",
    "\n",
    "\n",
    "def compute_similarity_with_augmented_classifier(features, candidate_names, \n",
    "                                                 class_name_key_mapping, all_augmented_classifier, \n",
    "                                                 method='ensemble', agg_func=None, return_type='max', **kwargs):\n",
    "    \"\"\" only support single instance \n",
    "    Args:\n",
    "        features: tensor([D])\n",
    "        candidate_names: list([])\n",
    "        class_name_key_mapping: {`class_name`: [`synsets`]}\n",
    "        all_augmented_classifier: {`synset`: tensor([M x D])}\n",
    "    \"\"\"\n",
    "    res_similarity = {}\n",
    "    for c in candidate_names:\n",
    "        res_similarity.setdefault(c, [])\n",
    "        synsets = class_name_key_mapping[c]\n",
    "        for synset in synsets:\n",
    "            if method == 'ensemble':\n",
    "                single_ensembled_classifier = all_augmented_classifier[synset].to(features.device).float().mean(dim=0)\n",
    "                sim = 100 * features.view(1, -1) @ single_ensembled_classifier.view(1, -1).t()\n",
    "                res_similarity[c].append(sim.item())\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "    if agg_func is not None:\n",
    "        for k, v in res_similarity.items():\n",
    "            res_similarity[k] = agg_func(v)\n",
    "        if return_type=='max':\n",
    "            max_k = max(res_similarity, key=lambda x: res_similarity[x])\n",
    "            return max_k\n",
    "        elif return_type=='topk':\n",
    "            top_k = heapq.nlargest(kwargs['k'], res_similarity, key=res_similarity.get)\n",
    "            return top_k\n",
    "    return res_similarity\n",
    "    \n",
    "    \n",
    "def agg_by_pred_cluster(args, pred_kmeans, all_topk_voc, voc_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred_kmeans: np.array([N])\n",
    "        all_topk_voc: np.array([N x K])\n",
    "        voc_size: int\n",
    "    Returns:\n",
    "        all_clu_pred: tensor([C x V])\n",
    "    \"\"\"\n",
    "    print('agg_by_pred_cluster')\n",
    "    all_clu_pred = []\n",
    "    n_count = []\n",
    "    for i in np.unique(pred_kmeans):\n",
    "        selected = (pred_kmeans==i)\n",
    "        n_count.append( selected.sum().item() )\n",
    "        counter_voc_ind, counter_val = np.unique((all_topk_voc[selected]).ravel(), return_counts=True)\n",
    "        # counter_val = counter_val/(n_count+1e-20) # L1 norm\n",
    "        clu_pred = torch.zeros(args.num_voc) # cluster-wise prob\n",
    "        clu_pred[torch.from_numpy(counter_voc_ind).long()] = torch.from_numpy(counter_val).float()\n",
    "        # clu_pred = F.normalize(all_topk_voc[selected].sum(dim=0), dim=-1, p=1)\n",
    "        all_clu_pred.append(clu_pred)\n",
    "    all_clu_pred = torch.stack(all_clu_pred, dim=0).cpu()\n",
    "    n_count = torch.tensor(n_count).cpu()\n",
    "    \n",
    "    # all_clu_pred = setdiff_assignment(all_clu_pred)\n",
    "    \n",
    "    all_clu_pred = all_clu_pred/(n_count.view(-1, 1) + 1e-20)\n",
    "    \n",
    "    print('is mutex assignment::', all_clu_pred.argmax(dim=-1).size(0)==all_clu_pred.argmax(dim=-1).unique().size(0))\n",
    "    print('assignment collision num::', len(list(filter(lambda x: x>1, Counter(all_clu_pred.argmax(dim=-1).numpy()).values()))))\n",
    "    return all_clu_pred\n",
    "\n",
    "def linear_assign(all_clu_pred, pred_kmeans, all_gt_voc):\n",
    "    print('linear_assign')\n",
    "    cost_mat = all_clu_pred.cpu().numpy()\n",
    "    print(f'assignment shape={cost_mat.shape}')\n",
    "    res_ass = linear_assignment(cost_mat.max() - cost_mat)\n",
    "    label_voc_kmeans = torch.tensor([res_ass[1][x.item()] for x in pred_kmeans])\n",
    "    print('instance label acc::', (label_voc_kmeans==all_gt_voc).float().mean().item())\n",
    "    return label_voc_kmeans, res_ass\n",
    "\n",
    "def reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, device, all_prob=None, \n",
    "                             instance_selected=None, \n",
    "                             classifier_selected=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        classifier_selected: tensor([C2])\n",
    "    \"\"\"\n",
    "    print('reassign_by_pred_cluster')\n",
    "    amp_autocast = torch.cuda.amp.autocast\n",
    "    label_voc_kmeans = label_voc_kmeans.to(device)\n",
    "    if all_prob is None:\n",
    "        cluster_ind = []\n",
    "        with tqdm(total=len(loader_f)) as pbar:\n",
    "            if hasattr(model, 'eval'):\n",
    "                model.eval()\n",
    "            for idx_batch, batch in enumerate(loader_f):\n",
    "                images, label_voc, label_clu, idx_img = batch[:4]\n",
    "                images = images.to(device)\n",
    "                if (instance_selected is not None) and ((~instance_selected[idx_img]).all()):\n",
    "                    continue\n",
    "                with amp_autocast():\n",
    "                    with torch.no_grad():\n",
    "                        if (instance_selected is not None):\n",
    "                            logits = model.visual(images[instance_selected[idx_img]])\n",
    "                        else:\n",
    "                            logits = model.visual(images)\n",
    "                            \n",
    "                        logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                        \n",
    "                        if classifier_selected is not None:\n",
    "                            similarity = 100 * logits @ classifier[classifier_selected].t()\n",
    "                            prob = classifier_selected[similarity.softmax(-1)]\n",
    "                            cluster_ind.append(prob.cpu().argmax(dim=-1))\n",
    "                        else:\n",
    "                            similarity = 100 * logits @ classifier.t()\n",
    "                            prob = similarity.softmax(-1)\n",
    "                            cluster_ind.append(prob[:, label_voc_kmeans].cpu().argmax(dim=-1))\n",
    "                pbar.update(1)\n",
    "        cluster_ind = torch.cat(cluster_ind, dim=0)\n",
    "    else:\n",
    "        all_prob = all_prob[:, label_voc_kmeans]\n",
    "        cluster_ind = all_prob.argmax(dim=-1)\n",
    "        \n",
    "    if classifier_selected is not None:\n",
    "        cluster_ind_voc = classifier_selected[cluster_ind]\n",
    "    else:\n",
    "        cluster_ind_voc = label_voc_kmeans[cluster_ind]\n",
    "    mapping_ind = dict(zip(cluster_ind.unique().numpy(), torch.arange(cluster_ind.unique().size(0)).numpy()))\n",
    "    cluster_ind = torch.tensor([mapping_ind[x.item()] for x in cluster_ind])\n",
    "    return cluster_ind, cluster_ind_voc\n",
    "\n",
    "\n",
    "def row_wise_isin(a, b):\n",
    "    n, k = b.size()\n",
    "    results = []\n",
    "    for i in range(1, k+1):\n",
    "        res = torch.zeros_like(a).bool()\n",
    "        for j in range(i):\n",
    "            res = res | (a==b[:, j])\n",
    "        results.append(res)\n",
    "    results = torch.stack(results, dim=1).cpu()\n",
    "    return results\n",
    "\n",
    "import openai\n",
    "def request_gpt(prompt, model_name='text-davinci-003', max_tokens=400, temperature=0.01, best_of=1):\n",
    "    openai.api_key = \"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\"\n",
    "    while 1:\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "              model=model_name,\n",
    "              prompt=prompt,\n",
    "              temperature=temperature,\n",
    "              max_tokens=max_tokens,\n",
    "              top_p=1,\n",
    "                best_of=best_of,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0,\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f'e={e}')\n",
    "            continue\n",
    "    return response\n",
    "\n",
    "def get_prompt_candidate_discrimination(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    ### 42\n",
    "    prompt = f\"Precisely describe discriminative visual features of each word in {candidate_string}. Describe the color and texture. In two bullet points, each uses the template \\\"{'name'}: {'description'}\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v2(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    prompt = f\"Precisely distinguish discriminative visual features (e.g., {attributes}) of each category in {candidate_string}. Each category is elaborated in separate sentence with template \\\"category_name: description\\\". Do not use comparative degree.\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v3(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    prompt = f\"There are five categories: {candidate_string}. Closely and Precisely mention all discriminative visual differences between each category and others. Each category is described in a caption with template \\\"category_name: description\\\". \"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_v4(candidates, attributes='color and shape'):\n",
    "    candidate_string = ''\n",
    "    candidates = list(map(lambda word:\"'\"+word+\"'\", candidates))\n",
    "    candidate_string = ', '.join(candidates[:-1]) + ', and ' + candidates[-1]\n",
    "    ### 44.8\n",
    "    # prompt = f\"Please generate visual descriptions based on the following five category nouns (taken from WordNet): {candidate_string}. For each category, provide a separate sentence that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others visually.\"\n",
    "    prompt = f\"Please generate visual descriptions based on the following three category nouns (taken from WordNet): {candidate_string}. For each category, sequentially provide a separate sentence that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others. Write in three lines, use template \\\"{'name'}: {'description'}\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_pair(candidates, attributes, index, enable_def=False):\n",
    "    pair = [ candidates[i] for i in index ]\n",
    "    candidate_string = ''\n",
    "    candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "    prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, please generate a separate phrase that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to only emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others in appearance. Write in two lines, use template \\\"name: description\\\".\"\n",
    "    if enable_def:\n",
    "        pair = [ candidates[i] for i in index ]\n",
    "        candidate_string = ''\n",
    "        candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "        prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, please generate a separate phrase that highlights representative visual features that distinguish it from the others. Be precise and concise in your descriptions, using vivid language to help bring each category to life. Please make sure to only emphasize the visual differences between the categories, and describe each category in a way that highlights how it differs from the others in appearance. Write in two lines, use template \\\"name: description\\\".\"\n",
    "    return prompt\n",
    "\n",
    "def get_prompt_candidate_discrimination_pair_caption(candidates, attributes, index, enable_def=False):\n",
    "    pair = [ candidates[i] for i in index ]\n",
    "    random.shuffle(pair)\n",
    "    candidate_string = ''\n",
    "    candidate_string = '\\'' + '\\' and \\''.join(pair) + '\\''\n",
    "    prompt = f\"Given two category nouns (taken from WordNet): {candidate_string}. For each category, imagine given one photo, please generate a list of frequently co-occurred related words in image caption dataset in descending order. Write in one line for each category. Only mention the word that the other do not have.\"\n",
    "    return prompt\n",
    "\n",
    "def build_classifier_from_prompt_response(args, model, response):\n",
    "    with open('../templates_small_description.json', 'rb') as f:\n",
    "        templates_small = json.load(f)['imagenet']\n",
    "    all_prompts = []\n",
    "    for r in response:\n",
    "        name, description = r.split(': ')[0].lower(), ': '.join(r.split(': ')[1:])\n",
    "        filled_templates_small = [t.format(name, description) for t in templates_small]\n",
    "        all_prompts.append(filled_templates_small)\n",
    "    all_aug_classifiers = []\n",
    "    for prompt in all_prompts:\n",
    "        aug_classifier = tokenize(prompt, truncate=True).to(args.device)\n",
    "        with torch.no_grad():\n",
    "            aug_classifier = model.encode_text(aug_classifier)\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        aug_classifier = aug_classifier.mean(dim=0) ### ensembling\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        all_aug_classifiers.append(aug_classifier)\n",
    "    all_aug_classifiers = torch.stack(all_aug_classifiers, dim=0).to(args.device)\n",
    "    return all_aug_classifiers\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c3799-6d65-4dc9-906a-a23e0787498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from my_util_package.evaluation import cluster_acc\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "\n",
    "subset = ['train', 'val'][0]\n",
    "modelf = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16')\n",
    "arch = 'vit_dino'\n",
    "\n",
    "\"\"\" load dataset \"\"\"\n",
    "transform_f = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "if subset == 'train':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=True, transform=transform_f, seed=1)\n",
    "elif subset == 'val':\n",
    "    dataset_f = get_datasets_oszsl(args, vocab, is_train=False, transform=transform_f, seed=1)\n",
    "args.nb_classes = dataset_f.num_classes\n",
    "loader_f = torch.utils.data.DataLoader(dataset_f, num_workers=8, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0a864-1216-410d-83c3-8442ba58cc8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline Classifier Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e010fc-ca2a-46cb-aca6-24b7fc442b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from MUST \"\"\"\n",
    "from clip.simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()\n",
    "\n",
    "def tokenize(texts: Union[str, List[str]], context_length: int = 77, truncate: bool = False) -> torch.LongTensor:\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
    "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
    "    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "    result = torch.zeros(len(all_tokens), context_length, dtype=torch.long)\n",
    "\n",
    "    for i, tokens in enumerate(all_tokens):\n",
    "        if len(tokens) > context_length:\n",
    "            if truncate:\n",
    "                tokens = tokens[:context_length]\n",
    "                tokens[-1] = eot_token\n",
    "            else:\n",
    "                raise RuntimeError(f\"Input {texts[i]} is too long for context length {context_length}\")\n",
    "        result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921a7ce-ded2-4d02-ae7f-a744f4d548c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load prompts and templates\n",
    "output_fpath = './cache/parsed-wn-gpt3-d-2023_02_26.json'\n",
    "with open(output_fpath, 'rb') as f:\n",
    "    all_parse_results = pickle.load(f)\n",
    "\n",
    "with open('../templates_small.json', 'rb') as f:\n",
    "    templates_small = json.load(f)['imagenet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc89912-bcfc-4ffe-a485-ca87a038a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "### synset and prompts\n",
    "text_inputs = {}\n",
    "for k, v in all_parse_results.items():\n",
    "    text_inputs[k] = [t.format(k.split('.')[0]) + f' {v}' for t in templates_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6d0b5-74a7-424a-a8a1-9d980d3b6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "### class name to synsets mapping\n",
    "class_name_key_mapping = {}\n",
    "for k in text_inputs:\n",
    "    class_name_key_mapping.setdefault(k.split('.')[0], [])\n",
    "    class_name_key_mapping[k.split('.')[0]].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4de6a-0da0-4545-b34f-8f14815fafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract prompt embeddings\n",
    "all_augmented_classifier = {}\n",
    "with tqdm(total=len(text_inputs)) as pbar:\n",
    "    for k, v in text_inputs.items():\n",
    "        aug_classifier = tokenize(v, truncate=True).to(args.device)\n",
    "        with torch.no_grad():\n",
    "            aug_classifier = model.encode_text(aug_classifier)\n",
    "        aug_classifier = aug_classifier/aug_classifier.norm(dim=-1, keepdim=True)\n",
    "        all_augmented_classifier[k] = aug_classifier.cpu()\n",
    "        \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba26ff-f2fb-41c2-aedc-1364b7057d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_classifier = {\n",
    "    'all_augmented_classifier': all_augmented_classifier,\n",
    "    'class_name_key_mapping': class_name_key_mapping,\n",
    "}\n",
    "torch.save(data_augmented_classifier, './cache/all_aug_prompts_embed-wn-gpt3-d-2023_02_26.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa61f051-f0e9-4f31-8b0c-8ba7fc2472a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### classifier statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981158e-b75a-43d4-aa6d-4f36fbf625dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load SCD results\n",
    "res = torch.load(f'./cache-{args.dataset_name}.pth')\n",
    "all_clu_pred = res['all_clu_pred']\n",
    "label_voc_kmeans = res['label_voc_kmeans']\n",
    "pred_kmeans_t = res['pred_kmeans_t']\n",
    "cluster_ind_voc = res['cluster_ind_voc']\n",
    "record_pred_kmeans_t = res['record_pred_kmeans_t']\n",
    "all_gt_voc = res['all_gt_voc']\n",
    "all_label_clu = res['all_label_clu']\n",
    "\n",
    "clip_store = torch.load(f'./cache/clip_store-{args.dataset_name}.pth')\n",
    "all_gt_label_voc = clip_store['all_gt_label_voc']\n",
    "all_gt_label_clu = clip_store['all_gt_label_clu']\n",
    "all_img_idx = clip_store['all_img_idx']\n",
    "all_features = clip_store['all_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd164501-06dc-44b1-92e6-c1be86cea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85009376-e8d3-4797-a7db-3ed4cef66322",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_all_topk_ind, classifier_all_topk_val = compute_knn_batch(classifier.to(args.device), \n",
    "                                                                     k=5, exclude_self=True, batch_size=512, \n",
    "                                                                     device=args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25305a39-9818-4fe0-a9c0-41fa3cda2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_all_topk_val.mean(dim=-1).mean(), classifier_all_topk_val.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ad7bc-e993-4838-a9e1-966fabb9b9a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in all_gt_label_voc.unique():\n",
    "    select = (all_gt_label_voc==c)\n",
    "    subset_features = torch.from_numpy(all_features[select]).to(args.device)\n",
    "    subset_features = subset_features/subset_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    target_classifier = classifier[c].to(args.device).view(1, -1)\n",
    "    target_classifier = target_classifier/target_classifier.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    sim_intra_img_text = subset_features@target_classifier.t()\n",
    "    print(sim_intra_img_text.mean())\n",
    "    \n",
    "    sim_intra = subset_features@subset_features.t()\n",
    "    mask = torch.ones_like(sim_intra)\n",
    "    mask = torch.scatter(mask, 1, torch.arange(mask.size(0), device=args.device).view(-1, 1), 0).bool()\n",
    "    intra_topk_ind, intra_topk_val = compute_knn_batch(subset_features.to(args.device), \n",
    "                                                       k=5, exclude_self=True, batch_size=512, \n",
    "                                                       device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5f084-6291-4662-a65d-28e17f8eacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_topk_ind, intra_topk_val = compute_knn_batch(torch.from_numpy(all_features).to(args.device), \n",
    "                                                   k=5, exclude_self=True, batch_size=512, \n",
    "                                                   device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44788174-d405-47f9-9a6d-2de1db63abf7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in all_gt_label_voc.unique():\n",
    "    select = (all_gt_label_voc==c)\n",
    "    class_features = torch.from_numpy(all_features)[select].to(args.device)\n",
    "    sim = class_features@class_features.t()\n",
    "    mask = torch.ones_like(sim)\n",
    "    mask = torch.scatter(mask, 1, torch.arange(mask.size(0), device=args.device).view(-1, 1), 0).bool()\n",
    "    print(sim[mask].mean(dim=-1).mean())\n",
    "    # intra_topk_ind, intra_topk_val = compute_knn_batch(torch.from_numpy(all_features)[select].to(args.device), \n",
    "    #                                                    k=5, exclude_self=True, batch_size=512, \n",
    "    #                                                    device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dfca8-c0a5-4bd7-9cd5-5579c80972ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_topk_val.mean(dim=-1).mean(), intra_topk_val.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49eb0d-8e63-40bc-94d3-18d1677cec09",
   "metadata": {},
   "source": [
    "### Method test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc0d97-0b29-418b-9bbe-947077fe1c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmented_classifier = torch.load('./cache/all_aug_prompts_embed-wn-gpt3-d-2023_02_26.pth')\n",
    "all_augmented_classifier = data_augmented_classifier['all_augmented_classifier']\n",
    "class_name_key_mapping = data_augmented_classifier['class_name_key_mapping']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c6430-8f89-45cc-8c30-f75caf92b879",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710c214-a68f-4c55-81b4-ddb2fd02724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = get_classifier(args)\n",
    "classifier = classifier/classifier.norm(dim=-1, keepdim=True)\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cb0cb-8ea6-430d-ae2b-5d5e68d8c8cd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_kmeans = torch.from_numpy(np.load(f'./pred_clu-{args.dataset_name}-train-clip.npy'))\n",
    "# all_clu_pred = agg_by_pred_cluster(args, pred_kmeans.numpy(), all_instance_voc_topk_ind, voc_size=args.num_voc)\n",
    "\n",
    "pred_kmeans_t = pred_kmeans\n",
    "history_set_pred = []\n",
    "for t in range(3):\n",
    "    record_pred_kmeans_t = pred_kmeans_t\n",
    "    all_clu_pred = agg_by_pred_cluster(args, pred_kmeans_t.numpy(), all_instance_voc_topk_ind, voc_size=args.num_voc)\n",
    "    label_voc_kmeans, res_ass = linear_assign(all_clu_pred, pred_kmeans_t, all_gt_label_voc)\n",
    "    pred_kmeans_t, cluster_ind_voc = reassign_by_pred_cluster(label_voc_kmeans, loader_f, model, classifier, args.device, all_prob=None)\n",
    "    set_pred = set(res_ass[1].tolist())\n",
    "    set_gt = set(all_gt_label_voc.unique().numpy().tolist())\n",
    "    print('missing label::', len(set_gt - set_pred))\n",
    "    print('cluster acc', cluster_acc(y_true=all_gt_label_clu.numpy(), y_pred=pred_kmeans_t.numpy()))\n",
    "    history_set_pred.append(set_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6616691-c6ee-4165-a0f4-71b5bed8a9be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for attributes in [\n",
    "    # 'texture and shape',\n",
    "    # 'shape and texture',\n",
    "    # 'color and shape',\n",
    "    # 'shape and color',\n",
    "    # 'components and color',\n",
    "    # 'color and components',\n",
    "    # 'components and texture',\n",
    "    # 'texture and components',\n",
    "    # 'components and shape',\n",
    "    # 'shape and components',\n",
    "    # 'texture and color',\n",
    "    'color and texture',\n",
    "    # 'components, shape, and color',\n",
    "    # 'shape, color, and components',\n",
    "    # 'color, components, and shape',\n",
    "    # 'components, color, and shape',\n",
    "    # 'shape, components, and color',\n",
    "    # 'color, shape, and components',\n",
    "]:\n",
    "    topK = 3\n",
    "    print(attributes)\n",
    "    cluster_topk_voc_ind = all_clu_pred.topk(k=topK).indices.cpu()\n",
    "    class_prediction = []\n",
    "    record_response = []\n",
    "    all_prompt_response = []\n",
    "    all_aug_classifiers = []\n",
    "    with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "        for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "            candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "            # candidates_def = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "            while 1:\n",
    "                try:\n",
    "                    prompt = get_prompt_candidate_discrimination_v4(candidates, attributes)\n",
    "                    response = request_gpt(prompt, model_name='text-davinci-003')\n",
    "                    response = list(filter(lambda x: len(x), response['choices'][0]['text'].lstrip('\\n').split('\\n')))\n",
    "                    # response = record_response[idx]\n",
    "                    aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "                    assert aug_classifiers.size(0)==topK\n",
    "                    all_prompt_response.append(response)\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(response)\n",
    "            \n",
    "            subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "            sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "            ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "            class_prediction.append(cluster_topk_voc_ind[idx, ind[count.argmax()]].item())\n",
    "            record_response.append(response)\n",
    "            all_aug_classifiers.append(aug_classifiers)\n",
    "            pbar.update(1)\n",
    "    class_prediction = torch.tensor(class_prediction)\n",
    "    all_aug_classifiers = torch.cat(all_aug_classifiers, dim=0)\n",
    "\n",
    "    N = pred_kmeans.size(0)\n",
    "    instance_assigned_pred = torch.zeros(N).long()\n",
    "    for c in record_pred_kmeans_t.unique():\n",
    "        select = (record_pred_kmeans_t==c)\n",
    "        instance_assigned_pred[select] = class_prediction[c]\n",
    "    print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "    print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c9bbc-b930-4709-ac72-ff316056a493",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "topK = 3\n",
    "cluster_topk_voc_ind = all_clu_pred.topk(k=topK).indices.cpu()\n",
    "class_prediction = []\n",
    "record_response = []\n",
    "all_prompt_response = []\n",
    "all_aug_classifiers = []\n",
    "with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "    for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "        ### parse candidate class names\n",
    "        candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:topK]]\n",
    "        ### get subset features\n",
    "        subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "        ### candidate index flag\n",
    "        curr_candidate_idx_1 = 0 ### head\n",
    "        curr_candidate_idx_2 = 1 ### tail\n",
    "        ### record\n",
    "        pair_prompts = []\n",
    "        while curr_candidate_idx_2<topK:\n",
    "            ### get pair prompts\n",
    "            prompt = get_prompt_candidate_discrimination_pair_caption(candidates, attributes, \n",
    "                                                              index=[curr_candidate_idx_1, curr_candidate_idx_2],\n",
    "                                                             )\n",
    "            ### record\n",
    "            pred_ind = []\n",
    "            pair_repeat_prompts = []\n",
    "            ### repeat\n",
    "            for _ in range(3):\n",
    "                while 1:\n",
    "                    try:\n",
    "                        response = request_gpt(prompt, model_name='text-davinci-003', max_tokens=200, temperature=0.7, best_of=1)\n",
    "                        response = list(filter(lambda x: len(x), response['choices'][0]['text'].lstrip('\\n').split('\\n')))\n",
    "                        aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "                        ### constraint\n",
    "                        assert aug_classifiers.size(0)==2\n",
    "                        ### record\n",
    "                        pair_repeat_prompts.append(response)\n",
    "                        all_aug_classifiers.append(aug_classifiers)\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        print(response)\n",
    "                sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "                ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "                pred_ind.append(ind[count.argmax()].item())\n",
    "            ind, count = torch.tensor(pred_ind).unique(return_counts=True)\n",
    "            curr_candidate_idx_1 = ind[count.argmax()] ### winner\n",
    "            curr_candidate_idx_2 = curr_candidate_idx_2 + 1\n",
    "            pair_prompts.append(pair_repeat_prompts)\n",
    "        ### results\n",
    "        class_prediction.append(cluster_topk_voc_ind[idx, curr_candidate_idx_1].item())\n",
    "        all_prompt_response.append(pair_prompts)\n",
    "        pbar.update(1)\n",
    "\n",
    "class_prediction = torch.tensor(class_prediction)\n",
    "all_aug_classifiers = torch.cat(all_aug_classifiers, dim=0)\n",
    "\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b161c6d-5e08-4ff1-bad3-eb181ef223da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save({'all_prompt_response': all_prompt_response}, f'./cache/all_prompt_response-{args.dataset_name}-pair.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae5a98-dce3-4218-9b40-1ec1bf55eda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### upperbound performance of cluster-wise assignment\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==c].unique(return_counts=True) \n",
    "    instance_assigned_pred[select] = ind_gt[count_gt.argmax()]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))\n",
    "### class recall performance of SCD topK predictions\n",
    "recall = []\n",
    "all_gtlbl = []\n",
    "for idx in range(len(cluster_topk_voc_ind)):\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "    gtlbl = ind_gt[count_gt.argmax()]\n",
    "    recall.append(torch.isin(gtlbl, cluster_topk_voc_ind[idx, :3]).item())\n",
    "    all_gtlbl.append(gtlbl)\n",
    "\n",
    "recall = torch.tensor(recall)\n",
    "all_gtlbl = torch.tensor(all_gtlbl)\n",
    "recall.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9ba57-99c0-4454-b59c-5d7cb72dabc3",
   "metadata": {},
   "source": [
    "entropy partition experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe30e24-2aba-4c6c-bade-cfd76666aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "# normalize_sum = lambda x: x/x.sum(dim=-1, keepdim=True)\n",
    "entropy = lambda p, a=1: -((a*p)*((a*p)+1e-20).log()).sum()\n",
    "record_true = []\n",
    "record_false = []\n",
    "cluster_topk_voc_val = (1 * all_clu_pred.topk(k=topK).values.cpu()).softmax(-1)\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==c].unique(return_counts=True) \n",
    "    if (ind_gt[count_gt.argmax()]==cluster_topk_voc_ind[c][0]).item():\n",
    "        record_true.append(cluster_topk_voc_val[c][0])\n",
    "        # record_true.append(entropy(cluster_topk_voc_val[c]))\n",
    "    else:\n",
    "        record_false.append(cluster_topk_voc_val[c][0])\n",
    "        # record_false.append(entropy(cluster_topk_voc_val[c]))\n",
    "    # break\n",
    "    \n",
    "plt.figure()\n",
    "sns.distplot(torch.tensor(record_true).numpy(), bins=100)\n",
    "sns.distplot(torch.tensor(record_false).numpy(), bins=100)\n",
    "plt.legend(['true', 'false'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec8ff0-6354-4893-aec8-48e73bce1e12",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.distplot(torch.tensor(record_true).numpy(), bins=100)\n",
    "sns.distplot(torch.tensor(record_false).numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50233f07-b299-483f-ae58-56348d589103",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cluster_topk_voc_val[:, 0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7f3e6-a244-4e24-8ca0-204032c7be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./all_prompt_response_v4-{args.dataset_name}.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_prompt_response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb788e-a3f1-4710-96fa-53b1cf668822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./all_prompt_response_v4-{args.dataset_name}.pkl', 'rb') as f:\n",
    "#     all_prompt_response = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7759d-ee9f-4ebc-b990-77fb0a72a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pred_idx_list = []\n",
    "for idx in range(len(cluster_topk_voc_ind)):\n",
    "    ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "    correct_pred = (ind_gt[count_gt.argmax()] == class_prediction[idx]).item()\n",
    "    if not correct_pred:\n",
    "        false_pred_idx_list.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82cfcd9-04e8-4b78-93e5-5843f2f47106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "idx = np.random.choice(false_pred_idx_list)\n",
    "# idx = idx + 1\n",
    "response = all_prompt_response[idx]\n",
    "aug_classifiers = build_classifier_from_prompt_response(args, model, response)\n",
    "subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).to(args.device)\n",
    "sim = subset_features.float() @ aug_classifiers.float().t()\n",
    "ind, count = sim.argmax(dim=-1).unique(return_counts=True)\n",
    "ind_gt, count_gt = all_gt_label_voc[record_pred_kmeans_t==idx].unique(return_counts=True) \n",
    "\n",
    "print(all_prompt_response[idx])\n",
    "print(f'ind={ind}, count={count}')\n",
    "print(f'cand={cluster_topk_voc_ind[idx]}, prev_pred={class_prediction[idx]}')\n",
    "print(f'pred={cluster_topk_voc_ind[idx,ind[count.argmax()]]}, gt={ind_gt[count_gt.argmax()]}')\n",
    "print('synset=', mapping_vocidx_to_synsets(ind_gt[count_gt.argmax()].item(), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd72f04-a8a6-437d-8d14-3047a16728f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    'components, shape, and color',\n",
    "    'shape, color, and components',\n",
    "    'color, components, and shape',\n",
    "    'components, color, and shape',\n",
    "    'shape, components, and color',\n",
    "    'color, shape, and components',\n",
    "]\n",
    "print(attributes)\n",
    "cluster_topk_voc_ind = all_clu_pred.topk(k=5).indices.cpu()\n",
    "class_prediction = []\n",
    "record_response = []\n",
    "all_prompt_response = []\n",
    "with tqdm(total=len(cluster_topk_voc_ind)) as pbar:\n",
    "    for idx, row in enumerate(cluster_topk_voc_ind):\n",
    "        candidates = [mapping_vocidx_to_synsets(x, vocab)[0].name().split('.')[0] for x in row.numpy()[:5]]\n",
    "        ensembled_response = []\n",
    "        ensembled_classifier = []\n",
    "        for a in attributes:\n",
    "            prompt = get_prompt_candidate_discrimination(candidates, attributes)\n",
    "            response = request_gpt(prompt, model_name='text-davinci-003')\n",
    "            response = response['choices'][0]['text'].lstrip('\\n\\n').split('\\n\\n')\n",
    "            aug_classifiers = build_classifier_from_prompt_response(args, model, response) ### K x D\n",
    "            ensembled_classifier.append(aug_classifiers)\n",
    "            ensembled_response.append(response)\n",
    "        all_prompt_response.append(ensembled_response)\n",
    "        \n",
    "        ### similarity average ensemble\n",
    "        subset_features = torch.from_numpy(all_features[record_pred_kmeans_t==idx]).float()#.to(args.device).float()\n",
    "        a_c = aug_classifiers.float().t().cpu()\n",
    "        ensembled_sim = []\n",
    "        for aug_classifiers in ensembled_classifier:\n",
    "            sim = 100 * subset_features @ a_c\n",
    "            ensembled_sim.append(sim)\n",
    "        ensembled_sim = torch.stack(ensembled_sim, dim=0).mean(dim=0) ### average\n",
    "        ind, count = ensembled_sim.argmax(dim=-1).unique(return_counts=True)\n",
    "        class_prediction.append(cluster_topk_voc_ind[idx, ind[count.argmax()]].item())\n",
    "        record_response.append(response)\n",
    "        pbar.update(1)\n",
    "class_prediction = torch.tensor(class_prediction)\n",
    "\n",
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())\n",
    "print('conflict', len(all_gt_label_voc.unique()) - len(instance_assigned_pred.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d990eb6-1b8d-4e9b-b430-7747915e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f./cache/request/equest/ensmbled_prompts-{args.dataset_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(all_prompt_response, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d87ae-867b-492a-831a-96278284c467",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_prompt_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44eee86-26fe-4714-a0ca-313dd4b57a1b",
   "metadata": {},
   "source": [
    "#### iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01df0d-958d-4ccd-befd-f057ab1dbe70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6300e4-132b-4f12-a676-a6ea37857ac0",
   "metadata": {},
   "source": [
    "#### misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b089e8-6c33-4ee0-8165-41c2f24c9a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = class_prediction[c]\n",
    "print('acc', (instance_assigned_pred==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402145b0-b7f5-4bfb-b4ec-c2be49f66007",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "instance_assigned_pred_scd = torch.zeros(N).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred_scd[select] = all_clu_pred[c].argmax(dim=-1)\n",
    "print('acc', (instance_assigned_pred_scd==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654442-2239-42e5-9395-eb2429f9404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_fn = (instance_assigned_pred!=all_gt_label_voc) & (instance_assigned_pred_scd==all_gt_label_voc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e9cda-a276-45e1-98c1-b58da5a4272b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('flip rate', (class_prediction == all_clu_pred.argmax(dim=-1)).float().mean())\n",
    "scd_names = np.array([mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_clu_pred.argmax(dim=-1)])\n",
    "updated_names = np.array([mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in class_prediction])\n",
    "\n",
    "np.array(record_response)[class_prediction!=all_clu_pred.argmax(dim=-1)].tolist(), \\\n",
    "updated_names[(scd_names!=updated_names)], scd_names[(scd_names!=updated_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd471dc-dcea-488b-9028-3d60d3fc4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc', (all_clu_pred.argmax(dim=-1)==all_gt_label_voc).float().mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8be80-212f-4494-ad71-e1a64827b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = pred_kmeans.size(0)\n",
    "K = prob_k\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=5).indices\n",
    "\n",
    "print('acc', (instance_assigned_pred[:, 0]==all_gt_label_voc).float().mean().item())\n",
    "print('acc instance topk', (torch.from_numpy(all_instance_voc_topk_ind)[:, 0]==all_gt_label_voc).float().mean().item())\n",
    "retrieved_labels = instance_assigned_pred[instance_assigned_pred[:, 0]==all_gt_label_voc][:, 0].unique().numpy()\n",
    "pred_labels = instance_assigned_pred[:, 0].unique().numpy()\n",
    "gt_labels = all_gt_label_voc.unique().numpy()\n",
    "print(f'missing label of retrieval:: {len(set(gt_labels) - set(retrieved_labels))}')\n",
    "print(f'missing label of predict:: {len(set(gt_labels) - set(pred_labels))}')\n",
    "for k in range(1, K):\n",
    "    retrieved_labels_topk = instance_assigned_pred[instance_assigned_pred[:, 0]==all_gt_label_voc][:, :k].flatten().unique().numpy()\n",
    "    print(f'missing label of retieval at k={k}:: {len(set(gt_labels) - set(retrieved_labels_topk))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64614ea-8231-4ca1-aaf3-04cae70f776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_instance_topk = row_wise_isin(all_gt_label_voc, torch.from_numpy(all_instance_voc_topk_ind))\n",
    "\n",
    "isin_instance_topk.float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37ffd9-10cf-4b87-b9f7-89cb3471951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isin_instance_topk = row_wise_isin(all_gt_label_voc, instance_assigned_pred)\n",
    "isin_instance_topk.float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fb3425-be2f-497f-8647-69bb95942c93",
   "metadata": {},
   "source": [
    "instance based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae00b29-38ba-446f-aefe-532782fbb6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instance_voc_topk_ind\n",
    "\n",
    "candidate_names = \n",
    "compute_similarity_with_augmented_classifier(features, candidate_names, \n",
    "                                             class_name_key_mapping, all_augmented_classifier, \n",
    "                                             method='ensemble', agg_func=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44f6783-ef4e-45ed-b623-c27992cc4d84",
   "metadata": {},
   "source": [
    "cluster based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c8500-d3c7-4a61-a87e-9332efcc9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = record_pred_kmeans_t.size(0)\n",
    "K = prob_k\n",
    "instance_assigned_pred = torch.zeros([N, K]).long()\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    select = (record_pred_kmeans_t==c)\n",
    "    instance_assigned_pred[select] = all_clu_pred[c].topk(k=10).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b380c5-a65a-4f05-9983-5195b6e9a1fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "all_sample_ind = []\n",
    "with tqdm(total=all_features.shape[0]) as pbar:\n",
    "    for i in range(all_features.shape[0]):\n",
    "        img_feature = torch.from_numpy(all_features[i])#.to(args.device)\n",
    "        candidate_names = [mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] \n",
    "                           for x in instance_assigned_pred[i, :3]]\n",
    "        max_k = \\\n",
    "            compute_similarity_with_augmented_classifier(img_feature, candidate_names, \n",
    "                                                         class_name_key_mapping, all_augmented_classifier, \n",
    "                                                         method='ensemble', agg_func=np.mean, return_indices=True)\n",
    "        idx_max = candidate_names.index(max_k)\n",
    "        \n",
    "        all_sample_ind.append(idx_max)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "all_sample_ind = torch.tensor(all_sample_ind)\n",
    "baseline_instance_pred = instance_assigned_pred.gather(1, all_sample_ind.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c3f47-69b1-4e45-99ec-e5053c6233bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_instance_pred.flatten() == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7c61a-0dc3-4e57-bd73-131e028a32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(instance_assigned_pred[:, 0] == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe399f5-e538-4d0a-9b5a-d9e2b3028338",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_names, max_k, mapping_vocidx_to_synsets(all_gt_label_voc[i].item(), vocab), \\\n",
    "baseline_instance_pred[-1], all_gt_label_voc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92846901-17b1-4da1-9f38-c35ec002db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_instance_pred = baseline_instance_pred.flatten()\n",
    "baseline_instance_pred_clu = torch.zeros_like(baseline_instance_pred)\n",
    "for c in record_pred_kmeans_t.unique():\n",
    "    val, count = baseline_instance_pred[record_pred_kmeans_t==c].unique(return_counts=True)\n",
    "    baseline_instance_pred_clu[record_pred_kmeans_t==c] = val[count.argmax(dim=-1)].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ceb35-6d5d-4d5e-9875-2808b74894ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "(baseline_instance_pred_clu == all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa10391-ea9d-40f1-acf0-f47e1fdf56ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### reranked KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39be754-2a0d-42d5-a8ed-81a642a88350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" compute top-20 predictions \"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca48837-88e5-439a-b4a0-e4c693a127a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "N = all_instance_voc_topk_ind.shape[0]\n",
    "all_instance_voc_topk_ind_rerank = torch.zeros(N, K).long()\n",
    "with tqdm(total=N) as pbar:\n",
    "    for i in range(all_features.shape[0]):\n",
    "        feature = torch.from_numpy(all_features[i])\n",
    "        candidate_names = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_instance_voc_topk_ind[i, :3] ]\n",
    "        topk_candidate_voc_ind = \\\n",
    "        compute_similarity_with_augmented_classifier(feature, candidate_names, \n",
    "                                                     class_name_key_mapping, all_augmented_classifier, \n",
    "                                                     method='ensemble', agg_func=max, return_type='topk', k=K)\n",
    "        all_instance_voc_topk_ind_rerank[i] = torch.tensor([ vocab.mapping_names_idx[x] for x in topk_candidate_voc_ind ])\n",
    "        pbar.update(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6049d-fdb0-495f-8b23-24720c278dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.permutation(N)[0]\n",
    "feature = torch.from_numpy(all_features[i])\n",
    "candidate_names = [ mapping_vocidx_to_synsets(x.item(), vocab)[0].name().split('.')[0] for x in all_instance_voc_topk_ind[i] ]\n",
    "topk_candidate_voc_ind = \\\n",
    "compute_similarity_with_augmented_classifier(feature, candidate_names, \n",
    "                                             class_name_key_mapping, all_augmented_classifier, \n",
    "                                             method='ensemble', agg_func=max, return_type='topk', k=5)\n",
    "all_instance_voc_topk_ind_rerank[i] = torch.tensor([ vocab.mapping_names_idx[x] for x in topk_candidate_voc_ind ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac0558-2e4a-42d9-8ff6-2f0066ff7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_instance_voc_topk_ind_rerank[:, 0]==all_gt_label_voc).float().mean(), \\\n",
    "(torch.from_numpy(all_instance_voc_topk_ind)[:, 0]==all_gt_label_voc).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970564f-36dd-4efa-9c57-d91e09681d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, d = compute_similarity_with_augmented_classifier(torch.rand(512), ['cat', 'dog', 'frog', 'shirt', 'man', 'swarm', 'liquid'], \n",
    "                                                 class_name_key_mapping, all_augmented_classifier, \n",
    "                                                 method='ensemble', agg_func=max, return_type='topk', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3821e-c7b7-4764-8a61-a40698ed997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fpath = './cache/parsed-wn-gpt3-d-2023_02_26.json'\n",
    "with open(output_fpath, 'rb') as f:\n",
    "    all_parse_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a2b64-3e17-4025-9542-46213959d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_vocidx_to_synsets(all_gt_label_voc[i].item(), vocab)[0].name(), \\\n",
    "topk_candidate_voc_ind, \\\n",
    "[mapping_vocidx_to_synsets(x, vocab)[0].name() for x in all_instance_voc_topk_ind[i][:5]], \\\n",
    "[ all_parse_results[mapping_vocidx_to_synsets(x, vocab)[0].name()] for x in all_instance_voc_topk_ind[i][:5] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fb4f2-518b-461d-b14b-784b2354fb96",
   "metadata": {},
   "source": [
    "#### basic observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196adeb7-7e2d-4061-927f-0fad8c484f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" compute top-20 predictions \"\"\"\n",
    "args.num_voc = classifier.size(0)\n",
    "amp_autocast = torch.cuda.amp.autocast\n",
    "### collect variables\n",
    "prob_k = 5\n",
    "all_instance_voc_topk_ind = []\n",
    "all_gt_label_voc = []\n",
    "all_gt_label_clu = []\n",
    "all_features = []\n",
    "with tqdm(total=len(loader_f)) as pbar:\n",
    "    if hasattr(model, 'eval'):\n",
    "        model.eval()\n",
    "    for idx_batch, batch in enumerate(loader_f):\n",
    "        images, label_voc, label_clu, idx_img = batch[:4]\n",
    "        images = images.to(args.device)\n",
    "        with amp_autocast():\n",
    "            with torch.no_grad():\n",
    "                logits = model.visual(images)\n",
    "                logits = logits/logits.norm(dim=-1, keepdim=True)\n",
    "                similarity = 100 * logits @ classifier.t()\n",
    "                prob = similarity.softmax(-1)\n",
    "                prob_topk_ind = prob.topk(k=prob_k, dim=-1).indices\n",
    "                all_instance_voc_topk_ind.append(prob_topk_ind.cpu().numpy())\n",
    "                all_gt_label_voc.append(label_voc)\n",
    "                all_gt_label_clu.append(label_clu)\n",
    "                all_features.append(logits.cpu().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "all_instance_voc_topk_ind = np.concatenate(all_instance_voc_topk_ind)\n",
    "all_gt_label_voc = torch.cat(all_gt_label_voc, dim=0)\n",
    "all_gt_label_clu = torch.cat(all_gt_label_clu, dim=0)\n",
    "all_features = np.concatenate(all_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "gcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
