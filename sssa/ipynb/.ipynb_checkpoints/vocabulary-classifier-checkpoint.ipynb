{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18df8d4-c384-4612-95e2-3904a7dc2b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheng/anaconda3/envs/gcd/lib/python3.8/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.11) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "# sys.path.append('/home/sheng/sssa/CLIP/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from functools import reduce, partial\n",
    "from itertools import zip_longest\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from wordnet_utils import *\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "\n",
    "from ipynb_utils import get_hier_datasets, get_classifier, MCMF_assign_labels\n",
    "# import clip\n",
    "import model as clip\n",
    "from data.datasets import build_transform, get_hier_datasets, Vocab\n",
    "from data.imagenet_datasets import get_datasets_oszsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f61465e-e31f-4411-a661-ac47fe751312",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torchvision.datasets.Food101(root='/home/sheng/dataset/food/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9317fcd7-2386-46cb-90fa-dc4de5e9c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torchvision.datasets.OxfordIIITPet(root='/home/sheng/dataset/pet', split='trainval', target_types='category', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4831053-3698-41db-9d11-9db5fa30f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('/home/sheng/dataset/flowers/flowers-102/setid.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95281b5f-cfe7-4e88-af58-fa70256cb355",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abyssinian': 0,\n",
       " 'American Bulldog': 1,\n",
       " 'American Pit Bull Terrier': 2,\n",
       " 'Basset Hound': 3,\n",
       " 'Beagle': 4,\n",
       " 'Bengal': 5,\n",
       " 'Birman': 6,\n",
       " 'Bombay': 7,\n",
       " 'Boxer': 8,\n",
       " 'British Shorthair': 9,\n",
       " 'Chihuahua': 10,\n",
       " 'Egyptian Mau': 11,\n",
       " 'English Cocker Spaniel': 12,\n",
       " 'English Setter': 13,\n",
       " 'German Shorthaired': 14,\n",
       " 'Great Pyrenees': 15,\n",
       " 'Havanese': 16,\n",
       " 'Japanese Chin': 17,\n",
       " 'Keeshond': 18,\n",
       " 'Leonberger': 19,\n",
       " 'Maine Coon': 20,\n",
       " 'Miniature Pinscher': 21,\n",
       " 'Newfoundland': 22,\n",
       " 'Persian': 23,\n",
       " 'Pomeranian': 24,\n",
       " 'Pug': 25,\n",
       " 'Ragdoll': 26,\n",
       " 'Russian Blue': 27,\n",
       " 'Saint Bernard': 28,\n",
       " 'Samoyed': 29,\n",
       " 'Scottish Terrier': 30,\n",
       " 'Shiba Inu': 31,\n",
       " 'Siamese': 32,\n",
       " 'Sphynx': 33,\n",
       " 'Staffordshire Bull Terrier': 34,\n",
       " 'Wheaten Terrier': 35,\n",
       " 'Yorkshire Terrier': 36}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f80bfc6a-42b3-4309-aaa1-24e09bcad72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Food101(torchvision.datasets.Food101):\n",
    "    def __init__(self, root, split='train', transform=None, vocab=None, **kwargs):\n",
    "        super(Food101, self).__init__(root=root, split=split, transform=transform, **kwargs)\n",
    "        self.vocab = vocab\n",
    "        self.uq_idxs = np.array(range(len(self)))\n",
    "        self.classes = dict([(self.class_to_idx[c], c.lower()) for c in self.classes])\n",
    "        self.ssl_cluster = None\n",
    "        self.ad_weight = None\n",
    "        print(set(self._labels))\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, label_clu = super().__getitem__(item)\n",
    "        label_voc = self.classes[label_clu]\n",
    "        idx_img = self.uq_idxs[item]\n",
    "        result = [img, label_voc, label_clu, idx_img]\n",
    "        if self.ssl_cluster is not None:\n",
    "            result.append(self.ssl_cluster[idx])\n",
    "        if self.ad_weight is not None:\n",
    "            result.append(self.ad_weight[idx])\n",
    "        return result\n",
    "\n",
    "    \n",
    "class OxfordIIITPet(torchvision.datasets.OxfordIIITPet):\n",
    "    def __init__(self, root, split='trainval', transform=None, vocab=None, **kwargs):\n",
    "        super(OxfordIIITPet, self).__init__(root=root, split=split, transform=transform, **kwargs)\n",
    "        self.vocab = vocab\n",
    "        self.uq_idxs = np.array(range(len(self)))\n",
    "        self.classes = dict([(self.class_to_idx[c], c.lower()) for c in self.classes])\n",
    "        self.ssl_cluster = None\n",
    "        self.ad_weight = None\n",
    "        print(set(self._labels))\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, label_clu = super().__getitem__(item)\n",
    "        label_voc = self.classes[label_clu]\n",
    "        idx_img = self.uq_idxs[item]\n",
    "        result = [img, label_voc, label_clu, idx_img]\n",
    "        if self.ssl_cluster is not None:\n",
    "            result.append(self.ssl_cluster[idx])\n",
    "        if self.ad_weight is not None:\n",
    "            result.append(self.ad_weight[idx])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b641c0-6520-4a79-a736-479069ac9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_lvis_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/lvis_imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c406ad9-3f8e-472d-8b37-e91f8e5dfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from lvis import LVIS\n",
    "\n",
    "class LVISDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, split, transform=None, \n",
    "                 pad_ratio=0.2, pad_min=15, pad_max=20, vocab=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.pad_ratio = pad_ratio\n",
    "        self.pad_min = pad_min\n",
    "        self.pad_max = pad_max\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.ann_fpath = os.path.join(self.root_dir, f'lvis_v1_{split}.json')\n",
    "        self.lvis = LVIS(self.ann_fpath)\n",
    "        self.img_ids = self.lvis.get_img_ids()\n",
    "        self.all_img_ids = None\n",
    "        self.all_ann_ids = None\n",
    "        self.all_synset_ids = None\n",
    "        self.compute_img_ids_and_ann_ids()\n",
    "        extract_name = lambda y: list(map(lambda x: x.split('.')[0], y))\n",
    "        self.mapping_labels_clu = dict(zip(\n",
    "            list(set(extract_name(self.all_synset_ids))), \n",
    "            range(len(set(extract_name(self.all_synset_ids))))\n",
    "        ))\n",
    "        if self.vocab is not None:\n",
    "            self.mapping_labels_voc = dict(zip(\n",
    "                list(set(extract_name(self.all_synset_ids))),\n",
    "                map(lambda x: self.vocab.mapping_names_idx[x], list(set(extract_name(self.all_synset_ids))))\n",
    "            ))\n",
    "        else:\n",
    "            self.mapping_labels_voc = None\n",
    "        return \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lvis.get_ann_ids(img_ids=self.img_ids))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id, ann_id, synset = self.all_img_ids[index], self.all_ann_ids[index], self.all_synset_ids[index]\n",
    "        ### load img\n",
    "        img_info = self.lvis.load_imgs([img_id])[0]['coco_url'].split('/')[-1]\n",
    "        img_path = os.path.join(self.root_dir, self.split+'2017', img_info)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # Get the bounding box and category information\n",
    "        ann = self.lvis.load_anns([ann_id])[0]\n",
    "        [left, top, width, height] = ann['bbox']\n",
    "        label = ann['category_id']\n",
    "\n",
    "        # Crop the image according to the bounding box\n",
    "        cropped_img = img.crop([\n",
    "            max(0, left-max(self.pad_min, min(self.pad_max, self.pad_ratio*width))), \n",
    "            max(0, top-max(self.pad_min, min(self.pad_max, self.pad_ratio*height))), \n",
    "            min(img.size[0], left+width+max(self.pad_min, min(self.pad_max, self.pad_ratio*width))), \n",
    "            min(img.size[1], top+height+max(self.pad_min, min(self.pad_max, self.pad_ratio*height))),\n",
    "        ])\n",
    "\n",
    "        if self.transform:\n",
    "            cropped_img = self.transform(cropped_img)\n",
    "        \n",
    "        label_clu = self.mapping_labels_clu[synset.split('.')[0]]\n",
    "        if self.vocab is not None:\n",
    "            label_voc = self.mapping_labels_voc[synset.split('.')[0]]\n",
    "        else:\n",
    "            label_voc = None\n",
    "        idx_img = index\n",
    "        result = [cropped_img, label_voc, label_clu, idx_img]\n",
    "        return result\n",
    "\n",
    "    def compute_img_ids_and_ann_ids(self):\n",
    "        all_img_ids = []\n",
    "        all_ann_ids = []\n",
    "        all_synset_ids = []\n",
    "        for img_id in self.img_ids:\n",
    "            ann_ids = self.lvis.get_ann_ids(img_ids=[img_id])\n",
    "            anns = self.lvis.load_anns(ann_ids)\n",
    "            cat_ids = list(map(lambda x: x['category_id'], anns))\n",
    "            synsets = list(map(lambda x: x['synset'], self.lvis.load_cats(cat_ids)))\n",
    "            all_ann_ids.extend(ann_ids)\n",
    "            all_img_ids.extend([img_id for _ in range(len(ann_ids))])\n",
    "            all_synset_ids.extend(synsets)\n",
    "        self.all_img_ids = all_img_ids\n",
    "        self.all_ann_ids = all_ann_ids\n",
    "        self.all_synset_ids = all_synset_ids\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2c5539-9963-47a2-a1dd-0f23103fa92b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = read_imagenet21k_classes() + os.listdir('/home/sheng/dataset/imagenet-img/')\n",
    "classes = [wn.synset_from_pos_and_offset('n', int(x[1:])).name() for x in classes]\n",
    "classes = set(classes)\n",
    "\n",
    "d = LVISDataset(root_dir='/home/sheng/dataset/LVIS', split='train', transform=None, \n",
    "                pad_ratio=0.2, pad_min=30, pad_max=40)\n",
    "classes_lvis = set(d.all_synset_ids)\n",
    "\n",
    "combined_classes = classes | classes_lvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6449b6-b580-4364-b245-2ab27387cd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21844, 1203, 22049)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes), len(classes_lvis), len(classes | classes_lvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415fafc7-bbf2-4be9-b949-37399d22a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20071 20223\n"
     ]
    }
   ],
   "source": [
    "to_name = lambda x: list(set([item.split('.')[0] for item in x]))\n",
    "\n",
    "name_classes = to_name(classes)\n",
    "name_combined_classes = to_name(combined_classes)\n",
    "\n",
    "print(len(name_classes), len(name_combined_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "18103b74-ddad-479b-82c2-d2400ad66818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./cache/vocabulary/vocab_dataset=1.pkl', 'wb') as f:\n",
    "#     pickle.dump(name_classes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca24799-8652-4e2a-9c3a-1927b242cec3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48126f8c-e021-43a2-b687-7ef0e4979634",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = CIFAR100(root='/home/sheng/dataset/CIFAR100/', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5549aabe-03ac-46e7-8dc3-22751b941bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_mapping_cifar100 = {\n",
    "#     'aquarium_fish': 'freshwater_fish.n.01',\n",
    "#     'boy': 'male_child.n.01',\n",
    "#     'dinosaur': 'dinosaur.n.01',\n",
    "#     'maple_tree': 'maple.n.02',\n",
    "#     'oak_tree': 'oak.n.02',\n",
    "#     'palm_tree': 'palm.n.03',\n",
    "#     'pickup_truck': 'minivan.n.01',\n",
    "#     'pine_tree': 'pine.n.01',\n",
    "#     'possum': 'opossum.n.02',\n",
    "#     'sea': 'sea.n.03',\n",
    "#     'willow_tree': 'willow.n.01',\n",
    "# }\n",
    "\n",
    "category_mapping_cifar100 = {\n",
    "    'aquarium_fish': 'freshwater_fish',\n",
    "    'boy': 'male_child',\n",
    "    'dinosaur': 'dinosaur',\n",
    "    'maple_tree': 'maple',\n",
    "    'oak_tree': 'oak',\n",
    "    'palm_tree': 'palm',\n",
    "    'pickup_truck': 'minivan',\n",
    "    'pine_tree': 'pine',\n",
    "    'possum': 'opossum',\n",
    "    'sea': 'sea',\n",
    "    'willow_tree': 'willow',\n",
    "}\n",
    "\n",
    "categories = []\n",
    "for c in d.classes:\n",
    "    if c not in category_mapping_cifar100.keys():\n",
    "        categories.append(c)\n",
    "    else:\n",
    "        categories.append(category_mapping_cifar100[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "509b57be-8f5a-4a27-a966-f893f06b22ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in d.classes:\n",
    "#     if (len(wn.synsets(c))) and (not wn.synsets(c)[0].name().split('.')[0]==c):\n",
    "#         print(c, wn.synsets(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7320636e-062b-4742-8168-829160b55570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_synsets(x):\n",
    "    print()\n",
    "    y = wn.synsets(x)\n",
    "    for yy in y:\n",
    "        if '.n.' in yy.name():\n",
    "            print(yy.name(), yy.definition())\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fa6680-7809-4c00-b2ea-9fd2088bec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20076\n"
     ]
    }
   ],
   "source": [
    "name_classes = list(set(name_classes + categories))\n",
    "print(len(name_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a2653-b3d5-421c-90e9-df27e0eb2d29",
   "metadata": {},
   "source": [
    "### caltech101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bfe50aa-5255-4b37-969d-8718674ffbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = os.listdir('/home/sheng/dataset/Caltech101/caltech-101/caltech101/101_ObjectCategories/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9bc68d-b813-4e86-94f8-4e5bd7b9e58c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# category_mapping_caltech101 = {\n",
    "#     'brontosaurus': 'apatosaur',\n",
    "#     'car_side': 'car',\n",
    "#     'cougar_body': 'cougar',\n",
    "#     'faces': 'face',\n",
    "#     'stop_sign': 'sign',\n",
    "#     'water_lilly': 'nymphaea',\n",
    "#     'saxophone': 'sax',\n",
    "#     'leopards': 'leopard',\n",
    "#     'rooster': 'cock',\n",
    "#     'crocodile_head': 'crocodile',\n",
    "#     'wild_cat': 'wildcat',\n",
    "#     'hawksbill': 'hawksbill_turtle',\n",
    "#     'ceiling_fan': 'electric_fan',\n",
    "#     'ewer': 'pitcher',\n",
    "#     'inline_skate': 'roller_skate',\n",
    "#     'dollar_bill': 'dollar',\n",
    "#     'airplanes': 'airplane',\n",
    "#     'sea_horse': 'seahorse',\n",
    "#     'headphone': 'earphone',\n",
    "#     'panda': 'giant_panda',\n",
    "#     'cougar_face': 'cougar',\n",
    "#     'faces_easy': 'face',\n",
    "#     'motorbikes': 'motorbike',\n",
    "#     'rhino': 'rhinoceros',\n",
    "#     'stegosaurus': 'stegosaur',\n",
    "#     'cellphone ': 'cellular_telephone',\n",
    "# }\n",
    "\n",
    "# for c in categories:\n",
    "#     if (len(wn.synsets(c))) and (not wn.synsets(c)[0].name().split('.')[0]==c):\n",
    "#         if c.lower() not in category_mapping_caltech101:\n",
    "#             print(c, wn.synsets(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00f64c9d-a457-4391-a94c-aea4beac8ded",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# category_mapping_caltech101 = {\n",
    "#     'brontosaurus': 'apatosaur.n.01',\n",
    "#     'car_side': 'car.n.01',\n",
    "#     'cougar_body': 'cougar.n.01',\n",
    "#     'faces': 'face.n.01',\n",
    "#     'stop_sign': 'sign.n.02',\n",
    "#     'water_lilly': 'nymphaea.n.01',\n",
    "#     'saxophone': 'sax.n.02',\n",
    "#     'leopards': 'leopard.n.02',\n",
    "#     'rooster': 'cock.n.04',\n",
    "#     'crocodile_head': 'crocodile.n.01',\n",
    "#     'wild_cat': 'wildcat.n.03',\n",
    "#     'hawksbill': 'hawksbill_turtle.n.01',\n",
    "#     'ceiling_fan': 'electric_fan.n.01',\n",
    "#     'ewer': 'pitcher.',\n",
    "#     'inline_skate': 'roller_skate',\n",
    "#     'dollar_bill': 'dollar',\n",
    "#     'airplanes': 'airplane',\n",
    "#     'sea_horse': 'seahorse',\n",
    "#     'headphone': 'earphone',\n",
    "#     'panda': 'giant_panda',\n",
    "#     'cougar_face': 'cougar',\n",
    "#     'faces_easy': 'face',\n",
    "#     'motorbikes': 'motorbike',\n",
    "#     'rhino': 'rhinoceros',\n",
    "#     'stegosaurus': 'stegosaur',\n",
    "# }\n",
    "category_mapping_caltech101 = {\n",
    "    'brontosaurus': 'apatosaur',\n",
    "    'car_side': 'car',\n",
    "    'cougar_body': 'cougar',\n",
    "    'faces': 'face',\n",
    "    'stop_sign': 'sign',\n",
    "    'water_lilly': 'nymphaea',\n",
    "    'saxophone': 'sax',\n",
    "    'leopards': 'leopard',\n",
    "    'rooster': 'cock',\n",
    "    'crocodile_head': 'crocodile',\n",
    "    'wild_cat': 'wildcat',\n",
    "    'hawksbill': 'hawksbill_turtle',\n",
    "    'ceiling_fan': 'electric_fan',\n",
    "    'ewer': 'pitcher',\n",
    "    'inline_skate': 'roller_skate',\n",
    "    'dollar_bill': 'dollar',\n",
    "    'airplanes': 'airplane',\n",
    "    'sea_horse': 'seahorse',\n",
    "    'headphone': 'earphone',\n",
    "    'panda': 'giant_panda',\n",
    "    'cougar_face': 'cougar',\n",
    "    'faces_easy': 'face',\n",
    "    'motorbikes': 'minibike',\n",
    "    'rhino': 'rhinoceros',\n",
    "    'stegosaurus': 'stegosaur',\n",
    "    'cellphone': 'cellular_telephone',\n",
    "    'flamingo_head': 'flamingo',\n",
    "    'binocular': 'binoculars',\n",
    "}\n",
    "category_remove_caltech101 = ['yin_yang', 'background_google']\n",
    "new_categories = []\n",
    "for c in categories:\n",
    "    c = c.lower()\n",
    "    if c in category_remove_caltech101:\n",
    "        continue\n",
    "    elif c not in category_mapping_caltech101.keys():\n",
    "        new_categories.append(c)\n",
    "    else:\n",
    "        new_categories.append(category_mapping_caltech101[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4bd03f9-ed30-4228-b3f4-e193c01b0f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brontosaurus [Synset('apatosaur.n.01')]\n",
      "Faces [Synset('face.n.01'), Synset('expression.n.01'), Synset('face.n.03'), Synset('face.n.04'), Synset('face.n.05'), Synset('side.n.04'), Synset('face.n.07'), Synset('face.n.08'), Synset('grimace.n.01'), Synset('font.n.01'), Synset('face.n.11'), Synset('boldness.n.02'), Synset('face.n.13'), Synset('confront.v.02'), Synset('confront.v.01'), Synset('front.v.01'), Synset('face.v.04'), Synset('face.v.05'), Synset('confront.v.03'), Synset('face.v.07'), Synset('face.v.08'), Synset('face.v.09')]\n",
      "saxophone [Synset('sax.n.02')]\n",
      "Leopards [Synset('leopard.n.01'), Synset('leopard.n.02')]\n",
      "rooster [Synset('cock.n.04')]\n",
      "hawksbill [Synset('hawksbill_turtle.n.01')]\n",
      "binocular [Synset('binocular.a.01')]\n",
      "ewer [Synset('pitcher.n.02')]\n",
      "dollar_bill [Synset('dollar.n.02')]\n",
      "airplanes [Synset('airplane.n.01')]\n",
      "sea_horse [Synset('walrus.n.01'), Synset('seahorse.n.02')]\n",
      "headphone [Synset('earphone.n.01')]\n",
      "panda [Synset('giant_panda.n.01'), Synset('lesser_panda.n.01')]\n",
      "Motorbikes [Synset('minibike.n.01'), Synset('motorbike.v.01')]\n",
      "rhino [Synset('rhinoceros.n.01')]\n",
      "stegosaurus [Synset('stegosaur.n.01')]\n",
      "cellphone [Synset('cellular_telephone.n.01')]\n"
     ]
    }
   ],
   "source": [
    "for c in categories:\n",
    "    if (len(wn.synsets(c))==0) and (c.lower() not in category_mapping_caltech101.keys()) and (c.lower() not in category_remove_caltech101):\n",
    "        print(c)\n",
    "    \n",
    "    elif len(wn.synsets(c)):\n",
    "        cand = list(filter(lambda x: (x.name().split('.')[1]=='n') and (x.name().split('.')[0]==c.lower()), wn.synsets(c)))\n",
    "        if len(cand)==0:\n",
    "            print(c, wn.synsets(c))\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb00e9a1-2577-48f6-8245-7fd02484df50",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20079\n"
     ]
    }
   ],
   "source": [
    "name_classes = list(set(name_classes + new_categories))\n",
    "print(len(name_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d21af671-3d54-4c5b-ade9-b305f00a1a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20079\n"
     ]
    }
   ],
   "source": [
    "### lvis\n",
    "# name_combined_classes = list(set(name_combined_classes + name_classes))\n",
    "name_combined_classes = name_classes\n",
    "print(len(name_combined_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c157a8-4bcd-4d31-a711-56b4047325b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cache/vocabulary/vocab_dataset=2+lvis_20232.pkl', 'wb') as f:\n",
    "    pickle.dump(name_combined_classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61d5531e-270e-4fc1-b657-2889bbb2119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./cache/vocabulary/vocab_dataset=2_20079.pkl', 'wb') as f:\n",
    "    pickle.dump(name_combined_classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0a184d-7dce-419d-ae78-30ed129ffee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./cache/vocabulary/vocab_dataset=3_20088.pkl', 'wb') as f:\n",
    "#     pickle.dump(name_combined_classes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7516101b-98dd-4e4d-8e9f-e8fce07138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./cache/vocabulary/vocab_dataset=3+lvis_20239.pkl', 'wb') as f:\n",
    "#     pickle.dump(name_combined_classes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "gcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
