{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59416be7-90a8-4415-bf80-9194dc399904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "sys.path.append('/home/sheng/sssa/')\n",
    "# sys.path.append('/home/sheng/sssa/CLIP/')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from functools import reduce, partial\n",
    "from itertools import zip_longest\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "from wordnet_utils import *\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.folder import default_loader\n",
    "\n",
    "from ipynb_utils import get_hier_datasets, get_classifier, MCMF_assign_labels\n",
    "# import clip\n",
    "import model as clip\n",
    "from data.datasets import build_transform, get_hier_datasets, Vocab\n",
    "from data.imagenet_datasets import get_datasets_oszsl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af98d67a-bfff-4c0d-918b-f5dddb4e5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = 'cuda:1'\n",
    "    arch = 'ViT-B/16'\n",
    "    dataset = 'make_entity13'\n",
    "    n_sampled_classes = 100\n",
    "    input_size = 224\n",
    "    estimate_k = 252\n",
    "    \n",
    "    batch_size = 512\n",
    "    use_def = False\n",
    "    clip_checkpoint = None\n",
    "    # clip_checkpoint = '/home/sheng/MUST-output/make_nonliving26/baseline-04_22_1/checkpoint-current.pth'\n",
    "    # clip_checkpoint = '/home/sheng/MUST-output/make_nonliving26/chatgpt_init-warmup=2/checkpoint-current.pth'\n",
    "    f_classifier = './cache/wordnet_classifier_in21k_word.pth'\n",
    "    templates_name = 'templates_small'\n",
    "    seed = 0\n",
    "    \n",
    "args = Config()\n",
    "\n",
    "def load_templates(args):\n",
    "    with open(f'../{args.templates_name}.json', 'rb') as f:\n",
    "        templates = json.load(f)['imagenet']\n",
    "    return templates\n",
    "\n",
    "def get_vocab():\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        vocab: {`names`: list, `ids`: synset ids, `parents`: [{synset ids}]}\n",
    "    \"\"\"\n",
    "    with open('/home/sheng/dataset/wordnet_nouns_with_synset_4.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "    return vocab\n",
    "\n",
    "def get_subsample_vocab(sample_synset_id: set):\n",
    "    vocab = get_vocab()\n",
    "    index = np.array([ i for i in range(len(vocab['synsets'])) if vocab['synsets'][i] in sample_synset_id ]).astype(np.int32)\n",
    "    for k in vocab.keys():\n",
    "        vocab[k] = np.array(vocab[k])[index].tolist()\n",
    "    return vocab\n",
    "\n",
    "def read_imagenet21k_classes():\n",
    "    with open('/home/sheng/dataset/imagenet21k/imagenet21k_wordnet_ids.txt', 'r') as f:\n",
    "        data = f.read()\n",
    "        data = list(filter(lambda x: len(x), data.split('\\n')))\n",
    "    return data\n",
    "\n",
    "templates = load_templates(args)\n",
    "vocab = get_vocab()\n",
    "nouns = [ wn.synset(s) for s in vocab['synsets'] ]\n",
    "classnames = vocab['names']\n",
    "parents = vocab['parents']\n",
    "defs = vocab['def']\n",
    "\n",
    "\"\"\" build entire wn-graph \"\"\"\n",
    "from nxgraph_model import *\n",
    "\n",
    "with open('/home/sheng/dataset/wordnet_nouns_with_synset.pkl', 'rb') as f:\n",
    "    entire_vocab = pickle.load(f)\n",
    "    \n",
    "G = create_graph([wn.synset(x) for x in entire_vocab['synsets']], entire_vocab['ids'], entire_vocab['names'], entire_vocab['def'])\n",
    "\n",
    "\"\"\" prepare dataset and load CLIP \"\"\"\n",
    "classes = read_imagenet21k_classes() + os.listdir('/home/sheng/dataset/imagenet-img/')\n",
    "classes = [wn.synset_from_pos_and_offset('n', int(x[1:])).name() for x in classes]\n",
    "classes = set(classes)\n",
    "vocab = get_subsample_vocab(classes)\n",
    "vocab = Vocab(vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a91a99-a066-43f7-a7da-cf108eb3962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.Caltech101(root='/home/sheng/dataset/Caltech101/caltech-101/', transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a509964e-10fb-4e06-bf52-fa9282cb02bb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faces_2',\n",
       " 'Faces_3',\n",
       " 'Leopards',\n",
       " 'Motorbikes_16',\n",
       " 'accordion',\n",
       " 'Airplanes_Side_2',\n",
       " 'anchor',\n",
       " 'ant',\n",
       " 'barrel',\n",
       " 'bass',\n",
       " 'beaver',\n",
       " 'binocular',\n",
       " 'bonsai',\n",
       " 'brain',\n",
       " 'brontosaurus',\n",
       " 'buddha',\n",
       " 'butterfly',\n",
       " 'camera',\n",
       " 'cannon',\n",
       " 'car_side',\n",
       " 'ceiling_fan',\n",
       " 'cellphone',\n",
       " 'chair',\n",
       " 'chandelier',\n",
       " 'cougar_body',\n",
       " 'cougar_face',\n",
       " 'crab',\n",
       " 'crayfish',\n",
       " 'crocodile',\n",
       " 'crocodile_head',\n",
       " 'cup',\n",
       " 'dalmatian',\n",
       " 'dollar_bill',\n",
       " 'dolphin',\n",
       " 'dragonfly',\n",
       " 'electric_guitar',\n",
       " 'elephant',\n",
       " 'emu',\n",
       " 'euphonium',\n",
       " 'ewer',\n",
       " 'ferry',\n",
       " 'flamingo',\n",
       " 'flamingo_head',\n",
       " 'garfield',\n",
       " 'gerenuk',\n",
       " 'gramophone',\n",
       " 'grand_piano',\n",
       " 'hawksbill',\n",
       " 'headphone',\n",
       " 'hedgehog',\n",
       " 'helicopter',\n",
       " 'ibis',\n",
       " 'inline_skate',\n",
       " 'joshua_tree',\n",
       " 'kangaroo',\n",
       " 'ketch',\n",
       " 'lamp',\n",
       " 'laptop',\n",
       " 'llama',\n",
       " 'lobster',\n",
       " 'lotus',\n",
       " 'mandolin',\n",
       " 'mayfly',\n",
       " 'menorah',\n",
       " 'metronome',\n",
       " 'minaret',\n",
       " 'nautilus',\n",
       " 'octopus',\n",
       " 'okapi',\n",
       " 'pagoda',\n",
       " 'panda',\n",
       " 'pigeon',\n",
       " 'pizza',\n",
       " 'platypus',\n",
       " 'pyramid',\n",
       " 'revolver',\n",
       " 'rhino',\n",
       " 'rooster',\n",
       " 'saxophone',\n",
       " 'schooner',\n",
       " 'scissors',\n",
       " 'scorpion',\n",
       " 'sea_horse',\n",
       " 'snoopy',\n",
       " 'soccer_ball',\n",
       " 'stapler',\n",
       " 'starfish',\n",
       " 'stegosaurus',\n",
       " 'stop_sign',\n",
       " 'strawberry',\n",
       " 'sunflower',\n",
       " 'tick',\n",
       " 'trilobite',\n",
       " 'umbrella',\n",
       " 'watch',\n",
       " 'water_lilly',\n",
       " 'wheelchair',\n",
       " 'wild_cat',\n",
       " 'windsor_chair',\n",
       " 'wrench',\n",
       " 'yin_yang']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.annotation_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "79b4e4d9-30b9-4033-a6ea-5abc5e00aa4e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class CaltechDataset(ImageFolder):\n",
    "    def __init__(self, root, vocab=None, transform=None, split='train', **kwargs):\n",
    "        self.root = root\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "        assert split in ['train', 'test']\n",
    "        self.split = split\n",
    "        self.split_ratio = 0.8\n",
    "        \n",
    "        self.category_mapping_caltech101 = {\n",
    "            'brontosaurus': 'apatosaur',\n",
    "            'car_side': 'car',\n",
    "            'cougar_body': 'cougar',\n",
    "            'faces': 'face',\n",
    "            'stop_sign': 'sign',\n",
    "            'water_lilly': 'nymphaea',\n",
    "            'saxophone': 'sax',\n",
    "            'leopards': 'leopard',\n",
    "            'rooster': 'cock',\n",
    "            'crocodile_head': 'crocodile',\n",
    "            'wild_cat': 'wildcat',\n",
    "            'hawksbill': 'hawksbill_turtle',\n",
    "            'ceiling_fan': 'electric_fan',\n",
    "            'ewer': 'pitcher',\n",
    "            'inline_skate': 'roller_skate',\n",
    "            'dollar_bill': 'dollar',\n",
    "            'airplanes': 'airplane',\n",
    "            'sea_horse': 'seahorse',\n",
    "            'headphone': 'earphone',\n",
    "            'panda': 'giant_panda',\n",
    "            'cougar_face': 'cougar',\n",
    "            'faces_easy': 'face',\n",
    "            'motorbikes': 'motorbike',\n",
    "            'rhino': 'rhinoceros',\n",
    "            'stegosaurus': 'stegosaur',\n",
    "        }\n",
    "        self.category_remove_caltech101 = ['yin_yang', 'background_google']\n",
    "        self.parse_files()\n",
    "        self.map_classes()\n",
    "        self.random_split()\n",
    "        return\n",
    "    \n",
    "    def parse_files(self):\n",
    "        samples = []\n",
    "        targets = []\n",
    "        folder_path = Path(self.root)\n",
    "        for p in folder_path.glob('**/*/*'):\n",
    "            p = str(p)\n",
    "            if '.ipynb_checkpoints'!= p.split('/')[-2]:\n",
    "                samples.append(p)\n",
    "                targets.append(p.split('/')[-2])\n",
    "        self.samples = samples\n",
    "        self.targets = targets\n",
    "        return\n",
    "    \n",
    "    def map_classes(self):\n",
    "        new_targets = []\n",
    "        valid_inds = []\n",
    "        for i, c in enumerate(self.targets):\n",
    "            c = c.lower()\n",
    "            if c in self.category_mapping_caltech101.keys():\n",
    "                new_targets.append(self.category_mapping_caltech101[c])\n",
    "                valid_inds.append(i)\n",
    "            elif c in self.category_remove_caltech101:\n",
    "                pass\n",
    "            else:\n",
    "                new_targets.append(c)\n",
    "                valid_inds.append(i)\n",
    "        self.targets = np.array(new_targets)\n",
    "        self.samples = np.array(self.samples)[np.array(valid_inds)]\n",
    "        return\n",
    "    \n",
    "    def random_split(self):\n",
    "        np.random.seed(0)\n",
    "        all_select = np.zeros(len(self.targets)).astype(np.bool)\n",
    "        for c in np.unique(self.targets):\n",
    "            select = (self.targets==c)\n",
    "            position = select.nonzero()[0]\n",
    "            sampled_ind = np.random.choice(position, int(self.split_ratio*select.sum()), replace=False)\n",
    "            select = np.zeros_like(select)\n",
    "            select[sampled_ind] = True\n",
    "            all_select |= select\n",
    "        if self.split == 'train':\n",
    "            self.samples = self.samples[all_select]\n",
    "            self.targets = self.targets[all_select]\n",
    "        else:\n",
    "            self.samples = self.samples[~all_select]\n",
    "            self.targets = self.targets[~all_select]\n",
    "        return \n",
    "    \n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        [tested]\n",
    "            1. filtering @self.labels, @self.samples\n",
    "            2. @label to @vocab_idx; @label to @label_transformed\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.vocab is not None:\n",
    "            self.targets = list(map(lambda x: self.vocab.mapping_names_idx[x], self.targets)) ### to @voc_ind\n",
    "        self.num_classes = len(set(self.targets))\n",
    "        self.label_transform = {}\n",
    "        for c, i in zip(sorted(set(self.targets)), range(self.num_classes)):\n",
    "            self.label_transform[c] = i\n",
    "        self.labels_transformed = list(map(lambda x: self.label_transform[x], self.targets))\n",
    "        self.idx_imgs = np.array(range(len(self.samples)))\n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.samples[idx]\n",
    "        img = Image.open(img).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label_voc = self.targets[idx]\n",
    "        label_clu = self.labels_transformed[idx]\n",
    "        idx_img = self.idx_imgs[idx]\n",
    "        result = [img, label_voc, label_clu, idx_img]\n",
    "        if self.ssl_cluster is not None:\n",
    "            result.append(self.ssl_cluster[idx])\n",
    "        if self.ad_weight is not None:\n",
    "            result.append(self.ad_weight[idx])\n",
    "        return result\n",
    "    \n",
    "    @property\n",
    "    def len_output(self):\n",
    "        return 4 if self.ssl_cluster is None else 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5526cdc2-d137-47b6-9196-b2ec8089ec7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_894356/1740726143.py:77: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  all_select = np.zeros(len(self.targets)).astype(np.bool)\n"
     ]
    }
   ],
   "source": [
    "d = CaltechDataset(root='/home/sheng/dataset/Caltech101/caltech-101/caltech101/101_ObjectCategories/', split='test')\n",
    "\n",
    "d.preprocess()\n",
    "d.ssl_cluster = None\n",
    "d.ad_weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "66e7ff9b-912f-4b17-81db-2e9023cc9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.Image.Image image mode=RGB size=300x197 at 0x7F18783BC1F0>,\n",
       " 'car',\n",
       " 15,\n",
       " 100]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomCIFAR100(CIFAR100):\n",
    "    def __init__(self, root, train, transform=None, vocab=None, **kwargs):\n",
    "        super(CustomCIFAR100, self).__init__(root=root, train=train, transform=transform, **kwargs)\n",
    "        self.vocab = vocab\n",
    "        self.uq_idxs = np.array(range(len(self)))\n",
    "        category_mapping = {'aquarium_fish': 'freshwater_fish', 'maple_tree': 'maple'}\n",
    "        self.classes = [category_mapping[c] if c in category_mapping else c for c in self.classes]\n",
    "        self.class_to_idx = dict([(category_mapping[k],v) if k in category_mapping else (k,v) for k, v in self.class_to_idx.items()])\n",
    "        self.num_classes = len(self.classes)\n",
    "        \n",
    "        self.label_voc = list(map(lambda x: vocab.mapping_names_idx[ self.classes[x] ], self.targets))\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, label = super().__getitem__(item)\n",
    "        label_voc = self.label_voc[item]\n",
    "        idx_img = self.uq_idxs[item]\n",
    "        result = [img, label_voc, label_clu, idx_img]\n",
    "        if self.ssl_cluster is not None:\n",
    "            result.append(self.ssl_cluster[idx])\n",
    "        if self.ad_weight is not None:\n",
    "            result.append(self.ad_weight[idx])\n",
    "        return result\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcd",
   "language": "python",
   "name": "gcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
